{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:46:53.084679Z",
     "start_time": "2021-03-01T06:46:53.035444Z"
    }
   },
   "outputs": [],
   "source": [
    "# DONE\n",
    "\n",
    "# FT-HMC implemented for 8x8 2D QED (using SiLU as activation function).\n",
    "\n",
    "# Try to minimize size of the force in training. No significant improvements.\n",
    "\n",
    "# Some test on ergodicity\n",
    "# (calculate the probablity of generating the configs obtained via conventional HMC).\n",
    "\n",
    "# TODO\n",
    "\n",
    "# Plot the force size distribution\n",
    "# Is the large force from the original action or Field-Transformation the determinant?\n",
    "# If from the determinant, then the fermion force won't cause problem for HMC\n",
    "\n",
    "# Use the same Field-Transformation for larger system (say 16x16, 32x32, 64x64, etc)\n",
    "# Study how the delta H depends on the system size ( perhaps delta H ~ sqrt(volume) )\n",
    "\n",
    "# Study the auto-correlation for observables, topo, plaq, flowed plaq, etc.\n",
    "\n",
    "# Improving the Field-Transformation to reduce force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:46:53.960100Z",
     "start_time": "2021-03-01T06:46:53.247970Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from functools import reduce\n",
    "from field_transformation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:46:59.199990Z",
     "start_time": "2021-03-01T06:46:59.121986Z"
    }
   },
   "outputs": [],
   "source": [
    "# From Xiao-Yong\n",
    "\n",
    "class Param:\n",
    "    def __init__(\n",
    "            self,\n",
    "            beta: float = 6.0,\n",
    "            lat: list = [64, 64],\n",
    "            tau: float = 2.0,\n",
    "            nstep: int = 50,\n",
    "            ntraj: int = 256,\n",
    "            nrun: int = 4,\n",
    "            nprint: int = 256,\n",
    "            seed: int = 11*13,\n",
    "            randinit: bool = False,\n",
    "            nth: int = int(os.environ.get('OMP_NUM_THREADS', '2')),\n",
    "            nth_interop: int = 2\n",
    "    ):\n",
    "        self.params = {\n",
    "            'beta': beta, \n",
    "            'lat': lat,\n",
    "            'nd': len(lat),\n",
    "            'volume': reduce(lambda x, y: x * y, lat),\n",
    "            'tau': tau,\n",
    "            'nstep': nstep,\n",
    "            'dt': tau / nstep,\n",
    "            'ntraj': ntraj,\n",
    "            'nrun': nrun,\n",
    "            'nprint': nprint,\n",
    "            'seed': seed,\n",
    "            'randinit': randinit,\n",
    "            'nth': nth,\n",
    "            'nth_interop': nth_interop,\n",
    "        }\n",
    "        for k, v in self.params.items():\n",
    "            setattr(self, k, v)\n",
    "            \n",
    "    def initializer(self) -> torch.Tensor:\n",
    "        if self.randinit:\n",
    "            return torch.empty((param.nd,) + param.lat).uniform_(-math.pi, math.pi)\n",
    "        else:\n",
    "            return torch.zeros((param.nd,) + param.lat)\n",
    "        \n",
    "    def summary(self) -> str:\n",
    "        return '\\n'.join([f'{k}: {v}' for k, v in self.params.items()])\n",
    "    \n",
    "    def uniquestr(self) -> str:\n",
    "        lat = \".\".join(str(x) for x in self.lat)\n",
    "        return f\"out_l{lat}_b{param.beta}_n{param.ntraj}_t{param.tau}_s{param.nstep}.out\"\n",
    "\n",
    "    \n",
    "def action(param: Param, f: torch.Tensor) -> torch.Tensor:\n",
    "    return (-param.beta)*torch.sum(torch.cos(plaqphase(f)))\n",
    "\n",
    "\n",
    "def force(param: Param, f: torch.Tensor) -> torch.Tensor:\n",
    "    f.requires_grad_(True)\n",
    "    s = action(param, f)\n",
    "    f.grad = None\n",
    "    s.backward()\n",
    "    ff = f.grad\n",
    "    f.requires_grad_(False)\n",
    "    return ff\n",
    "\n",
    "\n",
    "def regularize(f):\n",
    "    p2 = 2*math.pi\n",
    "    f_ = (f - math.pi) / p2\n",
    "    return p2*(f_ - torch.floor(f_) - 0.5)\n",
    "\n",
    "def plaqphase(f: torch.Tensor) -> torch.Tensor:\n",
    "    return (f[0, :]\n",
    "            - f[1, :]\n",
    "            - torch.roll(f[0, :], shifts=-1, dims=1)\n",
    "            + torch.roll(f[1, :] ,shifts=-1, dims=0))\n",
    "\n",
    "\n",
    "def topocharge(f: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.floor(0.1 + torch.sum(regularize(plaqphase(f))) / (2 * math.pi))\n",
    "\n",
    "#plaqphase = lambda f: f[0,:] - f[1,:] - torch.roll(f[0,:], shifts=-1, dims=1) + torch.roll(f[1,:], shifts=-1, dims=0)\n",
    "#topocharge = lambda f: torch.floor(0.1 + torch.sum(regularize(plaqphase(f))) / (2*math.pi))\n",
    "\n",
    "\n",
    "def leapfrog(param: Param, x: torch.Tensor, p: torch.Tensor) -> (torch.Tensor, torch.Tensor):\n",
    "    dt = param.dt\n",
    "    x_ = x + 0.5*dt*p\n",
    "    f = force(param, x_)\n",
    "    p_ = p + (-dt)*f\n",
    "    print(f'plaq(x) {action(param, x) / (-param.beta*param.volume)}  force.norm {torch.linalg.norm(f)}')\n",
    "    for i in range(param.nstep-1):\n",
    "        x_ = x_ + dt*p_\n",
    "        p_ = p_ + (-dt)*force(param, x_)\n",
    "    x_ = x_ + 0.5*dt*p_\n",
    "    return (x_, p_)\n",
    "\n",
    "def hmc(param: Param, x: torch.Tensor):\n",
    "    p = torch.randn_like(x)\n",
    "    act0 = action(param, x) + 0.5*torch.sum(p*p)\n",
    "    x_, p_ = leapfrog(param, x, p)\n",
    "    xr = regularize(x_)\n",
    "    act = action(param, xr) + 0.5*torch.sum(p_*p_)\n",
    "    prob = torch.rand([], dtype=torch.float64)\n",
    "    dH = act-act0\n",
    "    exp_mdH = torch.exp(-dH)\n",
    "    acc = prob < exp_mdH\n",
    "    newx = xr if acc else x\n",
    "    return (dH, exp_mdH, acc, newx)\n",
    "\n",
    "put = lambda s: sys.stdout.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:47:00.872182Z",
     "start_time": "2021-03-01T06:47:00.810434Z"
    }
   },
   "outputs": [],
   "source": [
    "param = Param(\n",
    "    beta = 2.0,\n",
    "    lat = (8, 8),\n",
    "    tau = 2, # 0.3\n",
    "    nstep = 8, # 3\n",
    "    # ADJUST ME\n",
    "    ntraj = 2, # 2**16 # 2**10 # 2**15\n",
    "    #\n",
    "    nprint = 2,\n",
    "    seed = 1331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:47:06.648692Z",
     "start_time": "2021-03-01T06:47:06.585917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f85588faed0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(param.seed)\n",
    "\n",
    "torch.set_num_threads(param.nth)\n",
    "torch.set_num_interop_threads(param.nth_interop)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(param.nth)\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"0\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:47:14.317705Z",
     "start_time": "2021-03-01T06:47:14.258212Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(param, field = param.initializer()):\n",
    "    with open(param.uniquestr(), \"w\") as O:\n",
    "        params = param.summary()\n",
    "        O.write(params)\n",
    "        put(params)\n",
    "        plaq, topo = (action(param, field) / (-param.beta*param.volume), topocharge(field))\n",
    "        status = f\"Initial configuration:  plaq: {plaq}  topo: {topo}\\n\"\n",
    "        O.write(status)\n",
    "        put(status)\n",
    "        ts = []\n",
    "        for n in range(param.nrun):\n",
    "            t = -timer()\n",
    "            for i in range(param.ntraj):\n",
    "                dH, exp_mdH, acc, field = hmc(param, field)\n",
    "                plaq = action(param, field) / (-param.beta*param.volume)\n",
    "                topo = topocharge(field)\n",
    "                ifacc = \"ACCEPT\" if acc else \"REJECT\"\n",
    "                status = f\"Traj: {n*param.ntraj+i+1:4}  {ifacc}:  dH: {dH:< 12.8}  exp(-dH): {exp_mdH:< 12.8}  plaq: {plaq:< 12.8}  topo: {topo:< 3.3}\\n\"\n",
    "                O.write(status)\n",
    "                if (i+1) % (param.ntraj//param.nprint) == 0:\n",
    "                    put(status)\n",
    "            t += timer()\n",
    "            ts.append(t)\n",
    "        print(\"Run times: \", ts)\n",
    "        print(\"Per trajectory: \", [t/param.ntraj for t in ts])\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:47:17.426139Z",
     "start_time": "2021-03-01T06:47:17.218723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 2.0\n",
      "lat: (8, 8)\n",
      "nd: 2\n",
      "volume: 64\n",
      "tau: 2\n",
      "nstep: 8\n",
      "dt: 0.25\n",
      "ntraj: 2\n",
      "nrun: 4\n",
      "nprint: 2\n",
      "seed: 1331\n",
      "randinit: False\n",
      "nth: 2\n",
      "nth_interop: 2Initial configuration:  plaq: 1.0  topo: 0.0\n",
      "plaq(x) 1.0  force.norm 9.246826593536493\n",
      "Traj:    1  ACCEPT:  dH: -2.1286122    exp(-dH):  8.4031965    plaq:  0.87165922   topo:  0.0\n",
      "plaq(x) 0.8716592163190823  force.norm 13.600657198197021\n",
      "Traj:    2  ACCEPT:  dH: -0.43065065   exp(-dH):  1.5382581    plaq:  0.85113562   topo:  0.0\n",
      "plaq(x) 0.8511356194331359  force.norm 17.543097274383317\n",
      "Traj:    3  ACCEPT:  dH: -0.52286113   exp(-dH):  1.686847     plaq:  0.81229714   topo:  0.0\n",
      "plaq(x) 0.8122971355705814  force.norm 17.22642099298651\n",
      "Traj:    4  ACCEPT:  dH:  0.039753441  exp(-dH):  0.96102636   plaq:  0.78167924   topo:  0.0\n",
      "plaq(x) 0.7816792404187667  force.norm 17.046687492063338\n",
      "Traj:    5  ACCEPT:  dH:  0.42993024   exp(-dH):  0.65055447   plaq:  0.80392524   topo:  0.0\n",
      "plaq(x) 0.803925239737245  force.norm 17.257422008841356\n",
      "Traj:    6  ACCEPT:  dH: -0.96340329   exp(-dH):  2.6206       plaq:  0.78202049   topo:  0.0\n",
      "plaq(x) 0.7820204923371582  force.norm 18.801543612929585\n",
      "Traj:    7  ACCEPT:  dH: -0.74395609   exp(-dH):  2.1042436    plaq:  0.69283802   topo:  0.0\n",
      "plaq(x) 0.6928380205992222  force.norm 20.552012705600838\n",
      "Traj:    8  ACCEPT:  dH: -0.49108779   exp(-dH):  1.6340928    plaq:  0.66276864   topo:  0.0\n",
      "Run times:  [0.020430095999998343, 0.026535671000004868, 0.02491056299999883, 0.024749006999996936]\n",
      "Per trajectory:  [0.010215047999999172, 0.013267835500002434, 0.012455281499999415, 0.012374503499998468]\n"
     ]
    }
   ],
   "source": [
    "field = run(param)\n",
    "field_run = torch.reshape(field,(1,)+field.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:47:20.620195Z",
     "start_time": "2021-03-01T06:47:20.540260Z"
    }
   },
   "outputs": [],
   "source": [
    "def ft_flow(flow, f):\n",
    "    for layer in flow:\n",
    "        f, lJ = layer.forward(f)\n",
    "    return f.detach()\n",
    "\n",
    "def ft_flow_inv(flow, f):\n",
    "    for layer in reversed(flow):\n",
    "        f, lJ = layer.reverse(f)\n",
    "    return f.detach()\n",
    "\n",
    "def ft_action(param, flow, f):\n",
    "    y = f\n",
    "    logJy = 0.0\n",
    "    for layer in flow:\n",
    "        y, lJ = layer.forward(y)\n",
    "        logJy += lJ\n",
    "    action = U1GaugeAction(param.beta)\n",
    "    s = action(y) - logJy\n",
    "    return s\n",
    "\n",
    "def ft_force(param, flow, field, create_graph = False):\n",
    "    # f is the field follows the transformed distribution (close to prior distribution)\n",
    "    f = field\n",
    "    f.requires_grad_(True)\n",
    "    s = ft_action(param, flow, f)\n",
    "    ss = torch.sum(s)\n",
    "    # f.grad = None\n",
    "    ff, = torch.autograd.grad(ss, f, create_graph = create_graph)\n",
    "    f.requires_grad_(False)\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:47:21.988847Z",
     "start_time": "2021-03-01T06:47:21.918039Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(model, action, optimizer, metrics, batch_size, with_force = False, pre_model = None):\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "    optimizer.zero_grad()\n",
    "    #\n",
    "    xi = None\n",
    "    if pre_model != None:\n",
    "        pre_layers, pre_prior = pre_model['layers'], pre_model['prior']\n",
    "        pre_xi = pre_prior.sample_n(batch_size)\n",
    "        x = ft_flow(pre_layers, pre_xi)\n",
    "        xi = ft_flow_inv(layers, x)\n",
    "    #\n",
    "    xi, x, logq = apply_flow_to_prior(prior, layers, batch_size=batch_size, xi=xi)\n",
    "    logp = -action(x)\n",
    "    #\n",
    "    force_size = torch.tensor(0.0)\n",
    "    dkl = calc_dkl(logp, logq)\n",
    "    loss = torch.tensor(0.0)\n",
    "    if with_force:\n",
    "        assert pre_model != None\n",
    "        force = ft_force(param, layers, xi, True)\n",
    "        force_size = torch.sum(torch.square(force))\n",
    "        loss = force_size\n",
    "    else:\n",
    "        loss = dkl\n",
    "    #\n",
    "    loss.backward()\n",
    "    #\n",
    "    # minimization target\n",
    "    # loss mini\n",
    "    # -> (logq - logp) mini\n",
    "    # -> (action - logJ) mini\n",
    "    #\n",
    "    optimizer.step()\n",
    "    ess = compute_ess(logp, logq)\n",
    "    #\n",
    "    print(grab(loss),\n",
    "          grab(force_size),\n",
    "          grab(dkl),\n",
    "          grab(ess),\n",
    "          torch.linalg.norm(ft_force(param, layers, xi)))\n",
    "    #\n",
    "    metrics['loss'].append(grab(loss))\n",
    "    metrics['force'].append(grab(force_size))\n",
    "    metrics['dkl'].append(grab(dkl))\n",
    "    metrics['logp'].append(grab(logp))\n",
    "    metrics['logq'].append(grab(logq))\n",
    "    metrics['ess'].append(grab(ess))\n",
    "\n",
    "def flow_train(param, with_force = False, pre_model = None):  # packaged from original ipynb by Xiao-Yong Jin\n",
    "    # Theory\n",
    "    lattice_shape = param.lat\n",
    "    link_shape = (2,*param.lat)\n",
    "    beta = param.beta\n",
    "    u1_action = U1GaugeAction(beta)\n",
    "    # Model\n",
    "    prior = MultivariateUniform(torch.zeros(link_shape), 2*np.pi*torch.ones(link_shape))\n",
    "    #\n",
    "    n_layers = 24\n",
    "    n_s_nets = 2\n",
    "    hidden_sizes = [8,8]\n",
    "    kernel_size = 3\n",
    "    layers = make_u1_equiv_layers(lattice_shape=lattice_shape, n_layers=n_layers, n_mixture_comps=n_s_nets,\n",
    "                                  hidden_sizes=hidden_sizes, kernel_size=kernel_size)\n",
    "    set_weights(layers)\n",
    "    model = {'layers': layers, 'prior': prior}\n",
    "    # Training\n",
    "    base_lr = .001\n",
    "    optimizer = torch.optim.Adam(model['layers'].parameters(), lr=base_lr)\n",
    "    optimizer_wf = torch.optim.Adam(model['layers'].parameters(), lr=base_lr / 100.0)\n",
    "    #\n",
    "    # ADJUST ME\n",
    "    N_era = 10\n",
    "    N_epoch = 100\n",
    "    #\n",
    "    batch_size = 64\n",
    "    print_freq = N_epoch # epochs\n",
    "    plot_freq = 1 # epochs\n",
    "    history = {\n",
    "        'loss' : [],\n",
    "        'force' : [],\n",
    "        'dkl' : [],\n",
    "        'logp' : [],\n",
    "        'logq' : [],\n",
    "        'ess' : []\n",
    "    }\n",
    "    for era in range(N_era):\n",
    "        for epoch in range(N_epoch):\n",
    "            train_step(model, u1_action, optimizer, history, batch_size)\n",
    "            if with_force:\n",
    "                train_step(model, u1_action, optimizer_wf, history, batch_size,\n",
    "                           with_force = with_force, pre_model = pre_model)\n",
    "            if epoch % print_freq == 0:\n",
    "                print_metrics(history, print_freq, era, epoch)\n",
    "    return model,u1_action\n",
    "\n",
    "def flow_eval(model, u1_action):  # packaged from original ipynb by Xiao-Yong Jin\n",
    "    ensemble_size = 1024\n",
    "    u1_ens = make_mcmc_ensemble(model, u1_action, 64, ensemble_size)\n",
    "    print(\"Accept rate:\", np.mean(u1_ens['accepted']))\n",
    "    Q = grab(topo_charge(torch.stack(u1_ens['x'], axis=0)))\n",
    "    X_mean, X_err = bootstrap(Q**2, Nboot=100, binsize=16)\n",
    "    print(f'Topological susceptibility = {X_mean:.2f} +/- {X_err:.2f}')\n",
    "    print(f'... vs HMC estimate = 1.23 +/- 0.02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T07:10:16.504898Z",
     "start_time": "2021-03-01T06:47:24.945703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-235.80379178382827 0.0 -235.80379178382827 0.015742986900554163 tensor(173.9276)\n",
      "== Era 0 | Epoch 0 metrics ==\n",
      "\tloss -235.804\n",
      "\tforce 0\n",
      "\tdkl -235.804\n",
      "\tlogp 0.693854\n",
      "\tlogq -235.11\n",
      "\tess 0.015743\n",
      "-240.22592204900428 0.0 -240.22592204900428 0.01726504117436026 tensor(169.3064)\n",
      "-241.73488535507386 0.0 -241.73488535507386 0.016400911777968756 tensor(167.0606)\n",
      "-247.46169379805445 0.0 -247.46169379805445 0.015810153849540865 tensor(160.3539)\n",
      "-253.25240939507336 0.0 -253.25240939507336 0.01941417680419557 tensor(158.7390)\n",
      "-256.75166216575127 0.0 -256.75166216575127 0.015804690643426364 tensor(154.5671)\n",
      "-257.21331835493976 0.0 -257.21331835493976 0.01562887239859159 tensor(157.1432)\n",
      "-261.58546505634735 0.0 -261.58546505634735 0.020297799438260253 tensor(151.7423)\n",
      "-265.36695333901866 0.0 -265.36695333901866 0.0156412599546812 tensor(151.7542)\n",
      "-266.2862499543668 0.0 -266.2862499543668 0.016146700456890064 tensor(155.4196)\n",
      "-270.4000967148002 0.0 -270.4000967148002 0.01831122343147412 tensor(156.1291)\n",
      "-272.4753249417529 0.0 -272.4753249417529 0.04926610112492897 tensor(161.7628)\n",
      "-274.0188336018449 0.0 -274.0188336018449 0.01720192443603824 tensor(164.9150)\n",
      "-276.6255801641357 0.0 -276.6255801641357 0.025718036976023106 tensor(171.3087)\n",
      "-278.0437584060316 0.0 -278.0437584060316 0.04650591994411121 tensor(167.8843)\n",
      "-278.5597071189384 0.0 -278.5597071189384 0.12872091592793028 tensor(172.7423)\n",
      "-279.621035979776 0.0 -279.621035979776 0.05532086467648965 tensor(190.1240)\n",
      "-279.0197231824364 0.0 -279.0197231824364 0.03938253604333164 tensor(200.9539)\n",
      "-279.76487981304757 0.0 -279.76487981304757 0.054519163219636 tensor(197.8722)\n",
      "-278.52186411795196 0.0 -278.52186411795196 0.04685051049393451 tensor(190.9811)\n",
      "-279.3359481493468 0.0 -279.3359481493468 0.04544745289418525 tensor(200.5659)\n",
      "-278.24609126746435 0.0 -278.24609126746435 0.06238963263133862 tensor(220.7544)\n",
      "-278.34046858181995 0.0 -278.34046858181995 0.05001545440329313 tensor(206.7338)\n",
      "-278.83827606017775 0.0 -278.83827606017775 0.044844557072964274 tensor(204.9199)\n",
      "-277.829481382711 0.0 -277.829481382711 0.018040034645773903 tensor(209.8352)\n",
      "-277.5916656840476 0.0 -277.5916656840476 0.01636556036707938 tensor(206.6545)\n",
      "-278.1507596029114 0.0 -278.1507596029114 0.06118730824765313 tensor(207.9465)\n",
      "-278.8101103706663 0.0 -278.8101103706663 0.034171797405028785 tensor(197.2281)\n",
      "-279.4655671051157 0.0 -279.4655671051157 0.04598678738027564 tensor(184.8082)\n",
      "-280.6271984343321 0.0 -280.6271984343321 0.01813896051119748 tensor(195.5126)\n",
      "-280.49219102778613 0.0 -280.49219102778613 0.058131581935922494 tensor(188.1255)\n",
      "-280.2068988846669 0.0 -280.2068988846669 0.021029946327524276 tensor(190.1216)\n",
      "-280.0755728496201 0.0 -280.0755728496201 0.03678629248046825 tensor(194.5040)\n",
      "-280.27826695532247 0.0 -280.27826695532247 0.028742392685797303 tensor(192.5850)\n",
      "-280.1873088901689 0.0 -280.1873088901689 0.08962251720645786 tensor(180.5103)\n",
      "-280.89798536616973 0.0 -280.89798536616973 0.02286624294172809 tensor(176.2874)\n",
      "-279.7099388229209 0.0 -279.7099388229209 0.07881664348467764 tensor(178.6955)\n",
      "-280.85005605236887 0.0 -280.85005605236887 0.055791318173413366 tensor(172.9682)\n",
      "-281.22864291613104 0.0 -281.22864291613104 0.022475915863308292 tensor(172.0726)\n",
      "-280.7601195177947 0.0 -280.7601195177947 0.03457317148080947 tensor(171.1435)\n",
      "-280.7015899077326 0.0 -280.7015899077326 0.041598648103628816 tensor(175.0371)\n",
      "-280.07599874405196 0.0 -280.07599874405196 0.01571257750061264 tensor(179.4415)\n",
      "-280.1599174818852 0.0 -280.1599174818852 0.08907547182949271 tensor(172.4989)\n",
      "-280.51062148805613 0.0 -280.51062148805613 0.08400647854927791 tensor(173.4484)\n",
      "-281.0749944569544 0.0 -281.0749944569544 0.019619205321069054 tensor(173.8982)\n",
      "-280.32840611227647 0.0 -280.32840611227647 0.0399786225867048 tensor(165.3508)\n",
      "-280.55509908945055 0.0 -280.55509908945055 0.06077742684745242 tensor(172.4607)\n",
      "-281.0819986780939 0.0 -281.0819986780939 0.04230964744576648 tensor(176.0983)\n",
      "-280.0948994967971 0.0 -280.0948994967971 0.07837078262497556 tensor(183.6973)\n",
      "-280.8024783790729 0.0 -280.8024783790729 0.032545641534498564 tensor(182.5193)\n",
      "-281.4956722444581 0.0 -281.4956722444581 0.0275810425537696 tensor(176.5550)\n",
      "-280.40079033652864 0.0 -280.40079033652864 0.034283307159461957 tensor(172.2658)\n",
      "-281.9345064797601 0.0 -281.9345064797601 0.09477756280786527 tensor(180.6309)\n",
      "-280.8650609714495 0.0 -280.8650609714495 0.020599883182194127 tensor(181.0129)\n",
      "-280.89788182581094 0.0 -280.89788182581094 0.022247776021795965 tensor(187.7786)\n",
      "-281.1891778348007 0.0 -281.1891778348007 0.061989714949329665 tensor(186.5429)\n",
      "-280.31052060625746 0.0 -280.31052060625746 0.12670764213762786 tensor(177.8267)\n",
      "-282.5182438588376 0.0 -282.5182438588376 0.04110197507992237 tensor(179.2902)\n",
      "-280.88979613636826 0.0 -280.88979613636826 0.035788170121740404 tensor(180.6850)\n",
      "-281.67261027289476 0.0 -281.67261027289476 0.020884132175668875 tensor(187.8300)\n",
      "-281.2433286605999 0.0 -281.2433286605999 0.07685460093425996 tensor(182.5710)\n",
      "-281.39941651518035 0.0 -281.39941651518035 0.019674919471359555 tensor(184.8858)\n",
      "-281.44447396798336 0.0 -281.44447396798336 0.015986711230498888 tensor(182.5059)\n",
      "-282.11031570838367 0.0 -282.11031570838367 0.045043580083319566 tensor(183.4524)\n",
      "-280.9787463953471 0.0 -280.9787463953471 0.03672576751273208 tensor(168.4463)\n",
      "-280.53249089993466 0.0 -280.53249089993466 0.05635550986413327 tensor(182.7690)\n",
      "-282.19144397426135 0.0 -282.19144397426135 0.04076380493125131 tensor(179.7477)\n",
      "-281.711951856164 0.0 -281.711951856164 0.058305202359699326 tensor(176.5427)\n",
      "-281.6959079076538 0.0 -281.6959079076538 0.02402384231446624 tensor(166.3750)\n",
      "-280.2845728767015 0.0 -280.2845728767015 0.036981267900431554 tensor(180.1940)\n",
      "-281.0296800962542 0.0 -281.0296800962542 0.0549875835180861 tensor(175.1306)\n",
      "-281.33363761687013 0.0 -281.33363761687013 0.0273282222066487 tensor(173.1741)\n",
      "-281.2295763241233 0.0 -281.2295763241233 0.03630821176003668 tensor(179.3191)\n",
      "-281.17842959104695 0.0 -281.17842959104695 0.03828596828691298 tensor(181.6012)\n",
      "-281.63381482990314 0.0 -281.63381482990314 0.10277893799147371 tensor(174.1253)\n",
      "-281.66428921154534 0.0 -281.66428921154534 0.04247487350143048 tensor(175.1895)\n",
      "-282.0442685956595 0.0 -282.0442685956595 0.11302439180846932 tensor(181.0515)\n",
      "-282.217124653517 0.0 -282.217124653517 0.040262488754820844 tensor(181.2859)\n",
      "-282.10812986663086 0.0 -282.10812986663086 0.07920310769711404 tensor(176.3626)\n",
      "-281.86096576294597 0.0 -281.86096576294597 0.15869952263174672 tensor(185.5843)\n",
      "-282.21128894428523 0.0 -282.21128894428523 0.028988375934742277 tensor(179.8114)\n",
      "-280.85091289770736 0.0 -280.85091289770736 0.08700997061604492 tensor(186.5723)\n",
      "-281.1877732527943 0.0 -281.1877732527943 0.023828303839756003 tensor(177.4217)\n",
      "-281.761208043354 0.0 -281.761208043354 0.043515496622139105 tensor(177.1457)\n",
      "-281.63231670695757 0.0 -281.63231670695757 0.02070385025039926 tensor(196.2096)\n",
      "-281.7073711926606 0.0 -281.7073711926606 0.03038522265467768 tensor(191.7956)\n",
      "-282.26686509613796 0.0 -282.26686509613796 0.018121128150640247 tensor(178.5193)\n",
      "-282.32893941857486 0.0 -282.32893941857486 0.015834773442371275 tensor(185.0120)\n",
      "-282.5646146845484 0.0 -282.5646146845484 0.03721718187263389 tensor(182.8940)\n",
      "-281.66630905225867 0.0 -281.66630905225867 0.09016990979064439 tensor(180.6176)\n",
      "-281.8691022646892 0.0 -281.8691022646892 0.032426043228763066 tensor(182.4766)\n",
      "-281.8105358433904 0.0 -281.8105358433904 0.03087916641312881 tensor(191.2861)\n",
      "-282.21598126391734 0.0 -282.21598126391734 0.05421624568195883 tensor(178.4135)\n",
      "-282.85015366684627 0.0 -282.85015366684627 0.10421619782065272 tensor(174.2103)\n",
      "-281.99705545539797 0.0 -281.99705545539797 0.04501972828117287 tensor(175.0787)\n",
      "-282.940125520435 0.0 -282.940125520435 0.021274293550750265 tensor(172.8371)\n",
      "-281.8917014183581 0.0 -281.8917014183581 0.03897666733372761 tensor(172.9879)\n",
      "-283.15599364900083 0.0 -283.15599364900083 0.01696672651246978 tensor(169.7644)\n",
      "-282.47809447276256 0.0 -282.47809447276256 0.05757713509931378 tensor(170.1345)\n",
      "-282.6446707239398 0.0 -282.6446707239398 0.0561849518070143 tensor(173.9761)\n",
      "-282.00670714588443 0.0 -282.00670714588443 0.047572570236457196 tensor(170.8849)\n",
      "== Era 1 | Epoch 0 metrics ==\n",
      "\tloss -278.203\n",
      "\tforce 0\n",
      "\tdkl -278.203\n",
      "\tlogp 68.451\n",
      "\tlogq -209.752\n",
      "\tess 0.0447474\n",
      "-282.30318004954523 0.0 -282.30318004954523 0.03519414026309184 tensor(173.6366)\n",
      "-281.71068933998566 0.0 -281.71068933998566 0.044429059801847706 tensor(189.9906)\n",
      "-282.02463668393204 0.0 -282.02463668393204 0.02869624631395367 tensor(171.9115)\n",
      "-283.13286923975613 0.0 -283.13286923975613 0.019255968703855045 tensor(165.2447)\n",
      "-282.0692816718184 0.0 -282.0692816718184 0.02305745703770662 tensor(170.5575)\n",
      "-282.6374101397821 0.0 -282.6374101397821 0.03463303707863622 tensor(174.0301)\n",
      "-282.69424815211875 0.0 -282.69424815211875 0.07775488816440008 tensor(182.1365)\n",
      "-282.8336707077077 0.0 -282.8336707077077 0.11739860957902379 tensor(173.4950)\n",
      "-282.4292215109003 0.0 -282.4292215109003 0.04353524233108277 tensor(174.8651)\n",
      "-282.63920432682426 0.0 -282.63920432682426 0.057467884980354454 tensor(174.7497)\n",
      "-282.522661441311 0.0 -282.522661441311 0.18695199739179116 tensor(175.9306)\n",
      "-282.3960594537949 0.0 -282.3960594537949 0.10639430865819953 tensor(175.4130)\n",
      "-283.18745889396143 0.0 -283.18745889396143 0.0731661455603641 tensor(185.5502)\n",
      "-283.1071742096166 0.0 -283.1071742096166 0.11033916417667007 tensor(172.6518)\n",
      "-284.22318622434653 0.0 -284.22318622434653 0.07341238050431044 tensor(178.3674)\n",
      "-282.6782644014968 0.0 -282.6782644014968 0.04964608190177719 tensor(188.2040)\n",
      "-282.58670020715914 0.0 -282.58670020715914 0.01979867941971493 tensor(176.1086)\n",
      "-282.9601264612375 0.0 -282.9601264612375 0.06513096496416332 tensor(176.9925)\n",
      "-283.507229866559 0.0 -283.507229866559 0.019451505417375895 tensor(185.1243)\n",
      "-282.77542108747747 0.0 -282.77542108747747 0.0720419309162095 tensor(181.8959)\n",
      "-283.2024171454899 0.0 -283.2024171454899 0.058742829418482 tensor(170.0647)\n",
      "-282.7496708762466 0.0 -282.7496708762466 0.06744229921806949 tensor(189.1918)\n",
      "-282.19984885633585 0.0 -282.19984885633585 0.08623079508399159 tensor(183.4364)\n",
      "-283.4642465300078 0.0 -283.4642465300078 0.04030354199547901 tensor(169.0150)\n",
      "-283.0612352735593 0.0 -283.0612352735593 0.11139450370861136 tensor(176.9349)\n",
      "-282.29700158833884 0.0 -282.29700158833884 0.029870035508312916 tensor(173.2359)\n",
      "-283.0478913656436 0.0 -283.0478913656436 0.07469371942878723 tensor(180.8702)\n",
      "-283.2999767570986 0.0 -283.2999767570986 0.10333386148568184 tensor(184.7027)\n",
      "-283.2584641423234 0.0 -283.2584641423234 0.042256543041594916 tensor(164.9398)\n",
      "-283.5549297190919 0.0 -283.5549297190919 0.05284754294273788 tensor(176.7548)\n",
      "-283.44679563845085 0.0 -283.44679563845085 0.03132916591299293 tensor(169.0613)\n",
      "-283.2957660064998 0.0 -283.2957660064998 0.10908928614947638 tensor(168.3540)\n",
      "-283.36231638432264 0.0 -283.36231638432264 0.13317080561339126 tensor(178.3065)\n",
      "-283.3335630700467 0.0 -283.3335630700467 0.03771710179361245 tensor(169.9870)\n",
      "-283.68519867946276 0.0 -283.68519867946276 0.022691849782948866 tensor(162.7710)\n",
      "-283.82469976623 0.0 -283.82469976623 0.11088494592471682 tensor(173.6911)\n",
      "-283.2632033030259 0.0 -283.2632033030259 0.04599732008527495 tensor(166.0525)\n",
      "-283.9682544420002 0.0 -283.9682544420002 0.06766684517056247 tensor(176.9502)\n",
      "-283.1736355657762 0.0 -283.1736355657762 0.07462851811540372 tensor(185.8444)\n",
      "-283.46881889312465 0.0 -283.46881889312465 0.11987147049097922 tensor(180.1229)\n",
      "-283.40641675598147 0.0 -283.40641675598147 0.04601947783379247 tensor(182.7823)\n",
      "-283.5793508013917 0.0 -283.5793508013917 0.07835659860063421 tensor(175.5434)\n",
      "-283.93621492741386 0.0 -283.93621492741386 0.06598119556474961 tensor(178.8233)\n",
      "-283.91012809830227 0.0 -283.91012809830227 0.049936703949977596 tensor(182.1567)\n",
      "-284.3697748446327 0.0 -284.3697748446327 0.12103288366832006 tensor(160.9178)\n",
      "-283.9412174668042 0.0 -283.9412174668042 0.17673422218402898 tensor(169.1831)\n",
      "-284.2950279147256 0.0 -284.2950279147256 0.04776530373027298 tensor(171.9146)\n",
      "-283.96319330502206 0.0 -283.96319330502206 0.0741857367761963 tensor(165.7994)\n",
      "-284.2201830671403 0.0 -284.2201830671403 0.06989594801601863 tensor(172.9130)\n",
      "-284.45051366883473 0.0 -284.45051366883473 0.06088207421373078 tensor(175.0090)\n",
      "-283.8741287280267 0.0 -283.8741287280267 0.06459306405638057 tensor(179.6951)\n",
      "-283.67814048726876 0.0 -283.67814048726876 0.04960306698565343 tensor(178.4403)\n",
      "-283.8248137067871 0.0 -283.8248137067871 0.016166408115057963 tensor(169.3131)\n",
      "-284.11021619211493 0.0 -284.11021619211493 0.10069734602275496 tensor(182.6901)\n",
      "-284.08864210160567 0.0 -284.08864210160567 0.1197664454721053 tensor(179.7751)\n",
      "-283.60113745842614 0.0 -283.60113745842614 0.04771807037186106 tensor(175.5429)\n",
      "-284.53002920665483 0.0 -284.53002920665483 0.09251990685107744 tensor(168.7565)\n",
      "-284.0222837211801 0.0 -284.0222837211801 0.10871693142449344 tensor(194.3816)\n",
      "-284.6389806430451 0.0 -284.6389806430451 0.12263617010084052 tensor(162.3994)\n",
      "-283.85040911298563 0.0 -283.85040911298563 0.04448038210277206 tensor(185.6694)\n",
      "-283.6436309597954 0.0 -283.6436309597954 0.1589295256723189 tensor(177.9785)\n",
      "-284.085284121786 0.0 -284.085284121786 0.12204017675400022 tensor(164.1414)\n",
      "-284.52010441809915 0.0 -284.52010441809915 0.17213783609115507 tensor(174.7066)\n",
      "-284.0974205147344 0.0 -284.0974205147344 0.11808280917733889 tensor(171.3153)\n",
      "-284.1038455659367 0.0 -284.1038455659367 0.11329840995752463 tensor(157.0927)\n",
      "-284.48818801213673 0.0 -284.48818801213673 0.043779521579852 tensor(175.0124)\n",
      "-284.6844803917569 0.0 -284.6844803917569 0.1400977834540603 tensor(172.9611)\n",
      "-284.8279505794618 0.0 -284.8279505794618 0.06381134877238784 tensor(181.9822)\n",
      "-283.847314636737 0.0 -283.847314636737 0.1457542069842967 tensor(170.0130)\n",
      "-284.5270323027262 0.0 -284.5270323027262 0.16989467527463406 tensor(160.4349)\n",
      "-284.30560925652424 0.0 -284.30560925652424 0.11429048397444173 tensor(170.5609)\n",
      "-284.6048803190805 0.0 -284.6048803190805 0.04444173957319033 tensor(165.0588)\n",
      "-284.841079931793 0.0 -284.841079931793 0.042264704696751566 tensor(156.7691)\n",
      "-285.09822921006116 0.0 -285.09822921006116 0.07452433132458808 tensor(169.0757)\n",
      "-284.5679132181375 0.0 -284.5679132181375 0.04548152510590806 tensor(166.8612)\n",
      "-284.28800473966487 0.0 -284.28800473966487 0.05860942150288944 tensor(177.2119)\n",
      "-285.1073424821015 0.0 -285.1073424821015 0.027581707935021547 tensor(182.1247)\n",
      "-284.7711944624117 0.0 -284.7711944624117 0.16990258486277215 tensor(161.8611)\n",
      "-284.9485453738905 0.0 -284.9485453738905 0.04237198967617256 tensor(179.6818)\n",
      "-284.5407531860023 0.0 -284.5407531860023 0.10447810921395437 tensor(168.9022)\n",
      "-284.99020154302303 0.0 -284.99020154302303 0.05931719238077771 tensor(178.7228)\n",
      "-284.492945606835 0.0 -284.492945606835 0.1465350296105903 tensor(198.6983)\n",
      "-284.70163936834473 0.0 -284.70163936834473 0.09047054893545678 tensor(169.7947)\n",
      "-285.2429312925678 0.0 -285.2429312925678 0.024129017240739032 tensor(172.3599)\n",
      "-284.0130427928664 0.0 -284.0130427928664 0.15249106412388816 tensor(169.2721)\n",
      "-284.7599683129587 0.0 -284.7599683129587 0.02632855942286506 tensor(179.1257)\n",
      "-285.75495444126875 0.0 -285.75495444126875 0.10864935249242606 tensor(153.9854)\n",
      "-284.81064142098523 0.0 -284.81064142098523 0.10521914401770917 tensor(172.1167)\n",
      "-285.5448603539972 0.0 -285.5448603539972 0.1855202512248685 tensor(186.2401)\n",
      "-285.1338640784657 0.0 -285.1338640784657 0.05773327578451914 tensor(175.2438)\n",
      "-285.2730387331877 0.0 -285.2730387331877 0.10084277279356604 tensor(155.3600)\n",
      "-285.1694218778059 0.0 -285.1694218778059 0.16481802801902484 tensor(162.0158)\n",
      "-285.4812602201305 0.0 -285.4812602201305 0.21647479998460994 tensor(150.0655)\n",
      "-285.18648045414227 0.0 -285.18648045414227 0.20412787577286565 tensor(166.8762)\n",
      "-284.7439428094399 0.0 -284.7439428094399 0.05471426533879927 tensor(170.6931)\n",
      "-285.08235824509353 0.0 -285.08235824509353 0.20725302838207318 tensor(173.3536)\n",
      "-284.9361512862854 0.0 -284.9361512862854 0.06251251654264883 tensor(178.2972)\n",
      "-285.4491674382099 0.0 -285.4491674382099 0.13403303249778092 tensor(163.1847)\n",
      "-285.5311706336511 0.0 -285.5311706336511 0.05247993635689727 tensor(170.9179)\n",
      "-285.1491985889682 0.0 -285.1491985889682 0.05567179232604268 tensor(155.7343)\n",
      "== Era 2 | Epoch 0 metrics ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tloss -283.91\n",
      "\tforce 0\n",
      "\tdkl -283.91\n",
      "\tlogp 79.3769\n",
      "\tlogq -204.533\n",
      "\tess 0.084167\n",
      "-285.2184109390458 0.0 -285.2184109390458 0.05831390274229266 tensor(174.0637)\n",
      "-285.5080370194683 0.0 -285.5080370194683 0.1166042724279074 tensor(158.2435)\n",
      "-285.47454534289994 0.0 -285.47454534289994 0.08551370972479476 tensor(159.2134)\n",
      "-285.7410910826486 0.0 -285.7410910826486 0.09694266245844649 tensor(166.2664)\n",
      "-285.1816577242461 0.0 -285.1816577242461 0.18581720592138307 tensor(160.6161)\n",
      "-284.94563297692713 0.0 -284.94563297692713 0.037887675923891334 tensor(165.5799)\n",
      "-285.1367904117073 0.0 -285.1367904117073 0.07095008093136997 tensor(161.8093)\n",
      "-284.88992314549574 0.0 -284.88992314549574 0.1292122816474257 tensor(175.4481)\n",
      "-285.48417859246416 0.0 -285.48417859246416 0.09883028991631716 tensor(170.3434)\n",
      "-285.2071173702128 0.0 -285.2071173702128 0.1686882618690228 tensor(159.7044)\n",
      "-285.5761087567976 0.0 -285.5761087567976 0.10562976216060008 tensor(153.3455)\n",
      "-284.9573830256865 0.0 -284.9573830256865 0.1613954717331739 tensor(166.5366)\n",
      "-285.52831036667357 0.0 -285.52831036667357 0.06433101101357216 tensor(157.1581)\n",
      "-285.5380265392524 0.0 -285.5380265392524 0.08475295738354054 tensor(168.5715)\n",
      "-285.5215177825453 0.0 -285.5215177825453 0.046224439999741886 tensor(145.8244)\n",
      "-284.7379876502289 0.0 -284.7379876502289 0.12556293282681696 tensor(177.4749)\n",
      "-285.0976324712978 0.0 -285.0976324712978 0.051669530337644536 tensor(171.8913)\n",
      "-285.3677441486632 0.0 -285.3677441486632 0.07960932582645106 tensor(160.3034)\n",
      "-285.172117130299 0.0 -285.172117130299 0.14246042925814437 tensor(178.2159)\n",
      "-284.95505389019525 0.0 -284.95505389019525 0.09333795996034315 tensor(171.3762)\n",
      "-285.21079144991694 0.0 -285.21079144991694 0.02345102202011016 tensor(163.6698)\n",
      "-285.7729029572439 0.0 -285.7729029572439 0.1590933247135578 tensor(177.1358)\n",
      "-285.70097478620545 0.0 -285.70097478620545 0.07724134735040727 tensor(149.6147)\n",
      "-285.391373608909 0.0 -285.391373608909 0.06450193671957691 tensor(176.4151)\n",
      "-285.4059595776419 0.0 -285.4059595776419 0.2008997334958704 tensor(161.9324)\n",
      "-285.0249742498494 0.0 -285.0249742498494 0.16469151906217155 tensor(168.7602)\n",
      "-285.34496399192614 0.0 -285.34496399192614 0.08451825216577855 tensor(180.1230)\n",
      "-285.4542273420165 0.0 -285.4542273420165 0.15129332893332603 tensor(160.0746)\n",
      "-285.7394136091922 0.0 -285.7394136091922 0.07095784232522673 tensor(143.8819)\n",
      "-285.35257360520876 0.0 -285.35257360520876 0.2252389971580993 tensor(157.8147)\n",
      "-285.6514614256912 0.0 -285.6514614256912 0.12542073232142328 tensor(170.8566)\n",
      "-285.30860198452655 0.0 -285.30860198452655 0.24665216109748223 tensor(163.0398)\n",
      "-285.22001047477994 0.0 -285.22001047477994 0.19890735548454128 tensor(162.9307)\n",
      "-286.0346141044009 0.0 -286.0346141044009 0.060724437521455184 tensor(154.9434)\n",
      "-284.88161619753237 0.0 -284.88161619753237 0.1456399103051855 tensor(163.2169)\n",
      "-285.4859866499263 0.0 -285.4859866499263 0.15903325152067285 tensor(170.9442)\n",
      "-285.1185583000024 0.0 -285.1185583000024 0.10976198201361023 tensor(174.2226)\n",
      "-285.4987788689051 0.0 -285.4987788689051 0.26247521263505436 tensor(170.8950)\n",
      "-285.3732465873661 0.0 -285.3732465873661 0.07718100543475595 tensor(187.6936)\n",
      "-285.40862417950996 0.0 -285.40862417950996 0.039990432621335406 tensor(178.2936)\n",
      "-284.80634854312103 0.0 -284.80634854312103 0.13733116813624777 tensor(170.3104)\n",
      "-285.6282098060283 0.0 -285.6282098060283 0.10152011862808323 tensor(159.3864)\n",
      "-285.1068810633505 0.0 -285.1068810633505 0.10477600508488909 tensor(162.4142)\n",
      "-285.27508423020356 0.0 -285.27508423020356 0.10034933840116515 tensor(156.2405)\n",
      "-285.3810020436001 0.0 -285.3810020436001 0.0714380080535073 tensor(161.7828)\n",
      "-285.18245914653824 0.0 -285.18245914653824 0.12577538158485227 tensor(161.4112)\n",
      "-285.64785782581964 0.0 -285.64785782581964 0.20742398966624734 tensor(170.1285)\n",
      "-285.6591782869963 0.0 -285.6591782869963 0.0865304775532214 tensor(175.8828)\n",
      "-285.2087385595846 0.0 -285.2087385595846 0.15381965053538188 tensor(168.5506)\n",
      "-286.12585610110995 0.0 -286.12585610110995 0.07900627174344212 tensor(163.5564)\n",
      "-285.1630109045657 0.0 -285.1630109045657 0.10736049842533142 tensor(170.3251)\n",
      "-285.2642666096143 0.0 -285.2642666096143 0.05824219574694272 tensor(159.8768)\n",
      "-285.24075330162725 0.0 -285.24075330162725 0.02513388317778653 tensor(149.0011)\n",
      "-285.3878000143175 0.0 -285.3878000143175 0.13754289894838995 tensor(167.0263)\n",
      "-285.7401354310643 0.0 -285.7401354310643 0.2709526156846631 tensor(161.0943)\n",
      "-285.3269827196391 0.0 -285.3269827196391 0.14765894018364692 tensor(146.9850)\n",
      "-285.74927499460284 0.0 -285.74927499460284 0.0486481967757248 tensor(149.4949)\n",
      "-284.8469046964984 0.0 -284.8469046964984 0.04697929940557509 tensor(175.6567)\n",
      "-285.4205026853197 0.0 -285.4205026853197 0.18875815928515283 tensor(165.2185)\n",
      "-285.50508590616903 0.0 -285.50508590616903 0.2267452268441885 tensor(158.1366)\n",
      "-285.11426066992465 0.0 -285.11426066992465 0.11170305946448954 tensor(171.1510)\n",
      "-285.4200717483932 0.0 -285.4200717483932 0.08255416918835967 tensor(174.0107)\n",
      "-285.6588242093638 0.0 -285.6588242093638 0.2340175471610539 tensor(152.2888)\n",
      "-285.4040448912073 0.0 -285.4040448912073 0.12415036562649723 tensor(171.3159)\n",
      "-285.8326220236139 0.0 -285.8326220236139 0.13204942022108096 tensor(159.6966)\n",
      "-286.12827467087465 0.0 -286.12827467087465 0.08635103738067741 tensor(160.6796)\n",
      "-285.4023941930376 0.0 -285.4023941930376 0.21147548870984464 tensor(149.3049)\n",
      "-285.9532353569975 0.0 -285.9532353569975 0.0900110540251199 tensor(161.5633)\n",
      "-285.7232486283 0.0 -285.7232486283 0.08756597541290158 tensor(162.3246)\n",
      "-285.49115517907984 0.0 -285.49115517907984 0.2631365142210578 tensor(159.4343)\n",
      "-285.99757546433807 0.0 -285.99757546433807 0.11244521943021936 tensor(143.8802)\n",
      "-286.167799137468 0.0 -286.167799137468 0.13057303432118428 tensor(193.3245)\n",
      "-285.9101314902405 0.0 -285.9101314902405 0.16758019302615743 tensor(179.1590)\n",
      "-286.02838524043216 0.0 -286.02838524043216 0.10425423095814053 tensor(175.1772)\n",
      "-285.2856559015512 0.0 -285.2856559015512 0.24177755632869594 tensor(178.5364)\n",
      "-285.55992223407884 0.0 -285.55992223407884 0.16093645744025906 tensor(174.1965)\n",
      "-285.5090475273259 0.0 -285.5090475273259 0.1919964817617081 tensor(165.6718)\n",
      "-285.56434967209793 0.0 -285.56434967209793 0.02516573505361505 tensor(149.2694)\n",
      "-285.6594626697933 0.0 -285.6594626697933 0.23745579630997443 tensor(171.5936)\n",
      "-285.97686956721475 0.0 -285.97686956721475 0.23899631519817463 tensor(171.9225)\n",
      "-285.780326560224 0.0 -285.780326560224 0.18065905708737143 tensor(164.8595)\n",
      "-286.1399537964311 0.0 -286.1399537964311 0.28431228718305385 tensor(149.7332)\n",
      "-285.06797877537844 0.0 -285.06797877537844 0.06653915860296575 tensor(189.3691)\n",
      "-285.95221940619604 0.0 -285.95221940619604 0.16713016144299656 tensor(147.3088)\n",
      "-285.102728405786 0.0 -285.102728405786 0.1694316475254315 tensor(154.0403)\n",
      "-285.9449710904536 0.0 -285.9449710904536 0.19058660901895602 tensor(156.4954)\n",
      "-285.3359436672664 0.0 -285.3359436672664 0.05919862536075 tensor(147.4999)\n",
      "-285.84935224405973 0.0 -285.84935224405973 0.02916542139084924 tensor(172.8778)\n",
      "-285.6722934403898 0.0 -285.6722934403898 0.07606397676175877 tensor(149.7635)\n",
      "-286.04833985253174 0.0 -286.04833985253174 0.1684493414353511 tensor(143.6541)\n",
      "-285.3165836052094 0.0 -285.3165836052094 0.15058063873566377 tensor(184.5201)\n",
      "-286.04855617132927 0.0 -286.04855617132927 0.13691291943983927 tensor(161.3928)\n",
      "-285.854902245897 0.0 -285.854902245897 0.14551214859476544 tensor(159.7537)\n",
      "-286.0995853766601 0.0 -286.0995853766601 0.06316112282926942 tensor(168.0187)\n",
      "-285.54512764712405 0.0 -285.54512764712405 0.206258906142214 tensor(178.3941)\n",
      "-285.8807443244534 0.0 -285.8807443244534 0.09429638143328223 tensor(187.6910)\n",
      "-285.3657718193308 0.0 -285.3657718193308 0.13484266850204138 tensor(160.1588)\n",
      "-285.55937227388847 0.0 -285.55937227388847 0.1751961648359966 tensor(162.6509)\n",
      "-285.5763420966449 0.0 -285.5763420966449 0.1801899603856416 tensor(147.5945)\n",
      "-285.7028333380715 0.0 -285.7028333380715 0.17589751229652612 tensor(148.2741)\n",
      "== Era 3 | Epoch 0 metrics ==\n",
      "\tloss -285.489\n",
      "\tforce 0\n",
      "\tdkl -285.489\n",
      "\tlogp 83.2097\n",
      "\tlogq -202.279\n",
      "\tess 0.12966\n",
      "-285.76680265178265 0.0 -285.76680265178265 0.10178840738929257 tensor(150.5435)\n",
      "-285.4680570493844 0.0 -285.4680570493844 0.057700858076692486 tensor(171.2564)\n",
      "-285.4320627919464 0.0 -285.4320627919464 0.1302547484754149 tensor(177.0882)\n",
      "-285.9759109310212 0.0 -285.9759109310212 0.15499422698248255 tensor(146.2332)\n",
      "-285.2153668369717 0.0 -285.2153668369717 0.2189449581050887 tensor(171.8966)\n",
      "-285.48660306425217 0.0 -285.48660306425217 0.11321807829973943 tensor(187.9403)\n",
      "-285.5833949046988 0.0 -285.5833949046988 0.06373153825501945 tensor(158.9213)\n",
      "-285.4872705168798 0.0 -285.4872705168798 0.0839953258493482 tensor(182.5070)\n",
      "-285.54272284288584 0.0 -285.54272284288584 0.04935803177169447 tensor(175.0742)\n",
      "-285.1236794662193 0.0 -285.1236794662193 0.1780201144879282 tensor(176.3286)\n",
      "-285.84530449928945 0.0 -285.84530449928945 0.1956267839023526 tensor(155.9885)\n",
      "-286.18269455153677 0.0 -286.18269455153677 0.20304134682894795 tensor(165.7703)\n",
      "-285.68631223265453 0.0 -285.68631223265453 0.21162406838312944 tensor(173.1717)\n",
      "-285.771364346384 0.0 -285.771364346384 0.23513026087984623 tensor(168.5351)\n",
      "-285.31713457516406 0.0 -285.31713457516406 0.09205607013543603 tensor(185.0386)\n",
      "-285.3653766845781 0.0 -285.3653766845781 0.0710753175323004 tensor(166.2538)\n",
      "-285.2905723614315 0.0 -285.2905723614315 0.15304830221564364 tensor(146.5159)\n",
      "-286.194993757234 0.0 -286.194993757234 0.09924179134503326 tensor(140.5681)\n",
      "-285.59927213349647 0.0 -285.59927213349647 0.13849158519478552 tensor(143.8572)\n",
      "-285.59891436134194 0.0 -285.59891436134194 0.06521984104092854 tensor(156.7595)\n",
      "-285.4790959430529 0.0 -285.4790959430529 0.08939270539171404 tensor(161.1441)\n",
      "-285.7907303176325 0.0 -285.7907303176325 0.2305355311839392 tensor(159.3303)\n",
      "-285.82516958254695 0.0 -285.82516958254695 0.14869992292426606 tensor(160.4531)\n",
      "-285.960931029814 0.0 -285.960931029814 0.0437995913860963 tensor(168.2859)\n",
      "-286.4194444673995 0.0 -286.4194444673995 0.20034135140206283 tensor(164.1387)\n",
      "-285.94514798346074 0.0 -285.94514798346074 0.13872383396382437 tensor(175.2018)\n",
      "-286.32251168264213 0.0 -286.32251168264213 0.03848087795001645 tensor(153.5619)\n",
      "-285.42136722124803 0.0 -285.42136722124803 0.17850418260060957 tensor(205.6805)\n",
      "-285.75944904445754 0.0 -285.75944904445754 0.0513842446806299 tensor(169.3042)\n",
      "-286.03765187765566 0.0 -286.03765187765566 0.026644427522127943 tensor(171.5180)\n",
      "-285.893226269323 0.0 -285.893226269323 0.17379707100369884 tensor(171.0951)\n",
      "-285.57799451698935 0.0 -285.57799451698935 0.22343545947788113 tensor(191.7971)\n",
      "-285.97831641676976 0.0 -285.97831641676976 0.12836732978516927 tensor(160.6582)\n",
      "-285.976227651725 0.0 -285.976227651725 0.1315086287776724 tensor(150.0928)\n",
      "-285.47954380100407 0.0 -285.47954380100407 0.13725988235523898 tensor(149.2705)\n",
      "-285.7372194510653 0.0 -285.7372194510653 0.22963611398460165 tensor(176.6230)\n",
      "-285.7004468420614 0.0 -285.7004468420614 0.18084951748825553 tensor(157.5890)\n",
      "-285.83486832676147 0.0 -285.83486832676147 0.041838767796232516 tensor(174.3954)\n",
      "-285.92130328859713 0.0 -285.92130328859713 0.10114782101150564 tensor(154.7946)\n",
      "-286.07203455042077 0.0 -286.07203455042077 0.024293322666985386 tensor(191.2808)\n",
      "-285.75147052969476 0.0 -285.75147052969476 0.24202431801123864 tensor(177.6644)\n",
      "-285.8471073049054 0.0 -285.8471073049054 0.2018583077196697 tensor(164.8439)\n",
      "-286.5346025128837 0.0 -286.5346025128837 0.14179785842579984 tensor(167.3637)\n",
      "-286.26594642885857 0.0 -286.26594642885857 0.24229393931181253 tensor(155.5533)\n",
      "-286.46954412497007 0.0 -286.46954412497007 0.16740404884957835 tensor(157.0791)\n",
      "-286.1955829134787 0.0 -286.1955829134787 0.1241252157557497 tensor(166.4006)\n",
      "-286.0118338041941 0.0 -286.0118338041941 0.13708992634021855 tensor(203.2334)\n",
      "-285.8520907490885 0.0 -285.8520907490885 0.13551738600689442 tensor(166.1003)\n",
      "-285.2933921472849 0.0 -285.2933921472849 0.236216330869415 tensor(181.9316)\n",
      "-285.50445627492036 0.0 -285.50445627492036 0.08912614334845177 tensor(202.8846)\n",
      "-285.9996268283801 0.0 -285.9996268283801 0.12103188366228283 tensor(185.2486)\n",
      "-286.3301412601631 0.0 -286.3301412601631 0.13456353795881762 tensor(170.2457)\n",
      "-286.14750591520664 0.0 -286.14750591520664 0.03190149422646425 tensor(174.7110)\n",
      "-286.02588765326664 0.0 -286.02588765326664 0.05249145428278859 tensor(161.2350)\n",
      "-285.536589368963 0.0 -285.536589368963 0.2567077051690573 tensor(223.7720)\n",
      "-285.9594782771726 0.0 -285.9594782771726 0.15799818594210793 tensor(202.8918)\n",
      "-285.64003971468264 0.0 -285.64003971468264 0.2400711275459224 tensor(174.7470)\n",
      "-286.4455366786875 0.0 -286.4455366786875 0.08333277784487345 tensor(164.8188)\n",
      "-285.88780823095715 0.0 -285.88780823095715 0.16098871251316452 tensor(185.6120)\n",
      "-285.8289919808017 0.0 -285.8289919808017 0.24177051142076275 tensor(154.5666)\n",
      "-286.3316744815622 0.0 -286.3316744815622 0.06472993476071352 tensor(173.8204)\n",
      "-285.92098997700384 0.0 -285.92098997700384 0.19738540597564722 tensor(163.4354)\n",
      "-286.08232413017555 0.0 -286.08232413017555 0.2121773610853921 tensor(187.3811)\n",
      "-286.3081272575438 0.0 -286.3081272575438 0.1853159004479934 tensor(161.9840)\n",
      "-285.80295934297965 0.0 -285.80295934297965 0.08005205322247858 tensor(182.2111)\n",
      "-286.3197841969146 0.0 -286.3197841969146 0.08261502238083324 tensor(135.4652)\n",
      "-285.8738479639462 0.0 -285.8738479639462 0.17381075075798538 tensor(146.1151)\n",
      "-285.98768762089725 0.0 -285.98768762089725 0.12174536353849716 tensor(172.5823)\n",
      "-286.55975521689845 0.0 -286.55975521689845 0.21983654002942807 tensor(166.0589)\n",
      "-285.9220225161213 0.0 -285.9220225161213 0.18766772418411584 tensor(167.5606)\n",
      "-286.07659879897153 0.0 -286.07659879897153 0.18850989608400381 tensor(181.0600)\n",
      "-286.15439556423405 0.0 -286.15439556423405 0.09019733089259058 tensor(152.5548)\n",
      "-285.7425184634802 0.0 -285.7425184634802 0.2645679241178463 tensor(155.5382)\n",
      "-285.97452982100253 0.0 -285.97452982100253 0.0385485533304728 tensor(182.2066)\n",
      "-285.442681019642 0.0 -285.442681019642 0.0996107188892478 tensor(205.5914)\n",
      "-286.4502022307532 0.0 -286.4502022307532 0.1225395597818686 tensor(209.6046)\n",
      "-285.8741550638289 0.0 -285.8741550638289 0.18067527794623323 tensor(176.3223)\n",
      "-285.633172957895 0.0 -285.633172957895 0.10505634224926688 tensor(170.0886)\n",
      "-286.29825998408256 0.0 -286.29825998408256 0.11071059692263223 tensor(173.9313)\n",
      "-286.3767390940998 0.0 -286.3767390940998 0.2957896614010424 tensor(154.7378)\n",
      "-285.8748773295956 0.0 -285.8748773295956 0.15075267960772915 tensor(199.8584)\n",
      "-286.5401057141874 0.0 -286.5401057141874 0.1719899688337011 tensor(163.6161)\n",
      "-285.6899563612677 0.0 -285.6899563612677 0.13228359304576062 tensor(173.1019)\n",
      "-285.61924434351533 0.0 -285.61924434351533 0.23296359856791202 tensor(155.4756)\n",
      "-286.1689216052399 0.0 -286.1689216052399 0.06991240478156246 tensor(187.4093)\n",
      "-286.46966515329694 0.0 -286.46966515329694 0.2715143102314114 tensor(165.6034)\n",
      "-286.2173028679772 0.0 -286.2173028679772 0.16109965486880284 tensor(140.0564)\n",
      "-286.5079164410247 0.0 -286.5079164410247 0.17137915789133576 tensor(193.0755)\n",
      "-286.36780802193255 0.0 -286.36780802193255 0.15875643250669744 tensor(164.9792)\n",
      "-285.8241610477583 0.0 -285.8241610477583 0.11775348729415556 tensor(175.3829)\n",
      "-286.16674065728046 0.0 -286.16674065728046 0.020939657942264354 tensor(173.2131)\n",
      "-286.35452272681516 0.0 -286.35452272681516 0.17067485404840887 tensor(167.2548)\n",
      "-285.95632021929055 0.0 -285.95632021929055 0.22817950997981032 tensor(185.0857)\n",
      "-286.0976782420314 0.0 -286.0976782420314 0.27414884142187335 tensor(172.3105)\n",
      "-285.9022473386048 0.0 -285.9022473386048 0.18135584811568897 tensor(185.0857)\n",
      "-286.5479033295625 0.0 -286.5479033295625 0.18590415915297373 tensor(158.8732)\n",
      "-286.4339286364057 0.0 -286.4339286364057 0.08786954500251774 tensor(152.5512)\n",
      "-285.8722643214862 0.0 -285.8722643214862 0.09119058925592564 tensor(194.9570)\n",
      "-286.2734946360104 0.0 -286.2734946360104 0.12517089549092505 tensor(177.3496)\n",
      "-285.7866118709935 0.0 -285.7866118709935 0.10672450011149838 tensor(189.8093)\n",
      "== Era 4 | Epoch 0 metrics ==\n",
      "\tloss -285.924\n",
      "\tforce 0\n",
      "\tdkl -285.924\n",
      "\tlogp 84.217\n",
      "\tlogq -201.707\n",
      "\tess 0.144656\n",
      "-286.42959024970764 0.0 -286.42959024970764 0.24351044375963868 tensor(170.9347)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.07403823706 0.0 -286.07403823706 0.12732676696077913 tensor(180.7658)\n",
      "-286.171818284237 0.0 -286.171818284237 0.11671141404654953 tensor(164.3912)\n",
      "-286.32278366467307 0.0 -286.32278366467307 0.06557855207649757 tensor(159.9655)\n",
      "-286.29907929594674 0.0 -286.29907929594674 0.24660392220817695 tensor(178.4996)\n",
      "-286.70345074852213 0.0 -286.70345074852213 0.13025084497793202 tensor(180.4461)\n",
      "-286.229829868461 0.0 -286.229829868461 0.20246256551857741 tensor(171.2551)\n",
      "-286.182029290086 0.0 -286.182029290086 0.15544772488884223 tensor(171.7185)\n",
      "-286.30195926420197 0.0 -286.30195926420197 0.20824601214876662 tensor(164.9257)\n",
      "-286.82556491817616 0.0 -286.82556491817616 0.29026847375309905 tensor(173.1734)\n",
      "-286.4177581006933 0.0 -286.4177581006933 0.10261035785936544 tensor(182.5192)\n",
      "-286.3569199373462 0.0 -286.3569199373462 0.0577708900064954 tensor(164.2266)\n",
      "-286.1784712944642 0.0 -286.1784712944642 0.09900306937592586 tensor(172.7846)\n",
      "-286.4338164251218 0.0 -286.4338164251218 0.09164166897202923 tensor(175.3758)\n",
      "-286.51255808334054 0.0 -286.51255808334054 0.08394243379664575 tensor(184.6040)\n",
      "-286.493386042862 0.0 -286.493386042862 0.15191005068837282 tensor(171.0245)\n",
      "-286.1197153753396 0.0 -286.1197153753396 0.09586047127951422 tensor(221.3763)\n",
      "-286.2728983454558 0.0 -286.2728983454558 0.14550963010605658 tensor(202.0609)\n",
      "-286.6831738102128 0.0 -286.6831738102128 0.12920912775002713 tensor(201.8453)\n",
      "-286.3946246644623 0.0 -286.3946246644623 0.1945971212523816 tensor(164.9536)\n",
      "-286.3604874535939 0.0 -286.3604874535939 0.12965970484920575 tensor(178.8615)\n",
      "-286.367056859151 0.0 -286.367056859151 0.2742197354200798 tensor(155.8174)\n",
      "-286.20462568386716 0.0 -286.20462568386716 0.22485183099804398 tensor(185.4790)\n",
      "-286.1283679176628 0.0 -286.1283679176628 0.08275124585751469 tensor(281.1231)\n",
      "-286.61171097380065 0.0 -286.61171097380065 0.10207747123634948 tensor(173.9787)\n",
      "-286.262605569013 0.0 -286.262605569013 0.07285659243344081 tensor(222.5802)\n",
      "-286.133908367808 0.0 -286.133908367808 0.10001094752432403 tensor(147.5014)\n",
      "-286.3440629633405 0.0 -286.3440629633405 0.2655427345020945 tensor(170.0566)\n",
      "-286.3701797320316 0.0 -286.3701797320316 0.1364192302693023 tensor(191.7171)\n",
      "-286.3499863641968 0.0 -286.3499863641968 0.3042817508929587 tensor(177.0218)\n",
      "-286.43223628244164 0.0 -286.43223628244164 0.14243097979194402 tensor(172.3253)\n",
      "-286.120283559208 0.0 -286.120283559208 0.2492646938619725 tensor(158.2405)\n",
      "-286.1350680453419 0.0 -286.1350680453419 0.18106336223332414 tensor(209.8453)\n",
      "-286.0834476451131 0.0 -286.0834476451131 0.1980709794692767 tensor(193.3350)\n",
      "-286.4808490817836 0.0 -286.4808490817836 0.2064673319252998 tensor(181.6948)\n",
      "-285.8432581551578 0.0 -285.8432581551578 0.229207937101027 tensor(179.3602)\n",
      "-286.7683761952822 0.0 -286.7683761952822 0.05899978045570401 tensor(163.0777)\n",
      "-286.010886684527 0.0 -286.010886684527 0.16985894635770998 tensor(192.0954)\n",
      "-286.2966274324234 0.0 -286.2966274324234 0.16332491835373125 tensor(166.4388)\n",
      "-286.17721796619344 0.0 -286.17721796619344 0.17502150856518056 tensor(187.4265)\n",
      "-286.2757823964341 0.0 -286.2757823964341 0.16013411326177462 tensor(161.2580)\n",
      "-286.38526643810485 0.0 -286.38526643810485 0.29068029604309475 tensor(205.7795)\n",
      "-286.72890831508425 0.0 -286.72890831508425 0.241682386662042 tensor(217.0607)\n",
      "-286.20967234994725 0.0 -286.20967234994725 0.1825648320115576 tensor(163.0453)\n",
      "-286.3417710899305 0.0 -286.3417710899305 0.16533312798726393 tensor(151.1778)\n",
      "-286.3069250376763 0.0 -286.3069250376763 0.09986431235307981 tensor(143.4916)\n",
      "-286.1636828127844 0.0 -286.1636828127844 0.08215698995853707 tensor(176.1274)\n",
      "-286.4737532601949 0.0 -286.4737532601949 0.18105489219838164 tensor(159.3108)\n",
      "-286.71136545753785 0.0 -286.71136545753785 0.17136245122925386 tensor(228.7653)\n",
      "-286.491240677455 0.0 -286.491240677455 0.1305883210941926 tensor(180.9383)\n",
      "-286.3822576660291 0.0 -286.3822576660291 0.18351742045677402 tensor(189.0697)\n",
      "-286.415125191732 0.0 -286.415125191732 0.15125805003095816 tensor(163.2630)\n",
      "-286.7619151824821 0.0 -286.7619151824821 0.2739942248806341 tensor(158.4886)\n",
      "-286.52777884895045 0.0 -286.52777884895045 0.18331230839486923 tensor(174.5121)\n",
      "-285.9495677562033 0.0 -285.9495677562033 0.07384014198336131 tensor(181.3682)\n",
      "-286.38358818637704 0.0 -286.38358818637704 0.1011370607183106 tensor(158.0260)\n",
      "-286.19524658001467 0.0 -286.19524658001467 0.12883759989585158 tensor(176.9169)\n",
      "-286.64552364733737 0.0 -286.64552364733737 0.30285692706737655 tensor(184.4518)\n",
      "-286.7269365252197 0.0 -286.7269365252197 0.035749128891714055 tensor(157.6688)\n",
      "-286.76638036023144 0.0 -286.76638036023144 0.24600875136379516 tensor(155.9466)\n",
      "-286.0743490017146 0.0 -286.0743490017146 0.22247358436410736 tensor(185.2419)\n",
      "-286.76875559730126 0.0 -286.76875559730126 0.19707555163944568 tensor(163.4817)\n",
      "-286.48339966304593 0.0 -286.48339966304593 0.12648303909765798 tensor(153.5934)\n",
      "-286.04819027750204 0.0 -286.04819027750204 0.14572587049129726 tensor(171.2230)\n",
      "-286.504877791515 0.0 -286.504877791515 0.1690994649478698 tensor(155.9793)\n",
      "-286.40930767599826 0.0 -286.40930767599826 0.042361321749478646 tensor(184.4347)\n",
      "-286.4550086984357 0.0 -286.4550086984357 0.21585988580933946 tensor(164.3824)\n",
      "-286.24318174240796 0.0 -286.24318174240796 0.21595584844433632 tensor(190.5562)\n",
      "-286.51721846332714 0.0 -286.51721846332714 0.1323959799138984 tensor(172.8468)\n",
      "-285.94674109784205 0.0 -285.94674109784205 0.148540293439915 tensor(169.3668)\n",
      "-286.7659284988704 0.0 -286.7659284988704 0.13750762184242965 tensor(166.9726)\n",
      "-286.2570264485373 0.0 -286.2570264485373 0.1585518605266343 tensor(182.2817)\n",
      "-286.5313141574364 0.0 -286.5313141574364 0.14406973651102412 tensor(179.6070)\n",
      "-286.48766054855474 0.0 -286.48766054855474 0.20212125908977555 tensor(162.7002)\n",
      "-286.284086846899 0.0 -286.284086846899 0.24052119920063272 tensor(152.6455)\n",
      "-286.2800081722928 0.0 -286.2800081722928 0.18777512806434268 tensor(185.0891)\n",
      "-286.5107029908995 0.0 -286.5107029908995 0.1545593295440362 tensor(230.3852)\n",
      "-286.6711988197857 0.0 -286.6711988197857 0.1415901966524236 tensor(166.9662)\n",
      "-286.53649607713584 0.0 -286.53649607713584 0.13383364922831142 tensor(247.8737)\n",
      "-286.1618468575568 0.0 -286.1618468575568 0.16904615302348744 tensor(189.1767)\n",
      "-286.56434913032433 0.0 -286.56434913032433 0.21586749500057173 tensor(186.4219)\n",
      "-286.32734304434484 0.0 -286.32734304434484 0.2720651700598887 tensor(197.2730)\n",
      "-286.3693871692326 0.0 -286.3693871692326 0.27864863898593406 tensor(194.3047)\n",
      "-286.1476998295683 0.0 -286.1476998295683 0.3046825256893531 tensor(173.2453)\n",
      "-286.49633240404523 0.0 -286.49633240404523 0.24442785278278278 tensor(135.9470)\n",
      "-286.67331473333513 0.0 -286.67331473333513 0.2715268282199136 tensor(184.6945)\n",
      "-286.42480446054736 0.0 -286.42480446054736 0.26856642173670686 tensor(176.1258)\n",
      "-286.6305212773829 0.0 -286.6305212773829 0.1397077622036468 tensor(162.9548)\n",
      "-286.25732262379813 0.0 -286.25732262379813 0.2086851270497122 tensor(165.9216)\n",
      "-286.6079943156986 0.0 -286.6079943156986 0.11301142577246594 tensor(154.4492)\n",
      "-285.6891103529423 0.0 -285.6891103529423 0.3069080186654624 tensor(206.1992)\n",
      "-286.3423568771428 0.0 -286.3423568771428 0.09849810110392221 tensor(158.1010)\n",
      "-286.3373000227905 0.0 -286.3373000227905 0.3317959084119688 tensor(208.6203)\n",
      "-286.06390505558244 0.0 -286.06390505558244 0.056358300984838926 tensor(187.8571)\n",
      "-286.51840885598426 0.0 -286.51840885598426 0.153077247309687 tensor(178.8530)\n",
      "-286.46229994265445 0.0 -286.46229994265445 0.2959265342200026 tensor(170.6431)\n",
      "-286.81288220856896 0.0 -286.81288220856896 0.26257041906972434 tensor(177.0776)\n",
      "-286.4007356197823 0.0 -286.4007356197823 0.18434493471191854 tensor(163.2859)\n",
      "-286.588656766409 0.0 -286.588656766409 0.2987695923701348 tensor(172.5751)\n",
      "-286.74933526563404 0.0 -286.74933526563404 0.2334013111808512 tensor(171.6258)\n",
      "== Era 5 | Epoch 0 metrics ==\n",
      "\tloss -286.381\n",
      "\tforce 0\n",
      "\tdkl -286.381\n",
      "\tlogp 85.1085\n",
      "\tlogq -201.273\n",
      "\tess 0.176152\n",
      "-286.4694728347718 0.0 -286.4694728347718 0.06487870408447859 tensor(233.4533)\n",
      "-286.5149657154851 0.0 -286.5149657154851 0.29568363798753716 tensor(194.0043)\n",
      "-286.1856827793242 0.0 -286.1856827793242 0.12268512047212843 tensor(184.5077)\n",
      "-286.28570242517947 0.0 -286.28570242517947 0.10894453087450183 tensor(209.0626)\n",
      "-287.00146464670945 0.0 -287.00146464670945 0.14513892668375458 tensor(238.8169)\n",
      "-286.3977406892271 0.0 -286.3977406892271 0.1537423283279416 tensor(191.8957)\n",
      "-286.8200868343564 0.0 -286.8200868343564 0.11441787362097287 tensor(222.3287)\n",
      "-286.929929082762 0.0 -286.929929082762 0.06636762698992005 tensor(167.1097)\n",
      "-286.5381218721752 0.0 -286.5381218721752 0.21287292225453622 tensor(259.0772)\n",
      "-286.103048767477 0.0 -286.103048767477 0.14757232188435337 tensor(177.4414)\n",
      "-286.79881426929114 0.0 -286.79881426929114 0.199257622102214 tensor(175.7745)\n",
      "-286.88955565189116 0.0 -286.88955565189116 0.20663419603975863 tensor(212.8828)\n",
      "-286.734369382976 0.0 -286.734369382976 0.23961185994760767 tensor(198.8368)\n",
      "-286.3219745816764 0.0 -286.3219745816764 0.14143779852464114 tensor(222.2222)\n",
      "-286.2504391436628 0.0 -286.2504391436628 0.14604459521020666 tensor(155.7067)\n",
      "-286.8081381263945 0.0 -286.8081381263945 0.2522846437402769 tensor(207.6366)\n",
      "-286.71185388720403 0.0 -286.71185388720403 0.1000808176349796 tensor(187.6564)\n",
      "-286.7248982663929 0.0 -286.7248982663929 0.24895956848184597 tensor(175.3379)\n",
      "-286.2574371719121 0.0 -286.2574371719121 0.22832200771582575 tensor(182.6109)\n",
      "-286.7081255019908 0.0 -286.7081255019908 0.1235420632753882 tensor(155.5527)\n",
      "-287.02429185488734 0.0 -287.02429185488734 0.20749112975225562 tensor(183.9654)\n",
      "-286.76053329233866 0.0 -286.76053329233866 0.1874516735950512 tensor(158.8124)\n",
      "-286.1704688245949 0.0 -286.1704688245949 0.3208952781382001 tensor(226.3543)\n",
      "-286.58821270302894 0.0 -286.58821270302894 0.10410378392468074 tensor(154.4433)\n",
      "-286.71172426552005 0.0 -286.71172426552005 0.058870542008590494 tensor(197.1583)\n",
      "-287.0180851086458 0.0 -287.0180851086458 0.14303277386475802 tensor(183.5023)\n",
      "-286.69876849648006 0.0 -286.69876849648006 0.06128725822020581 tensor(166.1700)\n",
      "-286.4852861281904 0.0 -286.4852861281904 0.08404510498443295 tensor(206.7670)\n",
      "-286.82803379649306 0.0 -286.82803379649306 0.10290575137790993 tensor(221.7487)\n",
      "-286.68425852082373 0.0 -286.68425852082373 0.21024849879314042 tensor(149.8141)\n",
      "-286.27803629628266 0.0 -286.27803629628266 0.1744455116149397 tensor(174.8035)\n",
      "-286.55727796997223 0.0 -286.55727796997223 0.38354634124294085 tensor(179.0352)\n",
      "-286.64753322560745 0.0 -286.64753322560745 0.18789436337374985 tensor(170.0627)\n",
      "-287.26555914346426 0.0 -287.26555914346426 0.11634278278328793 tensor(181.3099)\n",
      "-286.5768805473451 0.0 -286.5768805473451 0.16344975453705038 tensor(153.4133)\n",
      "-286.5284512019823 0.0 -286.5284512019823 0.2861572945479249 tensor(169.6821)\n",
      "-286.4155612380258 0.0 -286.4155612380258 0.21209274175715523 tensor(176.9616)\n",
      "-286.78766257791534 0.0 -286.78766257791534 0.22988717524168423 tensor(200.1625)\n",
      "-286.5152617935748 0.0 -286.5152617935748 0.1901851951481394 tensor(176.7538)\n",
      "-286.35271339864204 0.0 -286.35271339864204 0.0817979253191999 tensor(184.3849)\n",
      "-286.9216427437259 0.0 -286.9216427437259 0.2481555819094294 tensor(177.7186)\n",
      "-286.5355535742531 0.0 -286.5355535742531 0.15126096575096573 tensor(220.5007)\n",
      "-286.04394912389307 0.0 -286.04394912389307 0.2917677887896905 tensor(209.4176)\n",
      "-286.3549369299672 0.0 -286.3549369299672 0.20868204945321242 tensor(243.2676)\n",
      "-286.3318349445217 0.0 -286.3318349445217 0.15151229917760775 tensor(192.7315)\n",
      "-286.5680532926812 0.0 -286.5680532926812 0.30480530573802417 tensor(156.6109)\n",
      "-286.5783845815589 0.0 -286.5783845815589 0.17918392297289404 tensor(165.7022)\n",
      "-286.6687063598261 0.0 -286.6687063598261 0.32558083963166495 tensor(267.9098)\n",
      "-286.65636602480413 0.0 -286.65636602480413 0.11479358468905579 tensor(187.0022)\n",
      "-286.61495328872513 0.0 -286.61495328872513 0.17581434091328735 tensor(239.4020)\n",
      "-286.3797728265412 0.0 -286.3797728265412 0.23107990451725072 tensor(167.0402)\n",
      "-286.7254030616142 0.0 -286.7254030616142 0.15484462944438693 tensor(230.5324)\n",
      "-286.2337514481955 0.0 -286.2337514481955 0.06162492953855451 tensor(200.0953)\n",
      "-286.28784140918737 0.0 -286.28784140918737 0.18309349412599046 tensor(176.0887)\n",
      "-286.32500640661243 0.0 -286.32500640661243 0.1816310008187277 tensor(195.9829)\n",
      "-286.3737273666836 0.0 -286.3737273666836 0.16577210501729683 tensor(252.9528)\n",
      "-286.6722872977839 0.0 -286.6722872977839 0.3095374170484726 tensor(243.4074)\n",
      "-286.19620047310946 0.0 -286.19620047310946 0.18296378042074393 tensor(172.7544)\n",
      "-286.76976681444376 0.0 -286.76976681444376 0.15133248620566267 tensor(189.4724)\n",
      "-286.59132540353903 0.0 -286.59132540353903 0.23917472886085678 tensor(200.3641)\n",
      "-286.8171317100902 0.0 -286.8171317100902 0.17891717650641994 tensor(197.6193)\n",
      "-286.14476542189084 0.0 -286.14476542189084 0.3048066545297609 tensor(180.5477)\n",
      "-286.2681119709067 0.0 -286.2681119709067 0.23083953040015726 tensor(220.7432)\n",
      "-286.6228704485872 0.0 -286.6228704485872 0.2178223920394307 tensor(324.4716)\n",
      "-286.5198965295881 0.0 -286.5198965295881 0.18534961264648234 tensor(182.7521)\n",
      "-286.8695591128519 0.0 -286.8695591128519 0.026826299319011447 tensor(153.9097)\n",
      "-286.8899283169988 0.0 -286.8899283169988 0.29757876157053986 tensor(183.4833)\n",
      "-286.4178567244386 0.0 -286.4178567244386 0.09804426501507263 tensor(154.8524)\n",
      "-286.82715687391357 0.0 -286.82715687391357 0.10369779241549322 tensor(155.6991)\n",
      "-286.6171198899917 0.0 -286.6171198899917 0.131678710592399 tensor(186.0081)\n",
      "-286.837796720379 0.0 -286.837796720379 0.07999511130667064 tensor(177.0422)\n",
      "-286.419893698132 0.0 -286.419893698132 0.2103592864136153 tensor(195.7338)\n",
      "-286.73447518310115 0.0 -286.73447518310115 0.30729915167855465 tensor(166.8233)\n",
      "-286.37719390485273 0.0 -286.37719390485273 0.16197827072936333 tensor(215.9955)\n",
      "-286.3667771868453 0.0 -286.3667771868453 0.21811714825348943 tensor(202.8112)\n",
      "-286.402454037615 0.0 -286.402454037615 0.14965668500072984 tensor(241.9607)\n",
      "-286.88422699184827 0.0 -286.88422699184827 0.22479366182310143 tensor(160.6115)\n",
      "-286.5886329236446 0.0 -286.5886329236446 0.20018198502355533 tensor(235.6666)\n",
      "-286.59170778687223 0.0 -286.59170778687223 0.3126736510663328 tensor(202.0222)\n",
      "-286.5990810877961 0.0 -286.5990810877961 0.3934638707681493 tensor(164.6092)\n",
      "-286.17745379695816 0.0 -286.17745379695816 0.10444206168087 tensor(174.6839)\n",
      "-286.8953880748324 0.0 -286.8953880748324 0.0917593102687335 tensor(148.5917)\n",
      "-286.4440845432545 0.0 -286.4440845432545 0.24286855806754298 tensor(221.4481)\n",
      "-286.71139822678896 0.0 -286.71139822678896 0.16081735819704523 tensor(198.2297)\n",
      "-286.74605973781604 0.0 -286.74605973781604 0.1755405276391546 tensor(431.1631)\n",
      "-286.2740859501182 0.0 -286.2740859501182 0.1197427889617042 tensor(172.8775)\n",
      "-286.5909043353223 0.0 -286.5909043353223 0.11723801093679644 tensor(210.9138)\n",
      "-286.40423469439946 0.0 -286.40423469439946 0.1880559732868107 tensor(209.6004)\n",
      "-286.45714771793257 0.0 -286.45714771793257 0.2140544705166064 tensor(169.5390)\n",
      "-286.90682964951276 0.0 -286.90682964951276 0.24842130407978716 tensor(153.4132)\n",
      "-286.5380180918618 0.0 -286.5380180918618 0.21356970153348867 tensor(196.4168)\n",
      "-286.6485399602511 0.0 -286.6485399602511 0.15280591588419484 tensor(200.8963)\n",
      "-286.90723113146527 0.0 -286.90723113146527 0.12424519967917026 tensor(225.1027)\n",
      "-286.5708324888101 0.0 -286.5708324888101 0.3359013226806081 tensor(168.0175)\n",
      "-286.4510063886478 0.0 -286.4510063886478 0.07789495270386297 tensor(142.6255)\n",
      "-286.57961599968297 0.0 -286.57961599968297 0.17513324983966172 tensor(161.6243)\n",
      "-286.731106877556 0.0 -286.731106877556 0.1133908536792638 tensor(193.6215)\n",
      "-286.73955385670456 0.0 -286.73955385670456 0.25724075361504717 tensor(199.9445)\n",
      "-286.9150497858104 0.0 -286.9150497858104 0.24097412998356546 tensor(165.8817)\n",
      "-286.97680450671965 0.0 -286.97680450671965 0.3518596343327221 tensor(175.6196)\n",
      "== Era 6 | Epoch 0 metrics ==\n",
      "\tloss -286.586\n",
      "\tforce 0\n",
      "\tdkl -286.586\n",
      "\tlogp 85.4844\n",
      "\tlogq -201.102\n",
      "\tess 0.185773\n",
      "-286.21250074075976 0.0 -286.21250074075976 0.11219675031864769 tensor(198.8597)\n",
      "-286.70537562320504 0.0 -286.70537562320504 0.2723606731309523 tensor(226.5222)\n",
      "-286.7561447655562 0.0 -286.7561447655562 0.0560480848451888 tensor(182.7325)\n",
      "-286.65105320097274 0.0 -286.65105320097274 0.06796693627514053 tensor(222.1213)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.8060090744058 0.0 -286.8060090744058 0.2206663872752518 tensor(205.1283)\n",
      "-286.83962092058255 0.0 -286.83962092058255 0.04996853536265053 tensor(330.5075)\n",
      "-286.5782347705788 0.0 -286.5782347705788 0.25769687839519223 tensor(173.5427)\n",
      "-286.43768491517295 0.0 -286.43768491517295 0.24694264303141616 tensor(202.9833)\n",
      "-285.99569953934156 0.0 -285.99569953934156 0.0933217723408387 tensor(196.0997)\n",
      "-286.8836865054619 0.0 -286.8836865054619 0.32105523564432786 tensor(172.0458)\n",
      "-286.92523266636414 0.0 -286.92523266636414 0.11408531772523961 tensor(236.2626)\n",
      "-286.37424945860846 0.0 -286.37424945860846 0.2763150618731418 tensor(187.5516)\n",
      "-286.87764579347015 0.0 -286.87764579347015 0.33560313755030724 tensor(196.6000)\n",
      "-286.6968894822108 0.0 -286.6968894822108 0.18031224420547132 tensor(187.4605)\n",
      "-286.52879833557733 0.0 -286.52879833557733 0.20499660157025143 tensor(196.2932)\n",
      "-286.2364603749641 0.0 -286.2364603749641 0.11616869499488437 tensor(197.9263)\n",
      "-286.1971812829619 0.0 -286.1971812829619 0.11281680078900248 tensor(253.9944)\n",
      "-287.03140349859484 0.0 -287.03140349859484 0.08090413256242644 tensor(195.7731)\n",
      "-286.32109875841445 0.0 -286.32109875841445 0.2542890517021588 tensor(172.7984)\n",
      "-286.57756805611217 0.0 -286.57756805611217 0.23256130869409897 tensor(189.0569)\n",
      "-286.5379995400149 0.0 -286.5379995400149 0.05962103904941826 tensor(224.7548)\n",
      "-286.85048280684777 0.0 -286.85048280684777 0.07016776682086155 tensor(265.4736)\n",
      "-286.82021463655735 0.0 -286.82021463655735 0.2534130779936704 tensor(286.0133)\n",
      "-286.6823554656421 0.0 -286.6823554656421 0.18071700204259175 tensor(179.6245)\n",
      "-286.3014864088636 0.0 -286.3014864088636 0.21088593644674913 tensor(207.0568)\n",
      "-286.61409216088737 0.0 -286.61409216088737 0.1404089722843349 tensor(298.1316)\n",
      "-286.8067406550573 0.0 -286.8067406550573 0.12410621005357503 tensor(165.5810)\n",
      "-286.7354118106314 0.0 -286.7354118106314 0.1686600077874285 tensor(194.4968)\n",
      "-286.6320644445185 0.0 -286.6320644445185 0.23531877225951892 tensor(219.1722)\n",
      "-286.65158472360145 0.0 -286.65158472360145 0.2267386626337235 tensor(183.4204)\n",
      "-286.4291491290884 0.0 -286.4291491290884 0.3283966875556232 tensor(170.0605)\n",
      "-286.42086948493665 0.0 -286.42086948493665 0.2797013243479008 tensor(170.6312)\n",
      "-286.94023718019673 0.0 -286.94023718019673 0.27481976783007767 tensor(197.9816)\n",
      "-286.874611806211 0.0 -286.874611806211 0.3208634124495904 tensor(188.4059)\n",
      "-286.78406838501655 0.0 -286.78406838501655 0.15092152232816836 tensor(159.1613)\n",
      "-286.75631546194865 0.0 -286.75631546194865 0.09215714698100624 tensor(210.1781)\n",
      "-286.65002653297756 0.0 -286.65002653297756 0.26324548297420475 tensor(152.1128)\n",
      "-286.8302987214715 0.0 -286.8302987214715 0.26774509870070734 tensor(225.3008)\n",
      "-286.3873041312824 0.0 -286.3873041312824 0.1009531483023244 tensor(259.9835)\n",
      "-286.60137795884015 0.0 -286.60137795884015 0.265703578130609 tensor(185.9333)\n",
      "-286.4547088736805 0.0 -286.4547088736805 0.3386978102183731 tensor(186.2503)\n",
      "-286.51877660341813 0.0 -286.51877660341813 0.1551827983169664 tensor(200.1459)\n",
      "-286.587254725308 0.0 -286.587254725308 0.14145287504619403 tensor(189.6405)\n",
      "-286.8781468336989 0.0 -286.8781468336989 0.4118393086787081 tensor(196.1777)\n",
      "-286.57918126775746 0.0 -286.57918126775746 0.21737550320361612 tensor(260.5416)\n",
      "-286.62783131934066 0.0 -286.62783131934066 0.10990701244817916 tensor(162.8724)\n",
      "-286.5315313198096 0.0 -286.5315313198096 0.2652145012752678 tensor(192.0947)\n",
      "-286.74449003616127 0.0 -286.74449003616127 0.18283688883428886 tensor(188.3583)\n",
      "-286.55970024028096 0.0 -286.55970024028096 0.19898318883701394 tensor(194.2814)\n",
      "-286.61158739675164 0.0 -286.61158739675164 0.30862845686149 tensor(206.4952)\n",
      "-286.3609084253845 0.0 -286.3609084253845 0.16085720544560198 tensor(158.3239)\n",
      "-286.7881321541438 0.0 -286.7881321541438 0.13951531216782648 tensor(204.5644)\n",
      "-286.72173177458706 0.0 -286.72173177458706 0.1978859675720647 tensor(215.1988)\n",
      "-286.4439397065126 0.0 -286.4439397065126 0.061688765249324214 tensor(157.8472)\n",
      "-286.75039045018747 0.0 -286.75039045018747 0.32582701146353976 tensor(216.7427)\n",
      "-286.4095075144527 0.0 -286.4095075144527 0.24790750978256007 tensor(201.4481)\n",
      "-286.64946587860203 0.0 -286.64946587860203 0.28402136912197395 tensor(176.2442)\n",
      "-286.5465234198498 0.0 -286.5465234198498 0.3415103319911899 tensor(189.6886)\n",
      "-286.6230181138209 0.0 -286.6230181138209 0.12009370444277695 tensor(255.1559)\n",
      "-286.7756121438698 0.0 -286.7756121438698 0.31171061671290595 tensor(187.5637)\n",
      "-286.5347061895525 0.0 -286.5347061895525 0.2762524816301678 tensor(236.8673)\n",
      "-286.7141416387557 0.0 -286.7141416387557 0.2845596447355782 tensor(175.9644)\n",
      "-286.5438956544681 0.0 -286.5438956544681 0.18547856727007203 tensor(206.2545)\n",
      "-286.93453449144465 0.0 -286.93453449144465 0.37416354481150127 tensor(183.7536)\n",
      "-286.6980995672196 0.0 -286.6980995672196 0.22474510793564698 tensor(209.6134)\n",
      "-286.8429663114023 0.0 -286.8429663114023 0.2714463628381141 tensor(217.8321)\n",
      "-286.53709372878444 0.0 -286.53709372878444 0.308523391687386 tensor(189.3444)\n",
      "-286.6800966747372 0.0 -286.6800966747372 0.20119102635735492 tensor(234.4154)\n",
      "-286.45740112306305 0.0 -286.45740112306305 0.33738029837844447 tensor(227.5017)\n",
      "-286.2390909197527 0.0 -286.2390909197527 0.40979360999103553 tensor(213.2989)\n",
      "-286.5689545754424 0.0 -286.5689545754424 0.19375412643832463 tensor(231.6699)\n",
      "-286.55644640795344 0.0 -286.55644640795344 0.11978521267951889 tensor(273.8735)\n",
      "-286.8444426297499 0.0 -286.8444426297499 0.35134164095258635 tensor(197.0018)\n",
      "-286.6871411903393 0.0 -286.6871411903393 0.23437064785816378 tensor(176.7974)\n",
      "-286.7898819688658 0.0 -286.7898819688658 0.2947477867357875 tensor(186.0446)\n",
      "-286.8371535183753 0.0 -286.8371535183753 0.2404242323057376 tensor(219.5482)\n",
      "-287.18655773005617 0.0 -287.18655773005617 0.17750979696210273 tensor(172.1310)\n",
      "-286.9248734205265 0.0 -286.9248734205265 0.26292304179868026 tensor(180.7304)\n",
      "-286.4071763537755 0.0 -286.4071763537755 0.05419650227058297 tensor(197.8670)\n",
      "-286.51948077891007 0.0 -286.51948077891007 0.206765266447738 tensor(231.6628)\n",
      "-286.67415415326934 0.0 -286.67415415326934 0.28565741938539074 tensor(201.4678)\n",
      "-286.9066708566553 0.0 -286.9066708566553 0.24523839660724375 tensor(153.4733)\n",
      "-286.8271111906662 0.0 -286.8271111906662 0.08316911209300556 tensor(186.9260)\n",
      "-286.5733417586416 0.0 -286.5733417586416 0.17450341491589913 tensor(195.1013)\n",
      "-286.4163505141276 0.0 -286.4163505141276 0.2217066377092084 tensor(221.7617)\n",
      "-286.88251217093836 0.0 -286.88251217093836 0.11497636768684023 tensor(228.2464)\n",
      "-286.65238756498763 0.0 -286.65238756498763 0.17297810625208512 tensor(217.2299)\n",
      "-286.58997800645557 0.0 -286.58997800645557 0.15763569961462603 tensor(175.4449)\n",
      "-286.64807035928504 0.0 -286.64807035928504 0.37678054180679776 tensor(184.9833)\n",
      "-286.5997516975844 0.0 -286.5997516975844 0.18625613381440026 tensor(181.8282)\n",
      "-287.1211981516142 0.0 -287.1211981516142 0.19181562913691544 tensor(190.5649)\n",
      "-286.63601222726925 0.0 -286.63601222726925 0.23066423856132656 tensor(217.6608)\n",
      "-286.94841770685076 0.0 -286.94841770685076 0.25614967316960696 tensor(302.1397)\n",
      "-286.6396593870535 0.0 -286.6396593870535 0.32534296774960086 tensor(193.6499)\n",
      "-286.6237220727312 0.0 -286.6237220727312 0.1669630528777166 tensor(197.4364)\n",
      "-287.21057230400334 0.0 -287.21057230400334 0.2819350179364177 tensor(149.8249)\n",
      "-286.95499275819736 0.0 -286.95499275819736 0.27610153442130014 tensor(221.5961)\n",
      "-286.84838890673234 0.0 -286.84838890673234 0.30223234826286166 tensor(189.3013)\n",
      "-286.92717279047304 0.0 -286.92717279047304 0.2419564674612467 tensor(232.9252)\n",
      "-287.1145196453439 0.0 -287.1145196453439 0.17531825288466413 tensor(220.5177)\n",
      "== Era 7 | Epoch 0 metrics ==\n",
      "\tloss -286.664\n",
      "\tforce 0\n",
      "\tdkl -286.664\n",
      "\tlogp 85.9265\n",
      "\tlogq -200.738\n",
      "\tess 0.216187\n",
      "-286.70513880126555 0.0 -286.70513880126555 0.2352166315362018 tensor(237.0978)\n",
      "-286.4789558811958 0.0 -286.4789558811958 0.253686572849175 tensor(270.9518)\n",
      "-286.736989692184 0.0 -286.736989692184 0.2730430264615588 tensor(174.3351)\n",
      "-286.8733488622632 0.0 -286.8733488622632 0.22467091934483885 tensor(175.4950)\n",
      "-287.2029060834945 0.0 -287.2029060834945 0.13368012927298975 tensor(188.1281)\n",
      "-286.77118694600216 0.0 -286.77118694600216 0.20046328114133033 tensor(192.3367)\n",
      "-286.5221392941307 0.0 -286.5221392941307 0.08702627368529686 tensor(189.5470)\n",
      "-286.9623171351077 0.0 -286.9623171351077 0.37582323830203085 tensor(202.0211)\n",
      "-286.84108251491807 0.0 -286.84108251491807 0.24718255831254418 tensor(230.7164)\n",
      "-286.604102476709 0.0 -286.604102476709 0.13268130990254404 tensor(252.8802)\n",
      "-286.6702816403489 0.0 -286.6702816403489 0.2517896204584837 tensor(188.4514)\n",
      "-286.7004425736875 0.0 -286.7004425736875 0.34719714877881663 tensor(223.4796)\n",
      "-286.8711986040131 0.0 -286.8711986040131 0.40485413913850227 tensor(187.8317)\n",
      "-286.8299634787564 0.0 -286.8299634787564 0.28979731371972095 tensor(158.2216)\n",
      "-286.55235296859394 0.0 -286.55235296859394 0.22450674080286448 tensor(182.5440)\n",
      "-286.9383777944495 0.0 -286.9383777944495 0.14169723742096135 tensor(294.9708)\n",
      "-286.9684538386009 0.0 -286.9684538386009 0.17480712100825366 tensor(227.0379)\n",
      "-287.10364714722994 0.0 -287.10364714722994 0.3219480813222316 tensor(218.9350)\n",
      "-286.3359467949706 0.0 -286.3359467949706 0.24192874184275107 tensor(239.8630)\n",
      "-286.43046334760226 0.0 -286.43046334760226 0.26013600088311073 tensor(164.4965)\n",
      "-287.0470474603902 0.0 -287.0470474603902 0.10200957294708328 tensor(258.0757)\n",
      "-286.66784809120213 0.0 -286.66784809120213 0.230745163730348 tensor(212.6293)\n",
      "-286.8493135687596 0.0 -286.8493135687596 0.18805845039685917 tensor(256.1381)\n",
      "-286.6703933462766 0.0 -286.6703933462766 0.3784373531021115 tensor(181.2495)\n",
      "-287.34404080729627 0.0 -287.34404080729627 0.33418803458859686 tensor(248.0219)\n",
      "-286.9730543080519 0.0 -286.9730543080519 0.0972320699981878 tensor(219.5661)\n",
      "-287.11926170496633 0.0 -287.11926170496633 0.037867968956118804 tensor(163.9277)\n",
      "-286.504067431117 0.0 -286.504067431117 0.08367084848552933 tensor(182.6562)\n",
      "-286.7966262941543 0.0 -286.7966262941543 0.15161479203122274 tensor(239.9577)\n",
      "-286.60233031131355 0.0 -286.60233031131355 0.28329571744335774 tensor(182.3947)\n",
      "-286.7360309830778 0.0 -286.7360309830778 0.27021998161238064 tensor(311.0605)\n",
      "-287.14057668690634 0.0 -287.14057668690634 0.32276282392776556 tensor(169.4161)\n",
      "-286.85441162662516 0.0 -286.85441162662516 0.16195593316994228 tensor(204.6041)\n",
      "-286.7807049455327 0.0 -286.7807049455327 0.4331316218109552 tensor(230.9345)\n",
      "-286.8231590891573 0.0 -286.8231590891573 0.1443838557097427 tensor(212.2710)\n",
      "-286.8618212978217 0.0 -286.8618212978217 0.2091272357360129 tensor(213.4457)\n",
      "-286.81854587175394 0.0 -286.81854587175394 0.10537412992200039 tensor(223.4185)\n",
      "-286.69988761858883 0.0 -286.69988761858883 0.14422200522491227 tensor(205.0845)\n",
      "-286.68137174138405 0.0 -286.68137174138405 0.27643763471774463 tensor(226.8088)\n",
      "-286.3391494593908 0.0 -286.3391494593908 0.2964636929113884 tensor(206.0122)\n",
      "-286.30205583154657 0.0 -286.30205583154657 0.18357457781275438 tensor(203.4544)\n",
      "-286.99359254417277 0.0 -286.99359254417277 0.16315852078905813 tensor(174.6064)\n",
      "-286.9215118856382 0.0 -286.9215118856382 0.2082880409060645 tensor(192.1810)\n",
      "-286.83628942559494 0.0 -286.83628942559494 0.16277935965057727 tensor(163.3614)\n",
      "-286.7657088800286 0.0 -286.7657088800286 0.34890459928994694 tensor(257.2118)\n",
      "-286.83683104868436 0.0 -286.83683104868436 0.20118115416346938 tensor(245.8114)\n",
      "-286.81574320783113 0.0 -286.81574320783113 0.0735215596826632 tensor(168.5242)\n",
      "-286.882815522824 0.0 -286.882815522824 0.27986205378906254 tensor(186.7163)\n",
      "-286.52562757416837 0.0 -286.52562757416837 0.27994253749730347 tensor(346.4404)\n",
      "-286.8524915249967 0.0 -286.8524915249967 0.2970260790468597 tensor(181.0872)\n",
      "-286.5532627013491 0.0 -286.5532627013491 0.23269713554770768 tensor(265.3318)\n",
      "-286.6821983194946 0.0 -286.6821983194946 0.33367690044373494 tensor(192.4773)\n",
      "-287.12337960460104 0.0 -287.12337960460104 0.2513122476764446 tensor(200.4742)\n",
      "-286.6965409842026 0.0 -286.6965409842026 0.17638951644690357 tensor(290.3623)\n",
      "-286.80048450742174 0.0 -286.80048450742174 0.2553458096865669 tensor(202.1466)\n",
      "-286.81978726150754 0.0 -286.81978726150754 0.26083400420443603 tensor(246.7216)\n",
      "-286.72636517241887 0.0 -286.72636517241887 0.3564959538045955 tensor(198.9778)\n",
      "-286.6681826733603 0.0 -286.6681826733603 0.3845134774523287 tensor(282.2919)\n",
      "-287.08708970950084 0.0 -287.08708970950084 0.2357682216778548 tensor(161.6968)\n",
      "-286.57122233843364 0.0 -286.57122233843364 0.23489210903592805 tensor(196.4079)\n",
      "-287.02110008830795 0.0 -287.02110008830795 0.24430585960008772 tensor(253.7528)\n",
      "-286.65552210848483 0.0 -286.65552210848483 0.33483576171914076 tensor(209.3699)\n",
      "-286.62498462773016 0.0 -286.62498462773016 0.37497877173939126 tensor(184.1714)\n",
      "-286.6219699833204 0.0 -286.6219699833204 0.25438232068758304 tensor(164.8618)\n",
      "-286.8822517125076 0.0 -286.8822517125076 0.19541684855148325 tensor(190.4251)\n",
      "-286.8237371169861 0.0 -286.8237371169861 0.15904285360999107 tensor(168.8499)\n",
      "-286.48374308784304 0.0 -286.48374308784304 0.09737562911777753 tensor(179.8982)\n",
      "-286.76097497362707 0.0 -286.76097497362707 0.1717390643693621 tensor(398.6565)\n",
      "-286.57726243633897 0.0 -286.57726243633897 0.20241397937968375 tensor(194.5711)\n",
      "-286.78519239151615 0.0 -286.78519239151615 0.15260892390105094 tensor(176.0159)\n",
      "-286.52980133937643 0.0 -286.52980133937643 0.19119088254034797 tensor(190.7238)\n",
      "-287.2876153488791 0.0 -287.2876153488791 0.2457139272764612 tensor(160.6907)\n",
      "-286.9387111443202 0.0 -286.9387111443202 0.2908193241046282 tensor(219.8349)\n",
      "-286.8739825549926 0.0 -286.8739825549926 0.20284721342719075 tensor(213.0116)\n",
      "-287.1731475449297 0.0 -287.1731475449297 0.31327564180375284 tensor(200.5578)\n",
      "-286.66898562734684 0.0 -286.66898562734684 0.1855940463863101 tensor(217.5780)\n",
      "-286.9942308683127 0.0 -286.9942308683127 0.2273374327087548 tensor(214.5769)\n",
      "-287.05974462050995 0.0 -287.05974462050995 0.1948294889673504 tensor(224.0193)\n",
      "-286.97862455593105 0.0 -286.97862455593105 0.19045447828388806 tensor(188.1883)\n",
      "-286.8548232758915 0.0 -286.8548232758915 0.250545964960991 tensor(255.4195)\n",
      "-286.8621418919855 0.0 -286.8621418919855 0.1632481232142598 tensor(165.2504)\n",
      "-286.76105617977413 0.0 -286.76105617977413 0.12892691916058013 tensor(315.5487)\n",
      "-286.78624775966614 0.0 -286.78624775966614 0.3280032617050308 tensor(217.8768)\n",
      "-287.2362047782884 0.0 -287.2362047782884 0.17257161696302528 tensor(220.9687)\n",
      "-286.50203303687783 0.0 -286.50203303687783 0.25733713781767953 tensor(160.2375)\n",
      "-287.004942082596 0.0 -287.004942082596 0.28996086228779394 tensor(244.7921)\n",
      "-286.50004647304013 0.0 -286.50004647304013 0.13120939172669763 tensor(174.8870)\n",
      "-286.91299442748635 0.0 -286.91299442748635 0.3403329719574542 tensor(258.6882)\n",
      "-286.6809992293248 0.0 -286.6809992293248 0.180045025247429 tensor(241.4309)\n",
      "-286.90955176280255 0.0 -286.90955176280255 0.14352486738910888 tensor(189.8441)\n",
      "-287.09389265616255 0.0 -287.09389265616255 0.3443324806271347 tensor(203.3415)\n",
      "-286.9114267442315 0.0 -286.9114267442315 0.26161316388942474 tensor(168.1276)\n",
      "-286.5452854243273 0.0 -286.5452854243273 0.12126739283073966 tensor(236.3770)\n",
      "-286.99271297180337 0.0 -286.99271297180337 0.23634779298215897 tensor(252.0379)\n",
      "-287.07764758506846 0.0 -287.07764758506846 0.1679096605221765 tensor(236.9557)\n",
      "-286.9534121656824 0.0 -286.9534121656824 0.1354861260862616 tensor(182.5848)\n",
      "-287.20704491694846 0.0 -287.20704491694846 0.3861090987106821 tensor(342.6812)\n",
      "-286.6808385295459 0.0 -286.6808385295459 0.13407582397329892 tensor(213.5588)\n",
      "-286.7243294668656 0.0 -286.7243294668656 0.13632083901218175 tensor(192.3810)\n",
      "-286.56696483060193 0.0 -286.56696483060193 0.29772786987417893 tensor(204.9266)\n",
      "== Era 8 | Epoch 0 metrics ==\n",
      "\tloss -286.804\n",
      "\tforce 0\n",
      "\tdkl -286.804\n",
      "\tlogp 86.2392\n",
      "\tlogq -200.565\n",
      "\tess 0.228296\n",
      "-287.0531980628874 0.0 -287.0531980628874 0.10155563951294265 tensor(160.9061)\n",
      "-286.8481836351814 0.0 -286.8481836351814 0.2632914730455973 tensor(214.7669)\n",
      "-286.5982983498419 0.0 -286.5982983498419 0.08168233400022003 tensor(210.0193)\n",
      "-286.80657024883163 0.0 -286.80657024883163 0.21434508464863186 tensor(202.3975)\n",
      "-286.83361594190484 0.0 -286.83361594190484 0.1907703552498139 tensor(257.5079)\n",
      "-286.8886560850344 0.0 -286.8886560850344 0.20590849539950956 tensor(219.6310)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.7255404396324 0.0 -286.7255404396324 0.19201121471792307 tensor(196.1057)\n",
      "-287.095822172987 0.0 -287.095822172987 0.39830166341459383 tensor(269.2700)\n",
      "-286.7159158974782 0.0 -286.7159158974782 0.2398544135059376 tensor(147.8612)\n",
      "-286.7530398847164 0.0 -286.7530398847164 0.2174537179489148 tensor(221.9993)\n",
      "-287.1781980115127 0.0 -287.1781980115127 0.35783872935491234 tensor(205.1628)\n",
      "-286.6681289032741 0.0 -286.6681289032741 0.29862014031078504 tensor(216.4736)\n",
      "-287.1086413244841 0.0 -287.1086413244841 0.3646640687135799 tensor(225.3921)\n",
      "-287.08025553959646 0.0 -287.08025553959646 0.1936124729578828 tensor(220.9878)\n",
      "-286.90318376541006 0.0 -286.90318376541006 0.32413694928566456 tensor(176.0489)\n",
      "-287.09745699479805 0.0 -287.09745699479805 0.23504139883141362 tensor(225.3163)\n",
      "-286.69981513238446 0.0 -286.69981513238446 0.22369218917289793 tensor(208.3010)\n",
      "-287.0663898890353 0.0 -287.0663898890353 0.3056273431823325 tensor(175.1973)\n",
      "-286.76778890105044 0.0 -286.76778890105044 0.3244892028167246 tensor(209.3039)\n",
      "-286.54691925087366 0.0 -286.54691925087366 0.08587157165466094 tensor(166.1018)\n",
      "-286.8803609926477 0.0 -286.8803609926477 0.3837599103916197 tensor(185.5489)\n",
      "-287.48191717597194 0.0 -287.48191717597194 0.33355347609122055 tensor(177.9771)\n",
      "-286.57272301136226 0.0 -286.57272301136226 0.3472729040291136 tensor(271.6208)\n",
      "-286.87734969845974 0.0 -286.87734969845974 0.2539142842051346 tensor(236.4179)\n",
      "-287.1093312746826 0.0 -287.1093312746826 0.32644484996619977 tensor(174.2374)\n",
      "-286.8040437864786 0.0 -286.8040437864786 0.29316629863181076 tensor(154.2978)\n",
      "-286.835346954883 0.0 -286.835346954883 0.090117274981951 tensor(178.0467)\n",
      "-286.74220517011884 0.0 -286.74220517011884 0.25068238372695084 tensor(468.4696)\n",
      "-287.10983501646047 0.0 -287.10983501646047 0.2510052537059496 tensor(194.5758)\n",
      "-286.7880884139761 0.0 -286.7880884139761 0.1837332199113089 tensor(175.2556)\n",
      "-286.99485148832474 0.0 -286.99485148832474 0.4136521178216758 tensor(236.2073)\n",
      "-286.75009878325784 0.0 -286.75009878325784 0.24738061272722528 tensor(209.4333)\n",
      "-287.1925911011508 0.0 -287.1925911011508 0.24416000753337458 tensor(183.6945)\n",
      "-286.5619905403739 0.0 -286.5619905403739 0.17648463259008973 tensor(152.8649)\n",
      "-287.33171955450445 0.0 -287.33171955450445 0.32042964629510856 tensor(167.7005)\n",
      "-287.0169840046077 0.0 -287.0169840046077 0.06327140269389246 tensor(236.5848)\n",
      "-286.9658385319414 0.0 -286.9658385319414 0.1811518527349047 tensor(250.6129)\n",
      "-286.6607924863907 0.0 -286.6607924863907 0.4030583384383152 tensor(177.4593)\n",
      "-286.7072678194011 0.0 -286.7072678194011 0.18788012943887478 tensor(171.0371)\n",
      "-287.4500375991952 0.0 -287.4500375991952 0.2617011211980839 tensor(183.5777)\n",
      "-286.9229607993219 0.0 -286.9229607993219 0.2682661578771961 tensor(169.7558)\n",
      "-287.18329337580246 0.0 -287.18329337580246 0.25970461143217793 tensor(303.3737)\n",
      "-287.02175165599243 0.0 -287.02175165599243 0.3739475357983688 tensor(191.4230)\n",
      "-286.73341845605245 0.0 -286.73341845605245 0.3078586614149648 tensor(202.4097)\n",
      "-286.83790541331825 0.0 -286.83790541331825 0.13410186403122068 tensor(233.9579)\n",
      "-286.58877257771275 0.0 -286.58877257771275 0.3173370552696813 tensor(246.5475)\n",
      "-287.0827974875196 0.0 -287.0827974875196 0.3560324757699096 tensor(207.1340)\n",
      "-286.84308152659924 0.0 -286.84308152659924 0.15287254631336983 tensor(180.1596)\n",
      "-286.9143785379554 0.0 -286.9143785379554 0.29696595051339536 tensor(257.3516)\n",
      "-286.73128764673413 0.0 -286.73128764673413 0.19002890698772537 tensor(324.2455)\n",
      "-287.26240367474946 0.0 -287.26240367474946 0.3302511350812257 tensor(157.4808)\n",
      "-286.9287280744509 0.0 -286.9287280744509 0.41576592583728145 tensor(159.2926)\n",
      "-287.0024291241075 0.0 -287.0024291241075 0.1435067901450994 tensor(228.6460)\n",
      "-287.20136584723457 0.0 -287.20136584723457 0.2630326675250577 tensor(163.4891)\n",
      "-287.0550740739978 0.0 -287.0550740739978 0.3819346514877425 tensor(189.3689)\n",
      "-286.97106130966876 0.0 -286.97106130966876 0.2377064998820324 tensor(176.3325)\n",
      "-286.74798422686763 0.0 -286.74798422686763 0.2782920298989676 tensor(205.7586)\n",
      "-286.8579107120269 0.0 -286.8579107120269 0.2818098852965494 tensor(160.8159)\n",
      "-286.67864045678806 0.0 -286.67864045678806 0.25682970507616054 tensor(224.1411)\n",
      "-286.81110991408946 0.0 -286.81110991408946 0.09923306287446636 tensor(216.3735)\n",
      "-286.767376298323 0.0 -286.767376298323 0.2136143868030888 tensor(177.8027)\n",
      "-287.0865515896591 0.0 -287.0865515896591 0.2826776626287075 tensor(195.5022)\n",
      "-286.83783829705 0.0 -286.83783829705 0.3415166992736818 tensor(244.5563)\n",
      "-286.9098985705715 0.0 -286.9098985705715 0.16543119937267134 tensor(431.1427)\n",
      "-286.89853636583655 0.0 -286.89853636583655 0.2065400920306485 tensor(182.0993)\n",
      "-286.671936264887 0.0 -286.671936264887 0.19034125273014563 tensor(226.2608)\n",
      "-286.7448351103497 0.0 -286.7448351103497 0.31734308035242204 tensor(168.2508)\n",
      "-287.0383819725828 0.0 -287.0383819725828 0.26566771541292294 tensor(414.7657)\n",
      "-287.3372552467512 0.0 -287.3372552467512 0.46897294004495826 tensor(192.9554)\n",
      "-287.1425558724094 0.0 -287.1425558724094 0.2199498516757565 tensor(197.7245)\n",
      "-287.1596641824619 0.0 -287.1596641824619 0.0720151157824435 tensor(248.2111)\n",
      "-287.07236160273345 0.0 -287.07236160273345 0.2633115278772951 tensor(169.9314)\n",
      "-287.04126429565383 0.0 -287.04126429565383 0.41300791765912087 tensor(195.7475)\n",
      "-286.6553615105738 0.0 -286.6553615105738 0.21381780463465952 tensor(227.3569)\n",
      "-287.0351126573643 0.0 -287.0351126573643 0.2740007031076401 tensor(200.5059)\n",
      "-287.3037304215053 0.0 -287.3037304215053 0.2629051185774578 tensor(206.2052)\n",
      "-287.00114658722936 0.0 -287.00114658722936 0.06818673729413774 tensor(243.5364)\n",
      "-286.9463153649477 0.0 -286.9463153649477 0.2258568296292246 tensor(245.9250)\n",
      "-286.9059448144858 0.0 -286.9059448144858 0.24493993234686257 tensor(311.1483)\n",
      "-286.75060898742856 0.0 -286.75060898742856 0.19046738321598877 tensor(173.0104)\n",
      "-286.643661469701 0.0 -286.643661469701 0.34378343195427025 tensor(208.5323)\n",
      "-286.7955029908205 0.0 -286.7955029908205 0.30560782584103724 tensor(239.0447)\n",
      "-286.74098921155087 0.0 -286.74098921155087 0.393333168474174 tensor(179.5457)\n",
      "-286.7733951339916 0.0 -286.7733951339916 0.20049978899985835 tensor(340.0496)\n",
      "-286.8168928650825 0.0 -286.8168928650825 0.3185052321789881 tensor(189.6882)\n",
      "-287.2981414365769 0.0 -287.2981414365769 0.30681928588556706 tensor(320.8569)\n",
      "-286.6716235501706 0.0 -286.6716235501706 0.2780745134311544 tensor(301.1567)\n",
      "-286.71865432557865 0.0 -286.71865432557865 0.31320792393416386 tensor(208.6181)\n",
      "-287.0669519263813 0.0 -287.0669519263813 0.23190376968891685 tensor(171.1248)\n",
      "-286.88879372276347 0.0 -286.88879372276347 0.20438522434660744 tensor(239.6729)\n",
      "-287.1351522580071 0.0 -287.1351522580071 0.3484579461704604 tensor(208.2863)\n",
      "-286.8124236523816 0.0 -286.8124236523816 0.18049515314916728 tensor(392.6307)\n",
      "-286.95599281546055 0.0 -286.95599281546055 0.30171001695647737 tensor(167.0891)\n",
      "-286.89327703310727 0.0 -286.89327703310727 0.30200949966310076 tensor(265.1135)\n",
      "-287.093885627833 0.0 -287.093885627833 0.09874873548165417 tensor(233.1875)\n",
      "-286.70022308746064 0.0 -286.70022308746064 0.2590791237196887 tensor(162.0747)\n",
      "-286.80872192430513 0.0 -286.80872192430513 0.13700738738760257 tensor(172.1721)\n",
      "-286.7447512009432 0.0 -286.7447512009432 0.49608890364227265 tensor(186.1383)\n",
      "-287.1720218140408 0.0 -287.1720218140408 0.12120082844340878 tensor(151.3459)\n",
      "-286.920348209062 0.0 -286.920348209062 0.08144240063087715 tensor(196.2350)\n",
      "== Era 9 | Epoch 0 metrics ==\n",
      "\tloss -286.916\n",
      "\tforce 0\n",
      "\tdkl -286.916\n",
      "\tlogp 86.4183\n",
      "\tlogq -200.498\n",
      "\tess 0.255\n",
      "-286.9506362396303 0.0 -286.9506362396303 0.23506123771893916 tensor(184.3595)\n",
      "-286.7720142124327 0.0 -286.7720142124327 0.27150555141685206 tensor(232.8392)\n",
      "-286.8219877666318 0.0 -286.8219877666318 0.09148070873649124 tensor(202.4919)\n",
      "-286.9357229993492 0.0 -286.9357229993492 0.36033944144956775 tensor(176.1439)\n",
      "-287.1962045652901 0.0 -287.1962045652901 0.09464179483743149 tensor(243.9701)\n",
      "-286.5805921156354 0.0 -286.5805921156354 0.30736062891403104 tensor(239.1517)\n",
      "-287.2091876577932 0.0 -287.2091876577932 0.20895127539310643 tensor(150.5074)\n",
      "-286.8874389492164 0.0 -286.8874389492164 0.301825405348103 tensor(191.4421)\n",
      "-286.8347309198189 0.0 -286.8347309198189 0.2738070382308133 tensor(194.3366)\n",
      "-287.0085840897557 0.0 -287.0085840897557 0.21249536863412283 tensor(233.2624)\n",
      "-287.15990704456823 0.0 -287.15990704456823 0.24007683408176161 tensor(224.2078)\n",
      "-287.15448694449515 0.0 -287.15448694449515 0.33858604430608136 tensor(366.4812)\n",
      "-286.86676923076527 0.0 -286.86676923076527 0.10051877029319363 tensor(220.1916)\n",
      "-286.9570472581329 0.0 -286.9570472581329 0.2677854972815718 tensor(237.3000)\n",
      "-286.68381141406235 0.0 -286.68381141406235 0.21936879018266667 tensor(292.2301)\n",
      "-287.27861124141083 0.0 -287.27861124141083 0.26537142772376476 tensor(216.4032)\n",
      "-286.9693003225634 0.0 -286.9693003225634 0.21013777298137512 tensor(154.0289)\n",
      "-287.20648887533105 0.0 -287.20648887533105 0.3118329904514746 tensor(262.2562)\n",
      "-286.80703527608233 0.0 -286.80703527608233 0.2238515723796903 tensor(202.4925)\n",
      "-287.0975715566052 0.0 -287.0975715566052 0.20235043143038242 tensor(169.2843)\n",
      "-286.98959520570736 0.0 -286.98959520570736 0.19625236941475854 tensor(160.1790)\n",
      "-287.1420617545894 0.0 -287.1420617545894 0.24200373048143214 tensor(190.7085)\n",
      "-286.96516948060946 0.0 -286.96516948060946 0.27572603795287015 tensor(183.2929)\n",
      "-286.9188657423814 0.0 -286.9188657423814 0.329610755373042 tensor(197.2664)\n",
      "-287.1387665185607 0.0 -287.1387665185607 0.17446698275324074 tensor(129.7519)\n",
      "-286.8235179326561 0.0 -286.8235179326561 0.256231172982959 tensor(168.7305)\n",
      "-286.7817100952341 0.0 -286.7817100952341 0.3592368418836805 tensor(170.3703)\n",
      "-286.9112860622095 0.0 -286.9112860622095 0.20829344635652353 tensor(461.7430)\n",
      "-286.945508754262 0.0 -286.945508754262 0.16703654294926487 tensor(205.4010)\n",
      "-286.97198426738964 0.0 -286.97198426738964 0.34341731812721127 tensor(195.1109)\n",
      "-287.22313623823277 0.0 -287.22313623823277 0.3000181422495149 tensor(254.4285)\n",
      "-286.7143399689933 0.0 -286.7143399689933 0.3087488612059581 tensor(179.4278)\n",
      "-286.9476775032298 0.0 -286.9476775032298 0.36872589335462075 tensor(173.8804)\n",
      "-286.76854365796737 0.0 -286.76854365796737 0.2690117696580149 tensor(213.9415)\n",
      "-287.03428830637375 0.0 -287.03428830637375 0.32150818937897335 tensor(210.3965)\n",
      "-287.06636512037676 0.0 -287.06636512037676 0.12516920737012097 tensor(177.0301)\n",
      "-286.6186200474672 0.0 -286.6186200474672 0.3500573628941421 tensor(159.5074)\n",
      "-287.16399158340334 0.0 -287.16399158340334 0.2719025855250968 tensor(281.0625)\n",
      "-286.77469397900165 0.0 -286.77469397900165 0.14790608832167018 tensor(211.0241)\n",
      "-287.07267208347804 0.0 -287.07267208347804 0.20651174905658104 tensor(345.0831)\n",
      "-287.1409575472611 0.0 -287.1409575472611 0.34746826262523123 tensor(169.0454)\n",
      "-286.80819223123177 0.0 -286.80819223123177 0.41194181615612846 tensor(175.9053)\n",
      "-287.133407335474 0.0 -287.133407335474 0.27568135195595184 tensor(253.5821)\n",
      "-287.0716566644177 0.0 -287.0716566644177 0.34782500486393203 tensor(191.2402)\n",
      "-286.97555783231326 0.0 -286.97555783231326 0.047498057719456664 tensor(173.2963)\n",
      "-286.7848068227569 0.0 -286.7848068227569 0.22508228801373686 tensor(188.4814)\n",
      "-287.01427832920217 0.0 -287.01427832920217 0.28189184700421055 tensor(182.9211)\n",
      "-286.78642336248765 0.0 -286.78642336248765 0.20112097962402575 tensor(201.8174)\n",
      "-287.069429308684 0.0 -287.069429308684 0.15508942177714063 tensor(230.4263)\n",
      "-286.8146280213618 0.0 -286.8146280213618 0.22040703279255847 tensor(223.1842)\n",
      "-286.66275782953363 0.0 -286.66275782953363 0.287907818907507 tensor(209.2347)\n",
      "-286.9901855850206 0.0 -286.9901855850206 0.18533561549336428 tensor(211.7132)\n",
      "-287.0327506555161 0.0 -287.0327506555161 0.28610414113769744 tensor(174.5232)\n",
      "-286.6559447884433 0.0 -286.6559447884433 0.27910491760726813 tensor(216.7364)\n",
      "-286.92493810669987 0.0 -286.92493810669987 0.28073484347399985 tensor(220.3665)\n",
      "-286.8786053888724 0.0 -286.8786053888724 0.09968385525342092 tensor(290.4025)\n",
      "-286.942323062685 0.0 -286.942323062685 0.1686336903072456 tensor(189.0276)\n",
      "-286.778771533988 0.0 -286.778771533988 0.49063900076581446 tensor(193.4237)\n",
      "-286.8155798363734 0.0 -286.8155798363734 0.24491052578566397 tensor(202.2113)\n",
      "-287.01707126143305 0.0 -287.01707126143305 0.3859175989929811 tensor(189.3322)\n",
      "-286.8993568467123 0.0 -286.8993568467123 0.09386196608859532 tensor(214.6720)\n",
      "-287.0123225154897 0.0 -287.0123225154897 0.16071625086390576 tensor(172.2747)\n",
      "-286.7428358392675 0.0 -286.7428358392675 0.19776249041018973 tensor(231.2268)\n",
      "-286.90458352385696 0.0 -286.90458352385696 0.0924521273701558 tensor(208.0983)\n",
      "-287.21030157443397 0.0 -287.21030157443397 0.24458922522662294 tensor(155.0588)\n",
      "-286.53233566920136 0.0 -286.53233566920136 0.36544883441289167 tensor(183.2669)\n",
      "-287.0148216686662 0.0 -287.0148216686662 0.29870990539513465 tensor(193.4545)\n",
      "-287.2031275636785 0.0 -287.2031275636785 0.15799033473281962 tensor(221.3399)\n",
      "-287.1538784337393 0.0 -287.1538784337393 0.2928706313211248 tensor(205.3340)\n",
      "-287.0025137905275 0.0 -287.0025137905275 0.21780837863212296 tensor(153.9192)\n",
      "-287.09532442616427 0.0 -287.09532442616427 0.26724599464440657 tensor(200.4002)\n",
      "-287.03190304966233 0.0 -287.03190304966233 0.3650955700476246 tensor(201.8294)\n",
      "-287.3038661947312 0.0 -287.3038661947312 0.2825861424159012 tensor(202.9939)\n",
      "-287.24761717375077 0.0 -287.24761717375077 0.15600830123947038 tensor(229.6587)\n",
      "-286.8818505125762 0.0 -286.8818505125762 0.26856687861198897 tensor(189.2298)\n",
      "-286.97280758615335 0.0 -286.97280758615335 0.1570116120049633 tensor(198.1759)\n",
      "-286.91316396697783 0.0 -286.91316396697783 0.19565489000351496 tensor(198.9173)\n",
      "-286.9193260934707 0.0 -286.9193260934707 0.2656090084653319 tensor(158.0998)\n",
      "-287.547082422443 0.0 -287.547082422443 0.3898791121417048 tensor(188.4085)\n",
      "-286.95150451870836 0.0 -286.95150451870836 0.2755039424003958 tensor(201.5219)\n",
      "-287.02308487895084 0.0 -287.02308487895084 0.3008180121589785 tensor(231.3856)\n",
      "-286.51340326800675 0.0 -286.51340326800675 0.2783026791884994 tensor(196.2648)\n",
      "-286.88881860491864 0.0 -286.88881860491864 0.30773594898826756 tensor(217.6866)\n",
      "-287.42756836384365 0.0 -287.42756836384365 0.12160664354460328 tensor(236.0715)\n",
      "-286.8276967349599 0.0 -286.8276967349599 0.21502839284718858 tensor(200.9876)\n",
      "-287.2638458646885 0.0 -287.2638458646885 0.17969084071223382 tensor(186.4959)\n",
      "-286.69293204136295 0.0 -286.69293204136295 0.20500508098320885 tensor(185.2642)\n",
      "-287.02664559387483 0.0 -287.02664559387483 0.2902491494039644 tensor(183.2664)\n",
      "-286.76069003015743 0.0 -286.76069003015743 0.21003815958093658 tensor(170.9971)\n",
      "-287.125569604588 0.0 -287.125569604588 0.3296113534181707 tensor(207.7591)\n",
      "-287.2044702565797 0.0 -287.2044702565797 0.226866253237999 tensor(163.5467)\n",
      "-287.248735673999 0.0 -287.248735673999 0.18304994966904672 tensor(253.3806)\n",
      "-287.11732615349 0.0 -287.11732615349 0.2837847015003347 tensor(169.5233)\n",
      "-287.14435145083996 0.0 -287.14435145083996 0.18643544705302748 tensor(192.8862)\n",
      "-286.63299594694354 0.0 -286.63299594694354 0.2766510038115985 tensor(197.8416)\n",
      "-287.15062179324605 0.0 -287.15062179324605 0.16039625648419215 tensor(146.0794)\n",
      "-286.97754626167045 0.0 -286.97754626167045 0.2517363278508512 tensor(185.5234)\n",
      "-287.2088071979043 0.0 -287.2088071979043 0.3131289750247911 tensor(176.6577)\n",
      "-286.77527216407 0.0 -286.77527216407 0.35516171152226167 tensor(230.1794)\n",
      "Accept rate: 0.3544921875\n",
      "Topological susceptibility = 1.33 +/- 0.12\n",
      "... vs HMC estimate = 1.23 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "pre_flow_model, flow_act = flow_train(param)\n",
    "flow_eval(pre_flow_model,flow_act)\n",
    "pre_flow = pre_flow_model['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T08:39:29.831227Z",
     "start_time": "2021-03-01T07:17:06.161657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-238.39049113095712 0.0 -238.39049113095712 0.020874773022601868 tensor(172.2697)\n",
      "19895.576947002137 19895.576947002137 -319.57948662292415 0.05410863666028212 tensor(140.8972)\n",
      "== Era 0 | Epoch 0 metrics ==\n",
      "\tloss 9828.59\n",
      "\tforce 9947.79\n",
      "\tdkl -278.985\n",
      "\tlogp 45.1002\n",
      "\tlogq -233.885\n",
      "\tess 0.0374917\n",
      "-239.99976242090156 0.0 -239.99976242090156 0.01601788104416998 tensor(168.6970)\n",
      "18428.018472041527 18428.018472041527 -316.4374867879671 0.039221438631699995 tensor(135.6055)\n",
      "-243.9512480907071 0.0 -243.9512480907071 0.026686704957950145 tensor(165.5903)\n",
      "15839.57981419014 15839.57981419014 -315.55972312953156 0.0188816702314684 tensor(125.7213)\n",
      "-245.25210238388522 0.0 -245.25210238388522 0.052730437139897154 tensor(160.9210)\n",
      "14641.889907644227 14641.889907644227 -311.52194899679625 0.019416117340973465 tensor(120.8860)\n",
      "-251.90357941579376 0.0 -251.90357941579376 0.015625031459330835 tensor(156.8555)\n",
      "12966.220321964054 12966.220321964054 -309.63083721817384 0.05373812992987525 tensor(113.7596)\n",
      "-255.14223247114825 0.0 -255.14223247114825 0.01589952510969818 tensor(151.6675)\n",
      "11473.248995040858 11473.248995040858 -308.419609386882 0.02636675268309179 tensor(107.0143)\n",
      "-258.5069914340013 0.0 -258.5069914340013 0.04438283040825035 tensor(154.1447)\n",
      "11124.148955428265 11124.148955428265 -305.2806519505801 0.018557709830762367 tensor(105.3798)\n",
      "-259.75240049373537 0.0 -259.75240049373537 0.015631304308656037 tensor(155.7730)\n",
      "10906.320560771535 10906.320560771535 -303.16343164466224 0.03027517228112745 tensor(104.3492)\n",
      "-263.2254077484631 0.0 -263.2254077484631 0.016392653192000103 tensor(150.0725)\n",
      "10608.133543395921 10608.133543395921 -302.06501080070154 0.05857081604871448 tensor(102.9177)\n",
      "-265.1178470295751 0.0 -265.1178470295751 0.042046793357876124 tensor(155.9537)\n",
      "10473.522018819189 10473.522018819189 -299.70741078042283 0.07432530425301984 tensor(102.2713)\n",
      "-269.0283148299021 0.0 -269.0283148299021 0.03204521067037535 tensor(157.0725)\n",
      "9362.980406953799 9362.980406953799 -298.1164924917009 0.07362036419444783 tensor(96.6923)\n",
      "-271.36306795276283 0.0 -271.36306795276283 0.017760565211534133 tensor(157.4695)\n",
      "11949.032549304398 11949.032549304398 -295.2392337747335 0.02805870124713543 tensor(109.2696)\n",
      "-273.7045857157314 0.0 -273.7045857157314 0.0249474848428577 tensor(161.7525)\n",
      "12824.450791275623 12824.450791275623 -295.2450940794207 0.025090040927784097 tensor(113.2024)\n",
      "-274.2487181389696 0.0 -274.2487181389696 0.015965179378280195 tensor(164.3562)\n",
      "11426.981413591511 11426.981413591511 -295.4822419268669 0.07482946830487039 tensor(106.8322)\n",
      "-276.70270133518375 0.0 -276.70270133518375 0.05265721301894163 tensor(170.9046)\n",
      "13891.836451865662 13891.836451865662 -293.90708978074815 0.07151512911700394 tensor(117.8061)\n",
      "-277.7280103416329 0.0 -277.7280103416329 0.04105546222487773 tensor(182.4594)\n",
      "17761.69604714756 17761.69604714756 -292.78638943202714 0.04129144437886888 tensor(133.2243)\n",
      "-278.54132832071946 0.0 -278.54132832071946 0.03955989536005525 tensor(180.6602)\n",
      "22921.781003916367 22921.781003916367 -293.5522780226042 0.04766470132693135 tensor(151.3492)\n",
      "-278.8152292648887 0.0 -278.8152292648887 0.050822939109399425 tensor(185.1082)\n",
      "24664.5260265488 24664.5260265488 -294.01221839049674 0.02233888698496239 tensor(156.9925)\n",
      "-279.2760289140797 0.0 -279.2760289140797 0.02154906987251252 tensor(201.8404)\n",
      "28116.899711008176 28116.899711008176 -295.0767603604614 0.015691014016996588 tensor(167.6100)\n",
      "-278.72623606649483 0.0 -278.72623606649483 0.03480823875091064 tensor(200.6181)\n",
      "31700.408496868127 31700.408496868127 -294.2415336741334 0.020420787684381887 tensor(178.0084)\n",
      "-280.0420151997412 0.0 -280.0420151997412 0.040768980024873634 tensor(192.5800)\n",
      "31359.988858748155 31359.988858748155 -295.1536220444859 0.016915903152005387 tensor(177.0347)\n",
      "-279.3607602954974 0.0 -279.3607602954974 0.01861978131831952 tensor(199.6962)\n",
      "43909.42356949677 43909.42356949677 -295.4563929652211 0.04180060763157657 tensor(209.4772)\n",
      "-278.9582976503832 0.0 -278.9582976503832 0.05291075809580467 tensor(203.2394)\n",
      "41105.20596333296 41105.20596333296 -297.4384951173993 0.018217855517495884 tensor(202.6483)\n",
      "-279.40077023337795 0.0 -279.40077023337795 0.10761937150267796 tensor(209.6309)\n",
      "44988.31993098871 44988.31993098871 -297.1061920819879 0.04954457293751601 tensor(212.0780)\n",
      "-278.7749519006798 0.0 -278.7749519006798 0.01629912515491451 tensor(202.4341)\n",
      "43025.82630156899 43025.82630156899 -296.9382016209989 0.028327544363496084 tensor(207.3455)\n",
      "-278.148496781152 0.0 -278.148496781152 0.02009084379720101 tensor(214.9734)\n",
      "37485.52857735849 37485.52857735849 -295.9387494771604 0.016371904371676335 tensor(193.5698)\n",
      "-278.15136085542196 0.0 -278.15136085542196 0.0407780873892515 tensor(209.9924)\n",
      "37016.873358634875 37016.873358634875 -295.3661737058043 0.027738389493274115 tensor(192.3537)\n",
      "-279.15380553327884 0.0 -279.15380553327884 0.016698777071389108 tensor(212.9309)\n",
      "39884.349363985166 39884.349363985166 -295.5069860253728 0.01802804373750676 tensor(199.6709)\n",
      "-278.57095004868154 0.0 -278.57095004868154 0.08103544585714015 tensor(200.6965)\n",
      "39412.397338839306 39412.397338839306 -295.6976659405032 0.036472769395616465 tensor(198.4660)\n",
      "-279.214423837351 0.0 -279.214423837351 0.08005218116831701 tensor(191.3194)\n",
      "32716.767658938563 32716.767658938563 -295.34525113882904 0.0779152597933942 tensor(180.8396)\n",
      "-279.44206595862806 0.0 -279.44206595862806 0.11729519184106545 tensor(203.4119)\n",
      "28636.30819214518 28636.30819214518 -294.73524125377287 0.022413436549570308 tensor(169.1952)\n",
      "-279.5735782560498 0.0 -279.5735782560498 0.017017396629557358 tensor(192.7177)\n",
      "30406.912117405933 30406.912117405933 -294.05894184504456 0.02430938356402866 tensor(174.3438)\n",
      "-279.88875100285156 0.0 -279.88875100285156 0.08581371750427366 tensor(196.1366)\n",
      "27776.60935084286 27776.60935084286 -293.8953343027133 0.015637492686615684 tensor(166.6339)\n",
      "-281.26079147925543 0.0 -281.26079147925543 0.055043980649308086 tensor(182.4193)\n",
      "23753.9518481641 23753.9518481641 -293.7264512618191 0.059348809003671316 tensor(154.1044)\n",
      "-280.50226229531665 0.0 -280.50226229531665 0.02188557630889308 tensor(181.0395)\n",
      "20678.60323610808 20678.60323610808 -292.9669283841361 0.02372560007745541 tensor(143.7806)\n",
      "-280.1464171942001 0.0 -280.1464171942001 0.0296449193654909 tensor(180.2961)\n",
      "23639.4376671099 23639.4376671099 -293.90182756232025 0.03450367897381056 tensor(153.7304)\n",
      "-279.95732506284406 0.0 -279.95732506284406 0.049500583285883915 tensor(174.5685)\n",
      "21446.166505797704 21446.166505797704 -292.714952399193 0.03600466552517353 tensor(146.4336)\n",
      "-280.4619736793386 0.0 -280.4619736793386 0.04868349586729328 tensor(174.3038)\n",
      "20182.916225682282 20182.916225682282 -291.68045702270496 0.09973503846243664 tensor(142.0498)\n",
      "-280.70185054319126 0.0 -280.70185054319126 0.017279875239388023 tensor(174.3545)\n",
      "20076.894531473772 20076.894531473772 -292.3062796367851 0.019080075561974393 tensor(141.6819)\n",
      "-280.5719523146804 0.0 -280.5719523146804 0.09743199412865788 tensor(179.1510)\n",
      "18603.535068246507 18603.535068246507 -292.8692791299827 0.03804532532814648 tensor(136.3778)\n",
      "-280.2346573070098 0.0 -280.2346573070098 0.14414920756174315 tensor(175.8164)\n",
      "17877.146964486823 17877.146964486823 -291.8430162917533 0.05080971801003105 tensor(133.6962)\n",
      "-280.24470772567395 0.0 -280.24470772567395 0.060405664561924255 tensor(166.3442)\n",
      "17644.747793692182 17644.747793692182 -292.781572707936 0.035356092007442996 tensor(132.8211)\n",
      "-280.0670336192017 0.0 -280.0670336192017 0.036094269768837395 tensor(179.9958)\n",
      "17938.774933089862 17938.774933089862 -292.6921064555722 0.035708674589991884 tensor(133.9281)\n",
      "-281.12600601967483 0.0 -281.12600601967483 0.06552827444090213 tensor(171.5787)\n",
      "20720.056045518162 20720.056045518162 -291.5686342181132 0.018091261740293768 tensor(143.9360)\n",
      "-280.7788409731379 0.0 -280.7788409731379 0.01589867758223111 tensor(173.1918)\n",
      "17325.983855100418 17325.983855100418 -292.4384681803876 0.018443909249335314 tensor(131.6144)\n",
      "-280.47143668683736 0.0 -280.47143668683736 0.030546387024536856 tensor(173.2355)\n",
      "16464.886213741793 16464.886213741793 -292.74971476285265 0.10984176710000963 tensor(128.3015)\n",
      "-279.74299939003504 0.0 -279.74299939003504 0.05419075703411067 tensor(175.5486)\n",
      "19156.577592994934 19156.577592994934 -292.1162418247609 0.07369283856071894 tensor(138.3950)\n",
      "-280.27580372878276 0.0 -280.27580372878276 0.03043647069943212 tensor(179.9931)\n",
      "17422.427424975598 17422.427424975598 -292.7104217816043 0.04154169431161496 tensor(131.9818)\n",
      "-281.2684609205828 0.0 -281.2684609205828 0.04871379700255685 tensor(166.9346)\n",
      "16546.091975825253 16546.091975825253 -291.144763014249 0.06308855304903595 tensor(128.6180)\n",
      "-280.70591902137176 0.0 -280.70591902137176 0.16820946628090108 tensor(166.0044)\n",
      "17970.783635349926 17970.783635349926 -291.6503127099028 0.030074975625716736 tensor(134.0419)\n",
      "-280.016943317299 0.0 -280.016943317299 0.041072230955768424 tensor(184.9255)\n",
      "19089.85903561682 19089.85903561682 -293.05852959758147 0.03358259989401341 tensor(138.1475)\n",
      "-280.83257366341377 0.0 -280.83257366341377 0.02595551833339358 tensor(186.6027)\n",
      "18624.022056448608 18624.022056448608 -292.02189600954165 0.06953788669993143 tensor(136.4513)\n",
      "-281.3917135679443 0.0 -281.3917135679443 0.03634706928919315 tensor(179.5449)\n",
      "23161.87734651401 23161.87734651401 -292.88564896109574 0.030143730656083664 tensor(152.1721)\n",
      "-281.5480516000194 0.0 -281.5480516000194 0.0288669817663902 tensor(178.8267)\n",
      "19364.593785072175 19364.593785072175 -292.8803403742868 0.02040797555900196 tensor(139.1392)\n",
      "-280.748722083776 0.0 -280.748722083776 0.03234885981289983 tensor(187.9131)\n",
      "21564.43729947396 21564.43729947396 -293.4516478089802 0.05217984316675745 tensor(146.8352)\n",
      "-282.06015485842136 0.0 -282.06015485842136 0.039682320757447695 tensor(180.5528)\n",
      "20864.67496728756 20864.67496728756 -292.5213494982181 0.028032699821237198 tensor(144.4313)\n",
      "-281.1330956657972 0.0 -281.1330956657972 0.037972181129156644 tensor(185.7609)\n",
      "23018.595904688293 23018.595904688293 -292.4984389236513 0.018013919889406208 tensor(151.7037)\n",
      "-280.91478030233145 0.0 -280.91478030233145 0.027110175965742403 tensor(182.0434)\n",
      "20090.566504453345 20090.566504453345 -292.39367529156453 0.08100326595596424 tensor(141.7272)\n",
      "-280.71201033711014 0.0 -280.71201033711014 0.05444346033780284 tensor(182.4197)\n",
      "22481.44449418612 22481.44449418612 -292.768740227252 0.03327179940480232 tensor(149.9149)\n",
      "-281.5457132399689 0.0 -281.5457132399689 0.04347255920948553 tensor(183.0575)\n",
      "23052.13336396998 23052.13336396998 -292.3212472906608 0.045071604220677304 tensor(151.8118)\n",
      "-280.9442101492585 0.0 -280.9442101492585 0.03316471713121553 tensor(173.1371)\n",
      "23916.585068133303 23916.585068133303 -291.8741480963969 0.07721741362600798 tensor(154.6336)\n",
      "-281.23087131463114 0.0 -281.23087131463114 0.10098491740027064 tensor(178.6732)\n",
      "20432.552671750953 20432.552671750953 -292.3403295408509 0.022971169291865812 tensor(142.9194)\n",
      "-281.9234543144702 0.0 -281.9234543144702 0.050366286478813194 tensor(177.6927)\n",
      "21765.697961610458 21765.697961610458 -291.6452760650752 0.021451522672142093 tensor(147.5170)\n",
      "-281.2633853056966 0.0 -281.2633853056966 0.06369630882670825 tensor(189.2683)\n",
      "23823.6602328186 23823.6602328186 -291.94142630804896 0.026336575714687414 tensor(154.3384)\n",
      "-281.40355084558263 0.0 -281.40355084558263 0.030760293480906087 tensor(182.5000)\n",
      "21167.670126471356 21167.670126471356 -291.2049361976973 0.03360801906393864 tensor(145.4784)\n",
      "-281.237496556829 0.0 -281.237496556829 0.023017825705380197 tensor(187.4459)\n",
      "22813.4233770263 22813.4233770263 -291.19118428280126 0.09505184637946784 tensor(151.0277)\n",
      "-281.928389991882 0.0 -281.928389991882 0.04431431677752463 tensor(175.4540)\n",
      "24206.1636255603 24206.1636255603 -292.46670734811187 0.04666069187329092 tensor(155.5610)\n",
      "-281.92507067093453 0.0 -281.92507067093453 0.01834816493412668 tensor(168.3851)\n",
      "20468.083835539946 20468.083835539946 -292.57633518685304 0.07120384219212693 tensor(143.0491)\n",
      "-281.8330061941648 0.0 -281.8330061941648 0.018774945294964162 tensor(176.9875)\n",
      "19792.953461883095 19792.953461883095 -291.90442467538395 0.09827959508334314 tensor(140.6762)\n",
      "-281.9571382056258 0.0 -281.9571382056258 0.0197285148387587 tensor(182.5770)\n",
      "21589.104429770297 21589.104429770297 -291.5678845805207 0.17099317117159255 tensor(146.9177)\n",
      "-281.53522948026307 0.0 -281.53522948026307 0.024144073468217935 tensor(182.9182)\n",
      "21650.088389520904 21650.088389520904 -291.885160219507 0.01816874874660849 tensor(147.1234)\n",
      "-281.6617687240955 0.0 -281.6617687240955 0.07443690140599744 tensor(179.9366)\n",
      "22029.898063148743 22029.898063148743 -291.943681732747 0.03684177298279862 tensor(148.4037)\n",
      "-282.10739511980506 0.0 -282.10739511980506 0.023404645679453946 tensor(165.7846)\n",
      "18818.3141969501 18818.3141969501 -291.51563836031335 0.04395577956402889 tensor(137.1568)\n",
      "-281.517383769958 0.0 -281.517383769958 0.0354161059133171 tensor(177.5609)\n",
      "17172.794258109712 17172.794258109712 -291.09063695205947 0.01589788938322172 tensor(131.0314)\n",
      "-282.0688530418349 0.0 -282.0688530418349 0.05294169833675472 tensor(170.8821)\n",
      "17756.05412591112 17756.05412591112 -291.754297806541 0.02687007905089872 tensor(133.2379)\n",
      "-282.02452235582217 0.0 -282.02452235582217 0.037990364808394385 tensor(178.5186)\n",
      "17525.92640305434 17525.92640305434 -292.40261790176976 0.02337496692750136 tensor(132.3731)\n",
      "-282.1965917550975 0.0 -282.1965917550975 0.017797981378488162 tensor(175.3850)\n",
      "20576.247990481814 20576.247990481814 -291.35786307432573 0.0273856370163017 tensor(143.4255)\n",
      "-282.35817582246113 0.0 -282.35817582246113 0.021598486082060418 tensor(173.7803)\n",
      "19957.02059409067 19957.02059409067 -291.55607793731156 0.06474921276127381 tensor(141.2513)\n",
      "-281.4284706097185 0.0 -281.4284706097185 0.09515432299667506 tensor(177.3691)\n",
      "18440.107410378736 18440.107410378736 -291.7766558610036 0.07421412039432847 tensor(135.7810)\n",
      "-282.4552812490746 0.0 -282.4552812490746 0.03740502624898948 tensor(173.9329)\n",
      "18541.265846343482 18541.265846343482 -291.9882082438713 0.11119005042091686 tensor(136.1465)\n",
      "-282.55952880797696 0.0 -282.55952880797696 0.030101125695607897 tensor(176.3641)\n",
      "21834.563732724288 21834.563732724288 -291.7003601884413 0.10872885303435571 tensor(147.7485)\n",
      "-281.51796871747786 0.0 -281.51796871747786 0.07512080781370822 tensor(175.1920)\n",
      "21750.524845399435 21750.524845399435 -291.2401811839235 0.14188782831796687 tensor(147.4652)\n",
      "-282.6497666390602 0.0 -282.6497666390602 0.09962896919037964 tensor(182.2106)\n",
      "19673.706372612018 19673.706372612018 -290.9963661668676 0.03214543866788418 tensor(140.2460)\n",
      "-281.8628496580855 0.0 -281.8628496580855 0.11883052908638415 tensor(183.0589)\n",
      "19205.991303014016 19205.991303014016 -292.4998868419932 0.02859007645291673 tensor(138.5571)\n",
      "-282.8326143553081 0.0 -282.8326143553081 0.04318054529016041 tensor(164.0716)\n",
      "21384.240706788154 21384.240706788154 -291.34996781046283 0.05806277666556006 tensor(146.2120)\n",
      "-282.21149331757044 0.0 -282.21149331757044 0.10279090604391887 tensor(184.3557)\n",
      "20339.46188564942 20339.46188564942 -292.115991511252 0.0919680349523293 tensor(142.5987)\n",
      "-282.3191033756831 0.0 -282.3191033756831 0.07793644447292314 tensor(175.7515)\n",
      "17729.539115160762 17729.539115160762 -291.6181324394478 0.01696639872320419 tensor(133.1322)\n",
      "-282.208640605037 0.0 -282.208640605037 0.056424334786927696 tensor(172.8130)\n",
      "17407.44453633586 17407.44453633586 -291.96487460845736 0.08363862011086497 tensor(131.9104)\n",
      "-282.3398077665794 0.0 -282.3398077665794 0.02981596222229925 tensor(183.7080)\n",
      "23681.74907410734 23681.74907410734 -291.1401952450334 0.058535958002885934 tensor(153.8593)\n",
      "-281.9259187722655 0.0 -281.9259187722655 0.091694803726398 tensor(181.5036)\n",
      "21548.414501551255 21548.414501551255 -290.94770418640223 0.07356507200502914 tensor(146.7681)\n",
      "-282.1152098257321 0.0 -282.1152098257321 0.11458719923687075 tensor(170.4704)\n",
      "19005.381850266524 19005.381850266524 -290.7672426738043 0.02661612869580672 tensor(137.8268)\n",
      "-282.6449054627539 0.0 -282.6449054627539 0.019724820850180107 tensor(177.0531)\n",
      "21423.150547332494 21423.150547332494 -291.41258050632257 0.02372283826630172 tensor(146.3371)\n",
      "-282.5273131390998 0.0 -282.5273131390998 0.03417753818670146 tensor(168.2929)\n",
      "19476.375993676134 19476.375993676134 -290.4690505550258 0.06726723141006816 tensor(139.5231)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-282.0288759674046 0.0 -282.0288759674046 0.01748891782679761 tensor(172.2337)\n",
      "18107.09874547043 18107.09874547043 -291.0170564260919 0.09874884956579436 tensor(134.5299)\n",
      "-282.2200999082913 0.0 -282.2200999082913 0.06634073337839831 tensor(177.6308)\n",
      "17836.32625000032 17836.32625000032 -290.4221557180066 0.05567670330681381 tensor(133.5189)\n",
      "-282.6662888984654 0.0 -282.6662888984654 0.11425298353406703 tensor(175.1554)\n",
      "17472.065803800302 17472.065803800302 -290.81753088904554 0.043110457357864354 tensor(132.1487)\n",
      "-281.94873595086125 0.0 -281.94873595086125 0.041115689491939764 tensor(183.0737)\n",
      "18391.90620942812 18391.90620942812 -291.12573669849246 0.016070010122786912 tensor(135.5751)\n",
      "-282.77547573857044 0.0 -282.77547573857044 0.05110075496229343 tensor(176.0552)\n",
      "19292.295820321247 19292.295820321247 -291.48025269768925 0.04186817312021927 tensor(138.8499)\n",
      "-283.03733035669813 0.0 -283.03733035669813 0.04628325185417098 tensor(178.1560)\n",
      "23552.63477779828 23552.63477779828 -291.0865714546083 0.1287396576865669 tensor(153.4165)\n",
      "-282.72253605686797 0.0 -282.72253605686797 0.08885607480618463 tensor(173.5607)\n",
      "20202.949321480126 20202.949321480126 -290.6452451542346 0.05578923923545408 tensor(142.0870)\n",
      "-282.96433566869644 0.0 -282.96433566869644 0.06651285801967947 tensor(164.3966)\n",
      "20032.089965380317 20032.089965380317 -290.4571639283166 0.09503574949074423 tensor(141.4902)\n",
      "== Era 1 | Epoch 0 metrics ==\n",
      "\tloss 10099.2\n",
      "\tforce 10240.1\n",
      "\tdkl -286.81\n",
      "\tlogp 80.8646\n",
      "\tlogq -205.945\n",
      "\tess 0.0536643\n",
      "-282.81961051643935 0.0 -282.81961051643935 0.076729308859315 tensor(159.2995)\n",
      "19744.61536174524 19744.61536174524 -290.46379635091256 0.0942959411584302 tensor(140.4636)\n",
      "-283.36282251631525 0.0 -283.36282251631525 0.23372714501935032 tensor(171.2214)\n",
      "19216.558998911594 19216.558998911594 -290.53554294365284 0.08775915868574546 tensor(138.5707)\n",
      "-282.7925465051095 0.0 -282.7925465051095 0.1442739419102444 tensor(172.1684)\n",
      "23637.960920527155 23637.960920527155 -290.20696007113037 0.14539967077400012 tensor(153.6487)\n",
      "-282.6883102329763 0.0 -282.6883102329763 0.0410333718560782 tensor(179.3567)\n",
      "20784.20983493666 20784.20983493666 -290.77131589636286 0.1662237240776575 tensor(144.0879)\n",
      "-283.5771219499296 0.0 -283.5771219499296 0.062265442027001044 tensor(162.0506)\n",
      "20971.157510174526 20971.157510174526 -290.73188658853667 0.12657476327212266 tensor(144.6634)\n",
      "-282.94440508602213 0.0 -282.94440508602213 0.019420838165485923 tensor(176.2212)\n",
      "23240.394874667716 23240.394874667716 -290.8117429410321 0.031539082646937514 tensor(152.2912)\n",
      "-282.4563356542394 0.0 -282.4563356542394 0.18769141678431284 tensor(174.9367)\n",
      "20001.119084033984 20001.119084033984 -290.1432911024111 0.1455835233913425 tensor(141.3338)\n",
      "-283.23397270942843 0.0 -283.23397270942843 0.10643754052234412 tensor(180.9681)\n",
      "26210.77915524305 26210.77915524305 -289.69631094907345 0.041659300563127735 tensor(161.6077)\n",
      "-283.3213403092635 0.0 -283.3213403092635 0.06209244109723616 tensor(170.7116)\n",
      "23718.382816197165 23718.382816197165 -290.9320801819688 0.12779323830051284 tensor(153.8451)\n",
      "-282.906306680153 0.0 -282.906306680153 0.08413304278329707 tensor(172.1770)\n",
      "22969.96080216291 22969.96080216291 -290.361627657992 0.045075787567114056 tensor(151.3850)\n",
      "-283.26331529302274 0.0 -283.26331529302274 0.030489136381568215 tensor(179.1645)\n",
      "24942.905563663087 24942.905563663087 -289.8965639845928 0.10060865203021452 tensor(157.6920)\n",
      "-283.65229490129525 0.0 -283.65229490129525 0.09988157655326393 tensor(162.2875)\n",
      "26417.694954201615 26417.694954201615 -290.67643663019305 0.03448732698872364 tensor(162.3168)\n",
      "-283.8145312238437 0.0 -283.8145312238437 0.035749284066091895 tensor(166.4548)\n",
      "22949.666426631768 22949.666426631768 -290.35991326018393 0.06958798306912184 tensor(151.2760)\n",
      "-283.52150287351594 0.0 -283.52150287351594 0.06573174627697817 tensor(171.9417)\n",
      "21107.537387060132 21107.537387060132 -290.53813691603784 0.04480755073784761 tensor(144.9549)\n",
      "-283.0614921406874 0.0 -283.0614921406874 0.0735470043926925 tensor(189.2698)\n",
      "22174.773494694426 22174.773494694426 -289.83064716589035 0.06389323467932921 tensor(148.7400)\n",
      "-284.0662644996419 0.0 -284.0662644996419 0.06933400542336343 tensor(162.2660)\n",
      "20196.967625402627 20196.967625402627 -290.1576189117725 0.042972219535594734 tensor(142.0368)\n",
      "-284.3028258660423 0.0 -284.3028258660423 0.04941903438811135 tensor(161.7401)\n",
      "18681.465707684678 18681.465707684678 -290.70268110322917 0.05306193458130991 tensor(136.4971)\n",
      "-283.62306182667055 0.0 -283.62306182667055 0.11115168616775724 tensor(162.5620)\n",
      "17197.423766682874 17197.423766682874 -290.4448732320102 0.13180799934836243 tensor(131.0328)\n",
      "-283.8379847575412 0.0 -283.8379847575412 0.07579497380694934 tensor(168.4475)\n",
      "17979.95509879439 17979.95509879439 -290.22311311186013 0.10220161266075443 tensor(133.9413)\n",
      "-283.8476302406791 0.0 -283.8476302406791 0.02356758030957709 tensor(170.0822)\n",
      "16061.797808560053 16061.797808560053 -290.2785148991155 0.07775832488216672 tensor(126.6135)\n",
      "-283.65877372842215 0.0 -283.65877372842215 0.07679678620710376 tensor(160.6657)\n",
      "20676.685448747383 20676.685448747383 -289.8317911586289 0.08043996147244961 tensor(143.7131)\n",
      "-283.4272459450872 0.0 -283.4272459450872 0.02214139364873838 tensor(162.4566)\n",
      "18241.626345885015 18241.626345885015 -289.7340290508704 0.08346331335760708 tensor(134.9911)\n",
      "-284.52078957899107 0.0 -284.52078957899107 0.05123542366509841 tensor(161.9317)\n",
      "21541.309347322647 21541.309347322647 -289.64689926047413 0.07943858942929335 tensor(146.6836)\n",
      "-283.91262560132344 0.0 -283.91262560132344 0.16313411266277833 tensor(159.1136)\n",
      "17759.127416516214 17759.127416516214 -289.5684940239354 0.06929158492922631 tensor(133.1599)\n",
      "-283.80517729353676 0.0 -283.80517729353676 0.1278115946783962 tensor(163.0917)\n",
      "19700.66397903403 19700.66397903403 -290.2156597020172 0.060852358942046623 tensor(140.2777)\n",
      "-284.398767898178 0.0 -284.398767898178 0.035732210715169764 tensor(174.8791)\n",
      "15988.604932729984 15988.604932729984 -289.4130452133709 0.04039810374549775 tensor(126.3934)\n",
      "-284.03494727270925 0.0 -284.03494727270925 0.02335615738334578 tensor(172.7689)\n",
      "21825.99351828764 21825.99351828764 -289.5712563596238 0.06711897821833085 tensor(147.5512)\n",
      "-283.8200582469101 0.0 -283.8200582469101 0.14551532870367506 tensor(165.5694)\n",
      "20656.10039993018 20656.10039993018 -289.3221995042818 0.08684943130994006 tensor(143.6239)\n",
      "-284.52667568260813 0.0 -284.52667568260813 0.08224987858188178 tensor(166.8982)\n",
      "19791.004091474686 19791.004091474686 -289.49435646163465 0.10607959579560182 tensor(140.5256)\n",
      "-284.07023507347503 0.0 -284.07023507347503 0.0814652848451 tensor(175.6782)\n",
      "17502.162350868653 17502.162350868653 -289.3645381329873 0.05423867146083404 tensor(132.1814)\n",
      "-284.26045268557135 0.0 -284.26045268557135 0.03350081650118181 tensor(154.9347)\n",
      "18128.751197715348 18128.751197715348 -289.15699116992766 0.019860127870896978 tensor(134.5608)\n",
      "-284.267564653749 0.0 -284.267564653749 0.1267461508027443 tensor(171.3749)\n",
      "18939.10802707 18939.10802707 -289.23560604643495 0.021835636381028953 tensor(137.5175)\n",
      "-284.0972090677571 0.0 -284.0972090677571 0.11347180423393784 tensor(173.5135)\n",
      "21712.904834518355 21712.904834518355 -289.51992200093855 0.06166505212426596 tensor(147.0880)\n",
      "-284.66251338835525 0.0 -284.66251338835525 0.045227929033656265 tensor(165.6095)\n",
      "22443.301678710057 22443.301678710057 -289.2132866506012 0.05676600913440689 tensor(149.6302)\n",
      "-284.4626256927954 0.0 -284.4626256927954 0.019566031006201925 tensor(172.9097)\n",
      "21922.59448274377 21922.59448274377 -288.6342060752978 0.07533543335103683 tensor(147.9321)\n",
      "-284.5304002061955 0.0 -284.5304002061955 0.04924775522064289 tensor(196.5199)\n",
      "19435.235875945207 19435.235875945207 -289.4771960256668 0.04035150320343808 tensor(139.2488)\n",
      "-284.1624809395907 0.0 -284.1624809395907 0.06647499956141525 tensor(163.5682)\n",
      "20482.630537613048 20482.630537613048 -289.6949821965642 0.14913156486014081 tensor(142.8899)\n",
      "-284.5180151936001 0.0 -284.5180151936001 0.04322022109861837 tensor(154.9609)\n",
      "19597.52792067254 19597.52792067254 -289.70679892641533 0.14224284576146556 tensor(139.8667)\n",
      "-284.54187320110077 0.0 -284.54187320110077 0.0788358230885969 tensor(168.6167)\n",
      "25220.128926208454 25220.128926208454 -289.49183997446323 0.020900705762811396 tensor(158.4224)\n",
      "-283.7576593800852 0.0 -283.7576593800852 0.0458134044975593 tensor(157.0355)\n",
      "24476.39684824179 24476.39684824179 -289.10697148215064 0.06269272056240162 tensor(156.2308)\n",
      "-284.96889799848844 0.0 -284.96889799848844 0.05451225091321577 tensor(157.2858)\n",
      "23669.64177595624 23669.64177595624 -289.4334495008934 0.17039358826948883 tensor(153.3958)\n",
      "-284.3637418702765 0.0 -284.3637418702765 0.039527884692338006 tensor(172.7190)\n",
      "21601.126400477817 21601.126400477817 -289.2845233015993 0.09450516127813023 tensor(146.8623)\n",
      "-284.08319632701546 0.0 -284.08319632701546 0.1087251545684767 tensor(158.8386)\n",
      "19096.018306039645 19096.018306039645 -289.35149585105245 0.15771797554281328 tensor(138.0403)\n",
      "-284.05073511617707 0.0 -284.05073511617707 0.05262752160846602 tensor(162.9644)\n",
      "19835.243593107232 19835.243593107232 -289.38630519520143 0.1566807412984597 tensor(140.5594)\n",
      "-283.7944905174745 0.0 -283.7944905174745 0.1022639530167117 tensor(153.6106)\n",
      "20394.066269545554 20394.066269545554 -289.3408893228758 0.26880219383118914 tensor(142.6706)\n",
      "-283.9387442469967 0.0 -283.9387442469967 0.03238024028441628 tensor(165.9853)\n",
      "24767.811212594566 24767.811212594566 -289.4814488353419 0.049504251134498335 tensor(156.9504)\n",
      "-284.8048531912909 0.0 -284.8048531912909 0.06683769515555982 tensor(148.8766)\n",
      "20294.94875768882 20294.94875768882 -289.4899377620985 0.05378968707147552 tensor(142.3150)\n",
      "-284.14759570920666 0.0 -284.14759570920666 0.1430199551108187 tensor(171.0015)\n",
      "24275.923194693365 24275.923194693365 -288.6356745340838 0.08419590740090037 tensor(155.6296)\n",
      "-284.9354464730063 0.0 -284.9354464730063 0.14859251802808823 tensor(168.5837)\n",
      "17848.153588078785 17848.153588078785 -289.0156766798612 0.0596560695276933 tensor(133.3775)\n",
      "-284.42809031447064 0.0 -284.42809031447064 0.05904326687878743 tensor(183.7885)\n",
      "28667.949109231136 28667.949109231136 -289.22602944149367 0.11138128199688106 tensor(168.9964)\n",
      "-284.98273207052273 0.0 -284.98273207052273 0.09208127860473961 tensor(145.4247)\n",
      "21861.88403239929 21861.88403239929 -289.29258391551707 0.19033838240707676 tensor(147.6740)\n",
      "-284.84945559950836 0.0 -284.84945559950836 0.0729502327203441 tensor(155.2912)\n",
      "18119.75253274042 18119.75253274042 -289.0682055726314 0.2603020275689502 tensor(134.4919)\n",
      "-284.83984414483234 0.0 -284.83984414483234 0.10104973774719794 tensor(155.1568)\n",
      "21682.30100564842 21682.30100564842 -289.5835991833278 0.10546827016560104 tensor(147.0103)\n",
      "-284.7157696769975 0.0 -284.7157696769975 0.0707312723980305 tensor(184.4841)\n",
      "21624.855061900587 21624.855061900587 -289.4073705753799 0.02177364350721215 tensor(146.8984)\n",
      "-285.4264869056424 0.0 -285.4264869056424 0.06906736182779298 tensor(159.2995)\n",
      "18385.487420625086 18385.487420625086 -289.91411743289814 0.07756986926121484 tensor(135.4740)\n",
      "-284.6628991364343 0.0 -284.6628991364343 0.04552276217394544 tensor(160.4360)\n",
      "20082.28927823089 20082.28927823089 -288.89037464707536 0.11464239337876199 tensor(141.5747)\n",
      "-285.40629543203704 0.0 -285.40629543203704 0.20202248173189838 tensor(165.0781)\n",
      "23790.527086227023 23790.527086227023 -288.7774695672516 0.08690307457886988 tensor(154.0085)\n",
      "-284.6412230056822 0.0 -284.6412230056822 0.09207831308160883 tensor(157.0554)\n",
      "18672.68868342979 18672.68868342979 -289.0721305939951 0.04465004664826845 tensor(136.5616)\n",
      "-284.55939248496327 0.0 -284.55939248496327 0.1084614578757115 tensor(155.5394)\n",
      "21850.96420347743 21850.96420347743 -288.73288948831606 0.1244812726471608 tensor(147.6596)\n",
      "-284.19556866872585 0.0 -284.19556866872585 0.11355249641482007 tensor(156.8279)\n",
      "21934.088847267478 21934.088847267478 -289.5920080088075 0.030113549570577828 tensor(147.9644)\n",
      "-284.7437509639126 0.0 -284.7437509639126 0.03292927489653459 tensor(161.3984)\n",
      "21606.801124598176 21606.801124598176 -289.22919594977077 0.14928805569638975 tensor(146.8650)\n",
      "-284.7275786682236 0.0 -284.7275786682236 0.06390671743337631 tensor(151.4363)\n",
      "20516.12253138507 20516.12253138507 -288.4402260163831 0.04688734748479767 tensor(143.0782)\n",
      "-284.4792100643864 0.0 -284.4792100643864 0.19889811279899527 tensor(172.9341)\n",
      "19462.2440767788 19462.2440767788 -288.9998122779765 0.06320416193959294 tensor(139.3612)\n",
      "-284.7784701934654 0.0 -284.7784701934654 0.06076860294285381 tensor(165.2532)\n",
      "19961.548376377716 19961.548376377716 -289.5104234102368 0.053665786917697585 tensor(141.1229)\n",
      "-285.14969636122606 0.0 -285.14969636122606 0.2176832954557385 tensor(152.9804)\n",
      "19635.14711929371 19635.14711929371 -289.21993453636765 0.10054123352577125 tensor(140.0206)\n",
      "-284.63536319784475 0.0 -284.63536319784475 0.04479724970967454 tensor(169.3043)\n",
      "18816.483142059144 18816.483142059144 -289.27453105118764 0.03758926908756016 tensor(137.0410)\n",
      "-284.89743660981657 0.0 -284.89743660981657 0.04816932980180613 tensor(164.0773)\n",
      "16961.484932127696 16961.484932127696 -289.3395373440728 0.01919667926488061 tensor(130.1218)\n",
      "-283.96875658947863 0.0 -283.96875658947863 0.028793433390627357 tensor(163.6557)\n",
      "22488.175275474965 22488.175275474965 -289.3192473613575 0.018259123552993563 tensor(149.8482)\n",
      "-284.51589474196464 0.0 -284.51589474196464 0.03750234339935244 tensor(165.7652)\n",
      "20635.325308198095 20635.325308198095 -288.713514856253 0.23527734223532668 tensor(143.5079)\n",
      "-284.9914267545852 0.0 -284.9914267545852 0.067094482219765 tensor(174.4465)\n",
      "19442.398301621924 19442.398301621924 -288.55430231879086 0.11265206316204097 tensor(139.2795)\n",
      "-284.88210290419454 0.0 -284.88210290419454 0.06530674859992774 tensor(163.1174)\n",
      "17197.12942921072 17197.12942921072 -289.41461715262835 0.1569190215497587 tensor(131.0186)\n",
      "-284.68929463492896 0.0 -284.68929463492896 0.08022780381537664 tensor(170.3611)\n",
      "20585.839006858514 20585.839006858514 -289.18610235259564 0.08526375371142178 tensor(143.3220)\n",
      "-284.7670594682511 0.0 -284.7670594682511 0.14714919516832223 tensor(170.4913)\n",
      "25775.12063463978 25775.12063463978 -288.63553985205806 0.0985239157936436 tensor(160.3375)\n",
      "-285.13397076815374 0.0 -285.13397076815374 0.16495988028503963 tensor(157.3926)\n",
      "21941.979126029837 21941.979126029837 -288.7021422093313 0.09584539159912728 tensor(147.9899)\n",
      "-285.02721956590426 0.0 -285.02721956590426 0.06371956736686167 tensor(162.7678)\n",
      "23662.699762100005 23662.699762100005 -288.65620494187954 0.06812547562093059 tensor(153.5498)\n",
      "-285.0840157160036 0.0 -285.0840157160036 0.13258473884771493 tensor(147.1461)\n",
      "20099.89735052098 20099.89735052098 -288.6551377661 0.038497956196625195 tensor(141.6279)\n",
      "-284.27924417468677 0.0 -284.27924417468677 0.13784370972714952 tensor(173.4531)\n",
      "17858.158266796596 17858.158266796596 -289.6608293124293 0.18792132477484827 tensor(133.3992)\n",
      "-284.0660827647734 0.0 -284.0660827647734 0.06434793980284184 tensor(158.0043)\n",
      "17397.683482083514 17397.683482083514 -289.05659583481446 0.11752568285916218 tensor(131.8063)\n",
      "-285.6869015213317 0.0 -285.6869015213317 0.18915075995645336 tensor(150.3931)\n",
      "23684.817435288205 23684.817435288205 -288.789710662532 0.25440882462191916 tensor(153.6141)\n",
      "-285.1850847408715 0.0 -285.1850847408715 0.061384792574213976 tensor(156.7301)\n",
      "24013.2095850993 24013.2095850993 -288.32084801030055 0.05716108890394435 tensor(154.7240)\n",
      "-284.81709831618343 0.0 -284.81709831618343 0.054178727466368135 tensor(164.4866)\n",
      "27852.99478151896 27852.99478151896 -288.9666116349388 0.08680571729993765 tensor(166.6123)\n",
      "-285.0899454331882 0.0 -285.0899454331882 0.23666312507611278 tensor(161.4345)\n",
      "22223.627040500483 22223.627040500483 -289.31828497978506 0.1952792445563606 tensor(148.9065)\n",
      "-285.3424084064279 0.0 -285.3424084064279 0.1575202548452631 tensor(165.2963)\n",
      "21667.21883486978 21667.21883486978 -288.7999123310832 0.08134553994982593 tensor(146.9980)\n",
      "-284.88764049277614 0.0 -284.88764049277614 0.12154672257152145 tensor(136.7929)\n",
      "19874.591155474867 19874.591155474867 -288.47607314533246 0.018184672557223464 tensor(140.7305)\n",
      "-285.3351588923033 0.0 -285.3351588923033 0.0536741496122458 tensor(149.7882)\n",
      "18044.642843054313 18044.642843054313 -288.6581244312311 0.1318195571026301 tensor(134.1779)\n",
      "-285.41112523756163 0.0 -285.41112523756163 0.1748245201900717 tensor(170.2295)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20215.922302307892 20215.922302307892 -289.0490789642482 0.08581517078753059 tensor(142.0087)\n",
      "-284.7708420011242 0.0 -284.7708420011242 0.1241824655435952 tensor(145.8697)\n",
      "19158.524028265674 19158.524028265674 -289.117127331115 0.06887955802300738 tensor(138.2079)\n",
      "-285.0769650030387 0.0 -285.0769650030387 0.052996048514764 tensor(152.4883)\n",
      "22839.25626319651 22839.25626319651 -289.01215128805075 0.0850424860735054 tensor(150.9762)\n",
      "-285.02814523391044 0.0 -285.02814523391044 0.11159996303823944 tensor(155.1642)\n",
      "20938.334217736752 20938.334217736752 -288.77423971463463 0.08875526203928062 tensor(144.5194)\n",
      "-285.43705250318334 0.0 -285.43705250318334 0.021591439216530797 tensor(144.5166)\n",
      "18380.643497061435 18380.643497061435 -288.8009548812096 0.08265548621339397 tensor(135.4307)\n",
      "-285.13135757909276 0.0 -285.13135757909276 0.08273905264687126 tensor(162.2770)\n",
      "19564.29309519095 19564.29309519095 -288.17521469352937 0.1997791956284614 tensor(139.7457)\n",
      "-284.9900123827216 0.0 -284.9900123827216 0.07629313547627 tensor(152.8693)\n",
      "24816.61043901089 24816.61043901089 -288.3203136269647 0.07646680582768618 tensor(157.3521)\n",
      "-285.145242114735 0.0 -285.145242114735 0.1433153339203414 tensor(157.8780)\n",
      "20092.984081847244 20092.984081847244 -288.5118451922923 0.10078891949528848 tensor(141.5723)\n",
      "-285.5502652010882 0.0 -285.5502652010882 0.08373608315686228 tensor(152.7570)\n",
      "25705.469610962067 25705.469610962067 -288.7549052446228 0.07060295691340508 tensor(160.0804)\n",
      "-285.47727624734415 0.0 -285.47727624734415 0.07659297799332833 tensor(175.1644)\n",
      "21664.430461839078 21664.430461839078 -288.89035847556534 0.06002179347417669 tensor(146.9708)\n",
      "-285.2591338438984 0.0 -285.2591338438984 0.031107659700908077 tensor(162.4057)\n",
      "18764.896304911137 18764.896304911137 -288.5456538205782 0.10070103956923747 tensor(136.8464)\n",
      "-285.2897846880583 0.0 -285.2897846880583 0.08140721526625518 tensor(165.3016)\n",
      "21771.834273889544 21771.834273889544 -288.73618082137057 0.12863404045729018 tensor(147.3391)\n",
      "-285.4600538626445 0.0 -285.4600538626445 0.0743977357842288 tensor(144.6326)\n",
      "19315.595930147625 19315.595930147625 -288.9877843868403 0.08801542967514175 tensor(138.7477)\n",
      "-285.48952173138287 0.0 -285.48952173138287 0.07626292082188464 tensor(138.5225)\n",
      "20332.051657779997 20332.051657779997 -288.14634955825375 0.3255232961177151 tensor(142.3895)\n",
      "-285.0687733098764 0.0 -285.0687733098764 0.022784268898059377 tensor(168.2343)\n",
      "19695.867516317623 19695.867516317623 -288.1066620082252 0.1486420685927445 tensor(140.1532)\n",
      "== Era 2 | Epoch 0 metrics ==\n",
      "\tloss 10284.2\n",
      "\tforce 10426.7\n",
      "\tdkl -286.942\n",
      "\tlogp 84.1672\n",
      "\tlogq -202.775\n",
      "\tess 0.100089\n",
      "-285.4689762352773 0.0 -285.4689762352773 0.04481021892886916 tensor(165.9281)\n",
      "20221.46781269639 20221.46781269639 -288.52128454161704 0.09636303887907595 tensor(142.0295)\n",
      "-285.0380944635423 0.0 -285.0380944635423 0.09101164762800538 tensor(151.1159)\n",
      "22630.201141809215 22630.201141809215 -288.62029968790347 0.07515953108246294 tensor(150.0895)\n",
      "-285.1174236756889 0.0 -285.1174236756889 0.1146363170117104 tensor(163.3807)\n",
      "24349.007508250364 24349.007508250364 -288.65679366905067 0.0737403274937205 tensor(155.8073)\n",
      "-285.77428624716384 0.0 -285.77428624716384 0.08261512934913116 tensor(161.2758)\n",
      "21719.589849735872 21719.589849735872 -288.49383274439924 0.1570078582172156 tensor(147.1787)\n",
      "-284.85837234373173 0.0 -284.85837234373173 0.10004257923397815 tensor(148.5300)\n",
      "21546.95656613291 21546.95656613291 -288.54694318612485 0.2523881486619791 tensor(146.5711)\n",
      "-285.238462157782 0.0 -285.238462157782 0.06416066026196628 tensor(151.5030)\n",
      "20831.70045624327 20831.70045624327 -288.7699717992382 0.19716969366184278 tensor(144.1644)\n",
      "-285.34409247765757 0.0 -285.34409247765757 0.15096039387553625 tensor(168.5460)\n",
      "22551.096595591516 22551.096595591516 -288.538229538328 0.18278356815225671 tensor(149.9630)\n",
      "-286.12701657308946 0.0 -286.12701657308946 0.04851389969152086 tensor(163.2137)\n",
      "18045.6808692626 18045.6808692626 -288.75210055382996 0.1596076148421655 tensor(134.1566)\n",
      "-284.86878627708006 0.0 -284.86878627708006 0.1259268933021991 tensor(160.1460)\n",
      "21107.667053750123 21107.667053750123 -288.9639610281274 0.14571226453794142 tensor(145.1014)\n",
      "-285.3953907321767 0.0 -285.3953907321767 0.04695770148523348 tensor(146.4233)\n",
      "19829.059414099444 19829.059414099444 -288.88452577428353 0.1051409606591593 tensor(140.6597)\n",
      "-285.05034411947076 0.0 -285.05034411947076 0.16222158251416394 tensor(156.2255)\n",
      "22571.818741919153 22571.818741919153 -289.0943399052308 0.11847424440742581 tensor(150.0846)\n",
      "-285.0905785493776 0.0 -285.0905785493776 0.06994832826798728 tensor(162.6096)\n",
      "16993.14642586618 16993.14642586618 -288.8019788350683 0.1539345977965672 tensor(130.2503)\n",
      "-284.78409345964894 0.0 -284.78409345964894 0.10510948093570835 tensor(160.2903)\n",
      "21276.00760957011 21276.00760957011 -288.85690786704174 0.10764066596917046 tensor(145.7164)\n",
      "-285.37566785768087 0.0 -285.37566785768087 0.10206577212142805 tensor(170.2050)\n",
      "19512.760417322104 19512.760417322104 -288.7231389538717 0.1757476998653045 tensor(139.5417)\n",
      "-285.0551351473356 0.0 -285.0551351473356 0.02981038244409964 tensor(172.1121)\n",
      "23652.733274374375 23652.733274374375 -288.43846225019547 0.07934731852020496 tensor(153.6535)\n",
      "-285.18218684975454 0.0 -285.18218684975454 0.06926780232698103 tensor(157.0203)\n",
      "25306.180127954816 25306.180127954816 -288.90472016195264 0.13700959213653877 tensor(158.9005)\n",
      "-285.50239781211525 0.0 -285.50239781211525 0.08118709860928262 tensor(152.7576)\n",
      "24616.68198479006 24616.68198479006 -288.5553900348604 0.052346036854934636 tensor(156.7009)\n",
      "-285.7535291957418 0.0 -285.7535291957418 0.0769910326914265 tensor(141.0119)\n",
      "31298.132350970005 31298.132350970005 -288.75802844615373 0.1353928304072799 tensor(176.6796)\n",
      "-285.28279019925327 0.0 -285.28279019925327 0.09338709831507302 tensor(151.3666)\n",
      "19581.28029927129 19581.28029927129 -289.116502602537 0.10297337766727312 tensor(139.7710)\n",
      "-285.6015388309158 0.0 -285.6015388309158 0.22163907382155879 tensor(168.6117)\n",
      "20554.800063813636 20554.800063813636 -288.4134042673129 0.1437115797490559 tensor(143.1740)\n",
      "-285.0511674435967 0.0 -285.0511674435967 0.15971412674997434 tensor(159.0917)\n",
      "25377.502611054726 25377.502611054726 -288.5052111011298 0.037916980496377865 tensor(159.1350)\n",
      "-285.1345787728571 0.0 -285.1345787728571 0.2048536208710131 tensor(159.7632)\n",
      "20448.782256132636 20448.782256132636 -288.27962739133824 0.09094537656643085 tensor(142.8592)\n",
      "-284.859255160762 0.0 -284.859255160762 0.07833509834818785 tensor(163.7921)\n",
      "19085.016365628704 19085.016365628704 -288.59311546887767 0.06687330613421948 tensor(138.0039)\n",
      "-285.040273784056 0.0 -285.040273784056 0.14021167111776003 tensor(151.9544)\n",
      "21478.72813844565 21478.72813844565 -288.429417996662 0.16520220433159138 tensor(146.3837)\n",
      "-285.37496917623616 0.0 -285.37496917623616 0.22901082334039324 tensor(167.8424)\n",
      "25072.2220277913 25072.2220277913 -288.4128283028989 0.22620387511390397 tensor(158.1428)\n",
      "-285.26605062682347 0.0 -285.26605062682347 0.1940793882369013 tensor(176.1158)\n",
      "20965.742635309532 20965.742635309532 -288.6933557717855 0.08565898878039842 tensor(144.6867)\n",
      "-285.04041595222895 0.0 -285.04041595222895 0.14442773089507288 tensor(167.8490)\n",
      "21026.57591644204 21026.57591644204 -288.6632120225495 0.11755004035830947 tensor(144.7391)\n",
      "-285.18155253276257 0.0 -285.18155253276257 0.22466990859886493 tensor(160.3475)\n",
      "24094.4098560682 24094.4098560682 -288.59948097848974 0.19530597222046553 tensor(155.0018)\n",
      "-284.7486514398382 0.0 -284.7486514398382 0.08714435047472854 tensor(159.3641)\n",
      "25304.062138940804 25304.062138940804 -288.11891227431033 0.09228596213002987 tensor(158.7644)\n",
      "-285.76356872511826 0.0 -285.76356872511826 0.048399485578093066 tensor(154.4144)\n",
      "21182.26278752783 21182.26278752783 -288.49633171242556 0.020709637438877486 tensor(145.3632)\n",
      "-285.79086309352084 0.0 -285.79086309352084 0.12990670606057822 tensor(147.8179)\n",
      "23614.716675669897 23614.716675669897 -288.44553988112193 0.07236863718881803 tensor(153.4861)\n",
      "-285.3711501552357 0.0 -285.3711501552357 0.08185210667505508 tensor(152.4244)\n",
      "20355.518416462433 20355.518416462433 -288.53923927954304 0.07422554392144967 tensor(142.5088)\n",
      "-284.85816950703077 0.0 -284.85816950703077 0.08043261374491563 tensor(163.2565)\n",
      "20220.744747052013 20220.744747052013 -288.5186860465499 0.28450366835713836 tensor(142.0005)\n",
      "-285.54745333653136 0.0 -285.54745333653136 0.048424930971997265 tensor(164.8256)\n",
      "24115.97398124336 24115.97398124336 -288.44641734280555 0.17078285279103994 tensor(155.1220)\n",
      "-285.8662603441304 0.0 -285.8662603441304 0.03868698678791547 tensor(151.8592)\n",
      "19616.72618593426 19616.72618593426 -288.7582186238814 0.07599648195507078 tensor(139.9161)\n",
      "-285.28538221347605 0.0 -285.28538221347605 0.14607051652183975 tensor(145.6537)\n",
      "21367.3044397809 21367.3044397809 -288.41645700024435 0.25236756607022853 tensor(145.9539)\n",
      "-285.21057680690166 0.0 -285.21057680690166 0.12363365169739757 tensor(158.5403)\n",
      "18280.428711040702 18280.428711040702 -288.5685842338712 0.11310859761210065 tensor(135.0476)\n",
      "-285.2054298516101 0.0 -285.2054298516101 0.12352402512327647 tensor(151.6869)\n",
      "23218.810726737145 23218.810726737145 -288.59237334814816 0.16651879705268197 tensor(152.1693)\n",
      "-285.56207855908565 0.0 -285.56207855908565 0.16554327466681307 tensor(166.9864)\n",
      "17620.962329471466 17620.962329471466 -288.9006877458554 0.09565679617735591 tensor(132.5943)\n",
      "-285.3364143317568 0.0 -285.3364143317568 0.09220872263944292 tensor(172.4709)\n",
      "19375.93829370548 19375.93829370548 -288.60000864884637 0.10011621210057033 tensor(139.0232)\n",
      "-285.55235965565 0.0 -285.55235965565 0.19834152248977951 tensor(153.4664)\n",
      "17023.524268029658 17023.524268029658 -288.57098117528506 0.23196568642868595 tensor(130.3346)\n",
      "-285.39818233183 0.0 -285.39818233183 0.05661982227561866 tensor(161.0641)\n",
      "17445.466822057948 17445.466822057948 -288.6768728656486 0.16347246759047868 tensor(131.8710)\n",
      "-285.4198322197263 0.0 -285.4198322197263 0.09103047477660688 tensor(148.4220)\n",
      "21645.309413953386 21645.309413953386 -288.8480446121629 0.2200596231788237 tensor(146.9527)\n",
      "-284.90050223952016 0.0 -284.90050223952016 0.0943526186579298 tensor(148.6758)\n",
      "16435.881200627235 16435.881200627235 -288.9031850146373 0.08574313728839296 tensor(128.0502)\n",
      "-284.7575770102214 0.0 -284.7575770102214 0.07619275868438227 tensor(144.2742)\n",
      "17827.527048178643 17827.527048178643 -288.83303317295963 0.20010791080044638 tensor(133.3766)\n",
      "-284.71687941077516 0.0 -284.71687941077516 0.05985842971975773 tensor(165.3766)\n",
      "18578.293113607077 18578.293113607077 -288.985417593092 0.06113752492680368 tensor(136.1862)\n",
      "-285.01776507417634 0.0 -285.01776507417634 0.18346127705893978 tensor(156.5621)\n",
      "20619.773356853162 20619.773356853162 -287.7443886036068 0.06899409773155825 tensor(143.4628)\n",
      "-285.5738960879568 0.0 -285.5738960879568 0.20254245336263949 tensor(155.1102)\n",
      "22828.174374802435 22828.174374802435 -288.238220172557 0.10728856306578023 tensor(150.8557)\n",
      "-284.97186558053266 0.0 -284.97186558053266 0.19330232974071182 tensor(160.4688)\n",
      "18692.586431061998 18692.586431061998 -288.0164612899235 0.08493544300783225 tensor(136.5511)\n",
      "-284.8266820196221 0.0 -284.8266820196221 0.28743010323796064 tensor(166.8350)\n",
      "21522.64181530488 21522.64181530488 -288.2314437487866 0.18856642178265873 tensor(146.5487)\n",
      "-286.16408966503366 0.0 -286.16408966503366 0.11635221733339793 tensor(164.5497)\n",
      "24532.84265832456 24532.84265832456 -288.3609643976178 0.10720166252328125 tensor(156.4500)\n",
      "-285.47780102123795 0.0 -285.47780102123795 0.09909723949880733 tensor(150.2953)\n",
      "21214.73757918802 21214.73757918802 -288.12723561824833 0.1711012767705139 tensor(145.4460)\n",
      "-286.023203718835 0.0 -286.023203718835 0.19520660215325952 tensor(163.4779)\n",
      "20871.122110832486 20871.122110832486 -288.60483857484826 0.19128389625102155 tensor(144.3396)\n",
      "-284.7835719392288 0.0 -284.7835719392288 0.10688705622501507 tensor(168.3824)\n",
      "17879.320281432483 17879.320281432483 -288.84581862484134 0.15294873671037895 tensor(133.5931)\n",
      "-285.5113368249264 0.0 -285.5113368249264 0.1597405815828186 tensor(155.7429)\n",
      "22319.049636555123 22319.049636555123 -288.7207257569346 0.03445790211588215 tensor(149.2297)\n",
      "-285.2257552098063 0.0 -285.2257552098063 0.10004413161288388 tensor(155.9055)\n",
      "16011.833709537834 16011.833709537834 -287.97748786851565 0.07770204769488184 tensor(126.3828)\n",
      "-285.50951509411203 0.0 -285.50951509411203 0.05727091172342346 tensor(154.2831)\n",
      "25757.04641717595 25757.04641717595 -288.69336961116954 0.17936971791349515 tensor(160.3281)\n",
      "-285.37544087757584 0.0 -285.37544087757584 0.1913960609301677 tensor(172.8430)\n",
      "20066.6023513269 20066.6023513269 -288.5093705513988 0.09791012612531104 tensor(141.5667)\n",
      "-286.13656303009304 0.0 -286.13656303009304 0.20576291449321085 tensor(167.9434)\n",
      "19531.44659642035 19531.44659642035 -288.22655590733575 0.12957821906493533 tensor(139.5877)\n",
      "-285.94004711255536 0.0 -285.94004711255536 0.22904285502797433 tensor(136.2549)\n",
      "18680.91454581808 18680.91454581808 -288.4470969265095 0.19340976427397358 tensor(136.5321)\n",
      "-285.7566239231468 0.0 -285.7566239231468 0.16180133842275823 tensor(155.7845)\n",
      "20715.90821452702 20715.90821452702 -288.5962088804241 0.12997758632252499 tensor(143.7985)\n",
      "-285.37781932806416 0.0 -285.37781932806416 0.16875145859787866 tensor(144.2772)\n",
      "20981.827874379363 20981.827874379363 -288.67782892314494 0.06001749091055305 tensor(144.6899)\n",
      "-285.76921300659416 0.0 -285.76921300659416 0.034236934744214 tensor(141.6178)\n",
      "19151.86585120001 19151.86585120001 -288.53367514236464 0.0989215128307826 tensor(138.2638)\n",
      "-285.7325353128796 0.0 -285.7325353128796 0.16073649067780024 tensor(159.3884)\n",
      "21951.475323994087 21951.475323994087 -288.33255243079833 0.08243189594917308 tensor(148.0149)\n",
      "-285.8899493027077 0.0 -285.8899493027077 0.19703276697814417 tensor(161.9341)\n",
      "17795.8847753394 17795.8847753394 -288.69790965422004 0.23903315311447337 tensor(133.2718)\n",
      "-285.07238430223674 0.0 -285.07238430223674 0.28573301695288134 tensor(172.3466)\n",
      "18979.258853714586 18979.258853714586 -288.0960086628441 0.15858955607794262 tensor(137.6460)\n",
      "-285.68924904656234 0.0 -285.68924904656234 0.029660787221228217 tensor(145.3179)\n",
      "20325.24838880941 20325.24838880941 -288.17144466179224 0.10902428476494684 tensor(142.4635)\n",
      "-285.92315242733656 0.0 -285.92315242733656 0.03365066249839853 tensor(140.7844)\n",
      "16443.78507273399 16443.78507273399 -288.64314587174204 0.13714211069185886 tensor(128.1290)\n",
      "-285.41443931299546 0.0 -285.41443931299546 0.1168587353732868 tensor(177.4345)\n",
      "22326.67910895982 22326.67910895982 -288.3264231111781 0.14273990218888175 tensor(149.2575)\n",
      "-286.20047994918355 0.0 -286.20047994918355 0.29992210455425594 tensor(148.5017)\n",
      "24124.621366785395 24124.621366785395 -288.8340094762511 0.13863247903232412 tensor(155.1314)\n",
      "-286.0324865257264 0.0 -286.0324865257264 0.10126496398075946 tensor(157.0052)\n",
      "17843.914392123523 17843.914392123523 -288.68489612677007 0.07228887678738237 tensor(133.4412)\n",
      "-285.7182018471632 0.0 -285.7182018471632 0.07505395050070461 tensor(167.1739)\n",
      "20922.364598618664 20922.364598618664 -288.21749640395126 0.21028679898276886 tensor(144.3005)\n",
      "-286.02727859401875 0.0 -286.02727859401875 0.1383743598261762 tensor(159.9455)\n",
      "23238.432643310247 23238.432643310247 -288.1421635102165 0.11024480072920141 tensor(152.2866)\n",
      "-285.0734061235892 0.0 -285.0734061235892 0.15914076067535998 tensor(168.3847)\n",
      "18289.154165881904 18289.154165881904 -288.4846621609445 0.1706811281036505 tensor(135.1104)\n",
      "-285.6728692764078 0.0 -285.6728692764078 0.08240162388272101 tensor(171.1542)\n",
      "19506.810185940158 19506.810185940158 -288.4020836038655 0.11615363049925334 tensor(139.5406)\n",
      "-285.62674093491535 0.0 -285.62674093491535 0.200579829722276 tensor(161.5384)\n",
      "18893.85530238441 18893.85530238441 -288.5717018133606 0.09443628686021507 tensor(137.3500)\n",
      "-285.8459591596828 0.0 -285.8459591596828 0.17095517499175095 tensor(162.9382)\n",
      "20976.676566021953 20976.676566021953 -288.391095058446 0.3710897402336811 tensor(144.6360)\n",
      "-286.10625405219287 0.0 -286.10625405219287 0.14256597225484285 tensor(156.0797)\n",
      "20059.9914460219 20059.9914460219 -288.07483173609774 0.08226336970182559 tensor(141.4838)\n",
      "-285.9737725743345 0.0 -285.9737725743345 0.10662338862694667 tensor(161.4017)\n",
      "19485.80460960594 19485.80460960594 -288.34964721670394 0.09590679444854791 tensor(139.4124)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-285.772797657745 0.0 -285.772797657745 0.13352600059287248 tensor(157.7767)\n",
      "20738.191999614173 20738.191999614173 -288.56340876681264 0.2610773608756829 tensor(143.7585)\n",
      "-285.46334408463053 0.0 -285.46334408463053 0.15066971058082745 tensor(157.9661)\n",
      "22300.80950093914 22300.80950093914 -288.40516639264354 0.18582107082424165 tensor(149.1505)\n",
      "-285.3310271813408 0.0 -285.3310271813408 0.14386454062725842 tensor(142.6556)\n",
      "24843.47600563333 24843.47600563333 -287.6717669867619 0.05836557620280894 tensor(157.4783)\n",
      "-285.5410839964654 0.0 -285.5410839964654 0.09045148083147031 tensor(168.7516)\n",
      "21417.12381737355 21417.12381737355 -288.60570552724664 0.18768438021406503 tensor(146.1840)\n",
      "-285.730168523674 0.0 -285.730168523674 0.122192229778682 tensor(164.3966)\n",
      "19133.649837078316 19133.649837078316 -288.0868052717084 0.2116947041712562 tensor(138.2011)\n",
      "-285.398444279386 0.0 -285.398444279386 0.12247826272055558 tensor(166.5890)\n",
      "24505.120501426667 24505.120501426667 -288.6896016102867 0.13146141121115845 tensor(156.3132)\n",
      "-285.093536859941 0.0 -285.093536859941 0.05554569364406331 tensor(170.5671)\n",
      "17484.74373679718 17484.74373679718 -288.2278019676728 0.1832773114693049 tensor(132.0937)\n",
      "-285.47226419944434 0.0 -285.47226419944434 0.1946322376602999 tensor(156.7426)\n",
      "19613.948726219995 19613.948726219995 -288.56660270499907 0.1878034749064934 tensor(139.8893)\n",
      "-285.6938346756436 0.0 -285.6938346756436 0.11339759368542907 tensor(148.6308)\n",
      "21937.109308870156 21937.109308870156 -288.3239320326296 0.3039439141290659 tensor(147.8933)\n",
      "-286.0938854277869 0.0 -286.0938854277869 0.14437772861472264 tensor(176.1662)\n",
      "22110.347267328492 22110.347267328492 -288.7324280767467 0.2353296232495545 tensor(148.5292)\n",
      "-285.15471539246164 0.0 -285.15471539246164 0.10012957513823766 tensor(181.6190)\n",
      "25150.94454861489 25150.94454861489 -288.73925878697844 0.11775094722483329 tensor(158.3922)\n",
      "-286.3028954734215 0.0 -286.3028954734215 0.0709409492137722 tensor(158.4468)\n",
      "24011.13506608655 24011.13506608655 -288.57795590771485 0.19169222948390102 tensor(154.8100)\n",
      "-285.0216337793102 0.0 -285.0216337793102 0.03333784941073864 tensor(164.9782)\n",
      "26300.684878073796 26300.684878073796 -288.7241513730055 0.3066146609243574 tensor(161.9167)\n",
      "-285.80900045886904 0.0 -285.80900045886904 0.06923247826791563 tensor(164.4487)\n",
      "22870.916044195583 22870.916044195583 -288.1407769774385 0.09725226638271477 tensor(151.0625)\n",
      "-285.8173236352711 0.0 -285.8173236352711 0.1901856308534911 tensor(150.5037)\n",
      "20768.22400344725 20768.22400344725 -288.4759425808703 0.0703779734041785 tensor(143.9720)\n",
      "-285.32983719589777 0.0 -285.32983719589777 0.3313041020039154 tensor(151.4001)\n",
      "18866.122736338242 18866.122736338242 -288.40461406042886 0.20002092177604128 tensor(137.2034)\n",
      "-285.8349325554709 0.0 -285.8349325554709 0.19026779258473978 tensor(129.9840)\n",
      "19220.437130807935 19220.437130807935 -288.1401339151111 0.11694766330155225 tensor(138.4973)\n",
      "-285.13799521663555 0.0 -285.13799521663555 0.07758461445538398 tensor(152.3311)\n",
      "20358.068470213835 20358.068470213835 -288.3390133524435 0.21190059829489388 tensor(142.5463)\n",
      "-285.43767899741954 0.0 -285.43767899741954 0.06038970822691772 tensor(171.1877)\n",
      "23386.39728784415 23386.39728784415 -288.37086993003913 0.21571061545859777 tensor(152.7725)\n",
      "-286.0469738157659 0.0 -286.0469738157659 0.15432292218966825 tensor(143.9195)\n",
      "20456.83329699681 20456.83329699681 -288.53560033598166 0.2378311844202142 tensor(142.8292)\n",
      "-285.9334831461485 0.0 -285.9334831461485 0.26835041514433544 tensor(142.8001)\n",
      "20827.47119748128 20827.47119748128 -288.25636393437924 0.23811263456853837 tensor(144.1014)\n",
      "== Era 3 | Epoch 0 metrics ==\n",
      "\tloss 10309\n",
      "\tforce 10451.8\n",
      "\tdkl -287.038\n",
      "\tlogp 85.0252\n",
      "\tlogq -202.013\n",
      "\tess 0.148488\n",
      "-285.65697624045106 0.0 -285.65697624045106 0.10881843964494438 tensor(145.2123)\n",
      "27355.804648264624 27355.804648264624 -288.2221836355225 0.24062510311758079 tensor(165.1300)\n",
      "-286.1622654890017 0.0 -286.1622654890017 0.14379168664731184 tensor(171.0594)\n",
      "26507.378340973602 26507.378340973602 -288.4038459447768 0.047569170275694336 tensor(162.6487)\n",
      "-286.0012910380354 0.0 -286.0012910380354 0.06975619763486128 tensor(160.8139)\n",
      "19971.138596919795 19971.138596919795 -288.09006565589834 0.05632229086690702 tensor(141.1385)\n",
      "-285.6404144639413 0.0 -285.6404144639413 0.13198622264604506 tensor(171.5907)\n",
      "25489.221822424704 25489.221822424704 -288.19334788720397 0.1558266452682983 tensor(159.3421)\n",
      "-285.29240558498395 0.0 -285.29240558498395 0.16403218361230448 tensor(170.8362)\n",
      "28733.684595928302 28733.684595928302 -288.42627422706977 0.09101361810492882 tensor(169.3244)\n",
      "-285.4135608869499 0.0 -285.4135608869499 0.19264164806063686 tensor(174.8479)\n",
      "26179.66481119247 26179.66481119247 -288.4502278057417 0.1807693725290334 tensor(161.5374)\n",
      "-285.55905585378724 0.0 -285.55905585378724 0.21090912245964202 tensor(168.3797)\n",
      "24465.619479496327 24465.619479496327 -288.64837471773455 0.15731446464356316 tensor(156.1360)\n",
      "-285.6791466979839 0.0 -285.6791466979839 0.13227690396024902 tensor(157.9675)\n",
      "19596.796733846306 19596.796733846306 -288.52957219307524 0.11608188255133838 tensor(139.8520)\n",
      "-286.04881013631535 0.0 -286.04881013631535 0.17100470035404564 tensor(179.3493)\n",
      "25260.76125310149 25260.76125310149 -288.7631664640658 0.08445908846499017 tensor(158.6249)\n",
      "-285.54855529335043 0.0 -285.54855529335043 0.22614716015106262 tensor(156.0835)\n",
      "23809.17941041536 23809.17941041536 -288.07633913407807 0.05514428115604977 tensor(154.1821)\n",
      "-285.57339474820367 0.0 -285.57339474820367 0.081701057706424 tensor(165.2167)\n",
      "17989.700084275803 17989.700084275803 -288.5430162865268 0.18802655306180194 tensor(134.0374)\n",
      "-285.808635720709 0.0 -285.808635720709 0.08737081058328372 tensor(158.9209)\n",
      "20912.95489605474 20912.95489605474 -288.43565167919564 0.32458095763054295 tensor(144.5112)\n",
      "-285.8299054340003 0.0 -285.8299054340003 0.14209621836050923 tensor(141.1593)\n",
      "21567.037453197558 21567.037453197558 -288.64485135085215 0.13287873751122803 tensor(146.7415)\n",
      "-285.89190978332084 0.0 -285.89190978332084 0.12258593893452145 tensor(159.7958)\n",
      "18516.342091596278 18516.342091596278 -288.42382650364175 0.1982906295225043 tensor(135.9112)\n",
      "-286.08637968448636 0.0 -286.08637968448636 0.12269855159936184 tensor(149.1566)\n",
      "16876.525918164716 16876.525918164716 -288.7183797266133 0.16817641621808074 tensor(129.7586)\n",
      "-285.6013910253705 0.0 -285.6013910253705 0.27239022627553006 tensor(143.2696)\n",
      "16031.514288052014 16031.514288052014 -288.73871078960894 0.1691220528251589 tensor(126.5260)\n",
      "-285.37823015567596 0.0 -285.37823015567596 0.06940100163323341 tensor(152.8397)\n",
      "18861.772468487725 18861.772468487725 -288.5755344285927 0.21201498699341745 tensor(137.2097)\n",
      "-285.81290998568693 0.0 -285.81290998568693 0.10760757401752688 tensor(152.1939)\n",
      "19364.27047194552 19364.27047194552 -288.3362674323965 0.10243863120897079 tensor(139.0606)\n",
      "-285.48685602898354 0.0 -285.48685602898354 0.13360320417750995 tensor(142.0715)\n",
      "20140.423019952483 20140.423019952483 -288.537893590727 0.08610997789427019 tensor(141.8088)\n",
      "-285.33640630784953 0.0 -285.33640630784953 0.1206943493041345 tensor(154.4999)\n",
      "19324.463954201176 19324.463954201176 -288.21875691788165 0.1733440756513783 tensor(138.8708)\n",
      "-285.80310316665657 0.0 -285.80310316665657 0.06382868953726113 tensor(142.1668)\n",
      "19839.73476263103 19839.73476263103 -288.32324735949965 0.13706952862424532 tensor(140.7375)\n",
      "-285.7703221697011 0.0 -285.7703221697011 0.035610537303625935 tensor(134.9871)\n",
      "24162.024354116 24162.024354116 -288.0318545783622 0.04597053515024453 tensor(155.2702)\n",
      "-286.1198739288079 0.0 -286.1198739288079 0.16800658726827813 tensor(154.6041)\n",
      "25032.408583388824 25032.408583388824 -288.8863338343921 0.1520489811073637 tensor(157.9424)\n",
      "-286.15088334252283 0.0 -286.15088334252283 0.03408283883763455 tensor(166.0584)\n",
      "18056.345799313785 18056.345799313785 -287.99303865817603 0.18167754569313216 tensor(134.2842)\n",
      "-285.39442312969885 0.0 -285.39442312969885 0.13378039402057762 tensor(157.9324)\n",
      "20876.111383302603 20876.111383302603 -288.44093664681645 0.15830550176974972 tensor(144.3444)\n",
      "-286.1359346495903 0.0 -286.1359346495903 0.11782529341379529 tensor(155.4547)\n",
      "19704.045870170496 19704.045870170496 -288.40214934486613 0.17489070489639136 tensor(140.2213)\n",
      "-285.7437919576926 0.0 -285.7437919576926 0.10764630132272308 tensor(154.9134)\n",
      "18604.27928134823 18604.27928134823 -288.32395894726983 0.28864412144732493 tensor(136.2491)\n",
      "-285.82813327846 0.0 -285.82813327846 0.07769741861232254 tensor(149.8625)\n",
      "16330.780281076579 16330.780281076579 -288.32626931862876 0.0334624566463188 tensor(127.7157)\n",
      "-285.6819504619453 0.0 -285.6819504619453 0.07560835676428784 tensor(154.5349)\n",
      "21632.511032767157 21632.511032767157 -287.9656678952972 0.1574171534458261 tensor(146.9637)\n",
      "-285.98754044584985 0.0 -285.98754044584985 0.1281449389010641 tensor(150.7026)\n",
      "24705.95072633999 24705.95072633999 -287.97203318364825 0.22747808272225994 tensor(156.9644)\n",
      "-285.4494228337505 0.0 -285.4494228337505 0.23600533377972413 tensor(149.3030)\n",
      "15293.416341525466 15293.416341525466 -288.09640374590526 0.10705684457422558 tensor(123.5373)\n",
      "-285.7993066125421 0.0 -285.7993066125421 0.15256637108003643 tensor(143.1235)\n",
      "18181.1800244589 18181.1800244589 -288.2876007849635 0.10784897066574596 tensor(134.5800)\n",
      "-285.7192086747039 0.0 -285.7192086747039 0.053031079829557064 tensor(150.9288)\n",
      "19921.057144357343 19921.057144357343 -288.51598372199214 0.1801472438709785 tensor(140.9780)\n",
      "-285.962854294694 0.0 -285.962854294694 0.03347387631611937 tensor(138.5683)\n",
      "18549.198328524108 18549.198328524108 -288.38895898329633 0.11430147358053139 tensor(136.0673)\n",
      "-286.2567226474705 0.0 -286.2567226474705 0.08928217479777216 tensor(164.4344)\n",
      "20642.066690919706 20642.066690919706 -288.14654150629855 0.22017060907700964 tensor(143.5698)\n",
      "-285.5782728707097 0.0 -285.5782728707097 0.06948467231434029 tensor(151.6489)\n",
      "20073.855428628205 20073.855428628205 -288.1857052946886 0.29562840424813897 tensor(141.5260)\n",
      "-285.6898273420615 0.0 -285.6898273420615 0.16630725681419678 tensor(156.6627)\n",
      "23027.562555714263 23027.562555714263 -288.3448087490216 0.1875985194401337 tensor(151.6090)\n",
      "-285.588353360189 0.0 -285.588353360189 0.07221749321863577 tensor(150.9824)\n",
      "19454.966904344205 19454.966904344205 -288.8989546532448 0.143160942371081 tensor(139.3201)\n",
      "-285.63358049741 0.0 -285.63358049741 0.05750920964393357 tensor(152.4493)\n",
      "23796.699566061703 23796.699566061703 -287.9442159885923 0.1722561613048145 tensor(154.1305)\n",
      "-285.7148458529482 0.0 -285.7148458529482 0.21275036003967943 tensor(157.5057)\n",
      "23835.063994504417 23835.063994504417 -287.9767271152125 0.055936852648861564 tensor(154.2528)\n",
      "-285.57786365163554 0.0 -285.57786365163554 0.10251178062643476 tensor(161.4453)\n",
      "16189.066194514078 16189.066194514078 -288.39304776007424 0.02012909996078256 tensor(127.1359)\n",
      "-285.9394350934339 0.0 -285.9394350934339 0.22389417053221866 tensor(130.7702)\n",
      "21929.250801421407 21929.250801421407 -288.15437260411716 0.1075297439902915 tensor(147.9391)\n",
      "-285.7844211839031 0.0 -285.7844211839031 0.11770058036770976 tensor(145.2944)\n",
      "21019.472147245637 21019.472147245637 -288.19426032289056 0.03361462614917414 tensor(144.8164)\n",
      "-285.9090607554422 0.0 -285.9090607554422 0.2801216339917268 tensor(173.2994)\n",
      "24876.115083220266 24876.115083220266 -288.4350202907797 0.12832187750318758 tensor(157.2872)\n",
      "-285.8858662385867 0.0 -285.8858662385867 0.2326423385475399 tensor(134.7323)\n",
      "17290.488227593574 17290.488227593574 -288.1237601128628 0.20970316806799943 tensor(131.4252)\n",
      "-285.5783390039656 0.0 -285.5783390039656 0.0670022892028162 tensor(156.3707)\n",
      "18867.389193938125 18867.389193938125 -288.5750950497478 0.19058005729404368 tensor(137.2139)\n",
      "-286.00193913858595 0.0 -286.00193913858595 0.115978517782542 tensor(151.8769)\n",
      "21171.935402262032 21171.935402262032 -287.99848631795396 0.11483598581257423 tensor(145.2955)\n",
      "-285.72102862231105 0.0 -285.72102862231105 0.17609740004032556 tensor(162.7311)\n",
      "22326.60490605424 22326.60490605424 -288.0386073235556 0.17385102004969044 tensor(149.2633)\n",
      "-286.11696894035185 0.0 -286.11696894035185 0.15151382082142242 tensor(166.2079)\n",
      "18525.139136087382 18525.139136087382 -288.08486221780083 0.03483663271901496 tensor(135.9782)\n",
      "-285.96815015187076 0.0 -285.96815015187076 0.09285203296757213 tensor(138.2408)\n",
      "20652.058943448697 20652.058943448697 -288.5140679098744 0.12832924569133616 tensor(143.5461)\n",
      "-286.08692592030343 0.0 -286.08692592030343 0.1546285887630155 tensor(146.7400)\n",
      "23777.927738301496 23777.927738301496 -288.29956128844844 0.2166973118426433 tensor(153.9240)\n",
      "-286.03741684158535 0.0 -286.03741684158535 0.1987674204969816 tensor(154.3086)\n",
      "18369.492382458855 18369.492382458855 -288.20360498341483 0.09311491831182925 tensor(135.4116)\n",
      "-285.5898556520737 0.0 -285.5898556520737 0.03092742464220043 tensor(146.2700)\n",
      "18602.28285794468 18602.28285794468 -288.1883249090725 0.18981485679862026 tensor(136.2573)\n",
      "-285.9651375152795 0.0 -285.9651375152795 0.09798357611088254 tensor(162.9336)\n",
      "21760.76345826288 21760.76345826288 -287.94918478641563 0.25387986987270633 tensor(147.3671)\n",
      "-285.90933007223003 0.0 -285.90933007223003 0.048543916879439486 tensor(164.0182)\n",
      "23052.004551912018 23052.004551912018 -288.23166980293195 0.2626966593099334 tensor(151.4757)\n",
      "-286.15701312262956 0.0 -286.15701312262956 0.1825479770378602 tensor(144.9290)\n",
      "20487.402336494117 20487.402336494117 -288.2798326268475 0.05943310448956336 tensor(142.9783)\n",
      "-286.31905303456745 0.0 -286.31905303456745 0.10370713723718465 tensor(140.6751)\n",
      "20951.27611842008 20951.27611842008 -288.23293925877766 0.13289222627067065 tensor(144.5126)\n",
      "-286.05739294407783 0.0 -286.05739294407783 0.23308452163108254 tensor(151.7950)\n",
      "18376.632422322044 18376.632422322044 -287.8233574809925 0.10693632988477675 tensor(135.3786)\n",
      "-286.08844245736447 0.0 -286.08844245736447 0.1860900501435483 tensor(171.5467)\n",
      "21076.363134148192 21076.363134148192 -288.2330408293024 0.10739505149560886 tensor(144.9945)\n",
      "-286.2352162818677 0.0 -286.2352162818677 0.23199016200732514 tensor(154.2000)\n",
      "21661.47033388354 21661.47033388354 -287.8637194630619 0.15055478449464915 tensor(147.0127)\n",
      "-286.163792015784 0.0 -286.163792015784 0.2517859614077396 tensor(145.2712)\n",
      "21890.102930637786 21890.102930637786 -288.460692476315 0.05443542440711859 tensor(147.6937)\n",
      "-286.2012929334286 0.0 -286.2012929334286 0.0869684616459143 tensor(143.2093)\n",
      "20076.21130049356 20076.21130049356 -287.9312472175786 0.06069236011027272 tensor(141.5721)\n",
      "-285.95502367213504 0.0 -285.95502367213504 0.055055305455205886 tensor(150.7958)\n",
      "23581.712597221016 23581.712597221016 -288.1857505152202 0.2678740450222033 tensor(153.3946)\n",
      "-285.91174370555535 0.0 -285.91174370555535 0.06301501663288847 tensor(154.1069)\n",
      "17711.64979864752 17711.64979864752 -288.69635422682643 0.20983523700540563 tensor(132.9462)\n",
      "-286.4500151081887 0.0 -286.4500151081887 0.040201594883369315 tensor(134.4695)\n",
      "34798.1765296607 34798.1765296607 -288.2257153357814 0.19782903918449649 tensor(185.0986)\n",
      "-285.8288588496669 0.0 -285.8288588496669 0.1182077493856359 tensor(149.8972)\n",
      "20396.60963692141 20396.60963692141 -288.16461330910477 0.1993486502292013 tensor(142.7334)\n",
      "-285.53317065820136 0.0 -285.53317065820136 0.20920187623398215 tensor(156.1074)\n",
      "23045.190334368715 23045.190334368715 -288.4931629156338 0.1113445988456974 tensor(151.5822)\n",
      "-286.0333800049979 0.0 -286.0333800049979 0.11106544915691446 tensor(161.8126)\n",
      "20581.91405904443 20581.91405904443 -288.5718365374846 0.08665123231795249 tensor(143.2681)\n",
      "-285.30488886708645 0.0 -285.30488886708645 0.16991516284453959 tensor(165.1295)\n",
      "24130.890649817193 24130.890649817193 -287.8511742937885 0.17557770370031864 tensor(152.1576)\n",
      "-286.08809010624964 0.0 -286.08809010624964 0.15150805222795405 tensor(160.5347)\n",
      "19208.636336900658 19208.636336900658 -288.2494556000532 0.09558305631339596 tensor(138.4843)\n",
      "-286.14006847206895 0.0 -286.14006847206895 0.14116343165315298 tensor(171.5797)\n",
      "21534.069425364018 21534.069425364018 -288.18298200889154 0.16613668338691656 tensor(146.5930)\n",
      "-286.167908701653 0.0 -286.167908701653 0.1688331390454889 tensor(157.3575)\n",
      "26928.07176159798 26928.07176159798 -288.2544438029408 0.1253712957624137 tensor(163.9054)\n",
      "-285.9293313963053 0.0 -285.9293313963053 0.21932464135670895 tensor(176.3483)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23795.474775542818 23795.474775542818 -288.5274882315637 0.30356889931007763 tensor(154.1901)\n",
      "-285.1827729262832 0.0 -285.1827729262832 0.1418946311663951 tensor(156.6378)\n",
      "19224.02100400642 19224.02100400642 -288.45599867016364 0.18968129677743464 tensor(138.3854)\n",
      "-285.62606895193437 0.0 -285.62606895193437 0.13258059759868943 tensor(142.7041)\n",
      "23667.233065038257 23667.233065038257 -288.40961342577515 0.23209298321446936 tensor(153.6850)\n",
      "-286.16013444276166 0.0 -286.16013444276166 0.07365081620139523 tensor(150.4744)\n",
      "23860.893357346416 23860.893357346416 -288.1094493766308 0.23214431501453328 tensor(154.2875)\n",
      "-286.28434058454536 0.0 -286.28434058454536 0.03286456625991591 tensor(149.8403)\n",
      "21377.70386144462 21377.70386144462 -288.2114292755558 0.16811685408311078 tensor(146.0131)\n",
      "-285.729869331477 0.0 -285.729869331477 0.15966489171558237 tensor(154.8468)\n",
      "20664.923273788314 20664.923273788314 -287.60827147142953 0.07925116611560677 tensor(143.6191)\n",
      "-285.73469490586814 0.0 -285.73469490586814 0.17044092524306706 tensor(164.3091)\n",
      "16841.752575326616 16841.752575326616 -288.4300127747223 0.20433895962771428 tensor(129.5785)\n",
      "-285.42579123405665 0.0 -285.42579123405665 0.10640487863467388 tensor(160.7696)\n",
      "22281.26526279329 22281.26526279329 -288.1018007946963 0.20701794559203196 tensor(149.2007)\n",
      "-286.48546582844483 0.0 -286.48546582844483 0.041543121431239664 tensor(126.5558)\n",
      "22724.8843886624 22724.8843886624 -288.01000090366927 0.13350198020715784 tensor(150.5794)\n",
      "-286.3427511247205 0.0 -286.3427511247205 0.1421752726791049 tensor(155.4343)\n",
      "16242.477770295447 16242.477770295447 -288.0111470268315 0.15790373445160505 tensor(127.2922)\n",
      "-286.3698193841657 0.0 -286.3698193841657 0.14689134684145247 tensor(159.5544)\n",
      "18303.35559721532 18303.35559721532 -288.48558464172976 0.1414678747236381 tensor(135.1176)\n",
      "-286.1442467955703 0.0 -286.1442467955703 0.2265521257890888 tensor(144.9721)\n",
      "19311.95282021828 19311.95282021828 -288.2513116203722 0.14942658105436163 tensor(138.8948)\n",
      "-286.30712436543274 0.0 -286.30712436543274 0.1837913163207206 tensor(158.4399)\n",
      "17971.094340717762 17971.094340717762 -288.3791966539984 0.04961688492708632 tensor(133.8010)\n",
      "-285.9278216978838 0.0 -285.9278216978838 0.10441606626453316 tensor(148.1979)\n",
      "16605.5538814785 16605.5538814785 -288.3226817488314 0.24364883892706385 tensor(128.6721)\n",
      "-286.2531978272718 0.0 -286.2531978272718 0.06834159701913654 tensor(133.6254)\n",
      "22986.303990267435 22986.303990267435 -288.0933370632181 0.24310561500471153 tensor(151.4856)\n",
      "-286.36596119694434 0.0 -286.36596119694434 0.21700136635758357 tensor(159.2396)\n",
      "17724.59212519648 17724.59212519648 -288.60709172952056 0.028953656387443377 tensor(132.9550)\n",
      "-286.32872236754827 0.0 -286.32872236754827 0.06432350163678026 tensor(147.0684)\n",
      "25112.324319475105 25112.324319475105 -287.991554091163 0.15192385335420155 tensor(158.1234)\n",
      "-286.10785071226826 0.0 -286.10785071226826 0.30436485561757104 tensor(155.2852)\n",
      "17597.05054836078 17597.05054836078 -288.12721647270655 0.21102610538442618 tensor(132.5367)\n",
      "-285.8751148252446 0.0 -285.8751148252446 0.19360250243638824 tensor(154.3012)\n",
      "18248.36389327713 18248.36389327713 -287.7404874818332 0.2746815418998385 tensor(134.9210)\n",
      "-286.20841285497545 0.0 -286.20841285497545 0.07405375519170482 tensor(154.8780)\n",
      "20612.388616198026 20612.388616198026 -288.3639311548762 0.19264554877736975 tensor(143.3908)\n",
      "-285.9255225687166 0.0 -285.9255225687166 0.1324584875958911 tensor(148.9802)\n",
      "26343.670971144205 26343.670971144205 -288.2275118214258 0.22393373684531304 tensor(162.1153)\n",
      "-285.7061316520842 0.0 -285.7061316520842 0.10564933530862636 tensor(158.0848)\n",
      "22109.28830626829 22109.28830626829 -288.0955258946874 0.25501748458388895 tensor(148.5547)\n",
      "-286.120112169113 0.0 -286.120112169113 0.18455186838335844 tensor(146.2565)\n",
      "23119.997695636896 23119.997695636896 -288.3288143992036 0.2355634248319675 tensor(151.9118)\n",
      "-285.26459435292713 0.0 -285.26459435292713 0.1647428515849875 tensor(167.2408)\n",
      "22938.15969260395 22938.15969260395 -288.2413382969804 0.31304196371622145 tensor(151.2058)\n",
      "-285.90377022344194 0.0 -285.90377022344194 0.037843881332206945 tensor(147.3973)\n",
      "21324.634728928868 21324.634728928868 -288.30627731423635 0.22531783436945685 tensor(145.9073)\n",
      "-286.4535277628745 0.0 -286.4535277628745 0.11903920100604751 tensor(166.8093)\n",
      "23023.132187496816 23023.132187496816 -288.14114001490043 0.12211494589717041 tensor(151.5176)\n",
      "-286.13629802510155 0.0 -286.13629802510155 0.2320624456796376 tensor(145.9736)\n",
      "24410.476851815776 24410.476851815776 -287.81379119330705 0.05170400210067183 tensor(156.0344)\n",
      "-286.36593511102996 0.0 -286.36593511102996 0.12334770040338575 tensor(170.5704)\n",
      "16222.296270688397 16222.296270688397 -288.3046907979924 0.1558861956319168 tensor(127.2531)\n",
      "== Era 4 | Epoch 0 metrics ==\n",
      "\tloss 10523.4\n",
      "\tforce 10666.4\n",
      "\tdkl -287.112\n",
      "\tlogp 85.3615\n",
      "\tlogq -201.75\n",
      "\tess 0.154396\n",
      "-285.75361170176814 0.0 -285.75361170176814 0.0901439621744704 tensor(147.0718)\n",
      "19753.785774191103 19753.785774191103 -287.98529300072363 0.07070444943307805 tensor(139.5824)\n",
      "-286.313718101702 0.0 -286.313718101702 0.19634829147857594 tensor(167.0498)\n",
      "18666.62160103418 18666.62160103418 -287.86786933629605 0.17057270779369635 tensor(136.4455)\n",
      "-286.66933219254247 0.0 -286.66933219254247 0.10897382384251637 tensor(150.7143)\n",
      "22214.890419564545 22214.890419564545 -288.4141049292898 0.11337924306885004 tensor(148.3371)\n",
      "-286.1509805152373 0.0 -286.1509805152373 0.08932851151270774 tensor(149.7463)\n",
      "25700.182703919636 25700.182703919636 -288.3858312857225 0.14434270058286314 tensor(160.0215)\n",
      "-286.1113917166147 0.0 -286.1113917166147 0.0416065710587411 tensor(176.2001)\n",
      "19253.512899119716 19253.512899119716 -288.8209921054352 0.14327772910879255 tensor(138.5961)\n",
      "-286.24394897690445 0.0 -286.24394897690445 0.06906626435947887 tensor(152.3411)\n",
      "23747.522461722554 23747.522461722554 -288.7021547389564 0.10950012607188692 tensor(153.9151)\n",
      "-286.0276304019535 0.0 -286.0276304019535 0.19016644455221343 tensor(161.0330)\n",
      "21089.480221249014 21089.480221249014 -288.3235369711648 0.19878257343898023 tensor(145.0565)\n",
      "-286.01823498061714 0.0 -286.01823498061714 0.2794128608687025 tensor(154.6192)\n",
      "21783.24705785471 21783.24705785471 -287.6071527256828 0.13919183089749562 tensor(147.4049)\n",
      "-285.6913883061778 0.0 -285.6913883061778 0.1753782090727442 tensor(164.8577)\n",
      "16719.661573569465 16719.661573569465 -288.10442908681785 0.22878716042045114 tensor(129.1572)\n",
      "-286.2144398377883 0.0 -286.2144398377883 0.14747418864675338 tensor(155.6062)\n",
      "23196.80101161453 23196.80101161453 -288.1040477190994 0.3417771919283839 tensor(152.0640)\n",
      "-286.25621647096943 0.0 -286.25621647096943 0.19721825115014768 tensor(141.5371)\n",
      "25313.882088409893 25313.882088409893 -288.28872049429935 0.09235509732448707 tensor(158.6414)\n",
      "-286.0800559953898 0.0 -286.0800559953898 0.1756101597315826 tensor(169.6935)\n",
      "15621.298472814535 15621.298472814535 -288.24048820241677 0.07894989547385284 tensor(124.6258)\n",
      "-286.0501528343828 0.0 -286.0501528343828 0.13310507411455477 tensor(154.2598)\n",
      "26373.57176080811 26373.57176080811 -287.98467591435747 0.3042915028121869 tensor(162.1342)\n",
      "-286.2395643374708 0.0 -286.2395643374708 0.12962630102663739 tensor(144.7443)\n",
      "25266.058173749683 25266.058173749683 -288.0898755867224 0.1085304414863013 tensor(158.6800)\n",
      "-286.4879779997793 0.0 -286.4879779997793 0.3208587016434519 tensor(146.7072)\n",
      "21838.69146902477 21838.69146902477 -288.07197951693564 0.1931905870151033 tensor(147.4697)\n",
      "-285.82680939730676 0.0 -285.82680939730676 0.11251823552289988 tensor(161.8409)\n",
      "23525.454759229433 23525.454759229433 -288.06486519920406 0.17790443794094496 tensor(153.1190)\n",
      "-286.0377868806913 0.0 -286.0377868806913 0.15384784394399192 tensor(189.1844)\n",
      "19606.677391138404 19606.677391138404 -288.773371336768 0.15754350971744455 tensor(139.8920)\n",
      "-286.2081304139465 0.0 -286.2081304139465 0.30120698938270146 tensor(145.5132)\n",
      "18522.532186619654 18522.532186619654 -288.31381193519064 0.153129663534639 tensor(135.9479)\n",
      "-285.84210152104345 0.0 -285.84210152104345 0.2491027580570136 tensor(155.7438)\n",
      "18038.333485262883 18038.333485262883 -288.1397703281672 0.16382995704053893 tensor(134.1007)\n",
      "-285.73782902032076 0.0 -285.73782902032076 0.07605348581406299 tensor(163.8271)\n",
      "22606.266691603287 22606.266691603287 -288.25558790913954 0.06830631022278234 tensor(150.0407)\n",
      "-286.2933177595856 0.0 -286.2933177595856 0.04733569059383843 tensor(161.4860)\n",
      "26549.394912544296 26549.394912544296 -288.38382890612513 0.2796867628615937 tensor(162.6977)\n",
      "-286.72817893249317 0.0 -286.72817893249317 0.1569907071959254 tensor(152.0619)\n",
      "19256.951432856265 19256.951432856265 -288.3390528893178 0.07079790591557546 tensor(138.0946)\n",
      "-286.39543871664023 0.0 -286.39543871664023 0.12493718623263969 tensor(162.8630)\n",
      "20200.836962168243 20200.836962168243 -288.2264478134042 0.1671760757167872 tensor(142.0155)\n",
      "-285.9888354032421 0.0 -285.9888354032421 0.28558718704616876 tensor(170.4560)\n",
      "27119.16335301708 27119.16335301708 -288.1101110421747 0.09103033589620682 tensor(163.9782)\n",
      "-285.7141435061079 0.0 -285.7141435061079 0.03924900372374892 tensor(154.4701)\n",
      "24155.851091703465 24155.851091703465 -288.39061116701885 0.29903090388990433 tensor(155.0413)\n",
      "-286.7345881371809 0.0 -286.7345881371809 0.26542658681912235 tensor(166.7741)\n",
      "25858.90106981579 25858.90106981579 -288.41252633638567 0.18396470621107977 tensor(158.5035)\n",
      "-285.9165666994197 0.0 -285.9165666994197 0.13863843799022224 tensor(161.2359)\n",
      "24988.77724800527 24988.77724800527 -288.1930948485805 0.22288841374605178 tensor(157.5604)\n",
      "-286.5022568981683 0.0 -286.5022568981683 0.08463938136331056 tensor(156.8693)\n",
      "27121.424668209314 27121.424668209314 -288.2443718753668 0.28287530107434095 tensor(164.4451)\n",
      "-286.51594648984724 0.0 -286.51594648984724 0.2078278201850847 tensor(164.4372)\n",
      "25554.563425114822 25554.563425114822 -288.1139133389526 0.25638845662665816 tensor(159.6709)\n",
      "-286.4745435874132 0.0 -286.4745435874132 0.27910222338943624 tensor(153.3076)\n",
      "32691.097052579516 32691.097052579516 -288.6839670925969 0.33547907597388543 tensor(174.4098)\n",
      "-286.1473156869655 0.0 -286.1473156869655 0.14160542819384717 tensor(153.9234)\n",
      "22232.809183791 22232.809183791 -288.28198066087907 0.37792161532322627 tensor(149.1469)\n",
      "-286.0569627401778 0.0 -286.0569627401778 0.31769978178731667 tensor(162.4986)\n",
      "31546.97729183284 31546.97729183284 -288.4470165491084 0.21162879889439148 tensor(167.8981)\n",
      "-286.6301334362466 0.0 -286.6301334362466 0.20562094249186263 tensor(152.8384)\n",
      "30751.630158458196 30751.630158458196 -288.02207396899075 0.14445203164271442 tensor(173.1014)\n",
      "-286.01409136679274 0.0 -286.01409136679274 0.07496094531078255 tensor(177.9166)\n",
      "27521.761139144146 27521.761139144146 -288.0913082169697 0.16231906706310545 tensor(165.7152)\n",
      "-286.144521004126 0.0 -286.144521004126 0.23999288013090334 tensor(159.2340)\n",
      "19841.194005606456 19841.194005606456 -288.20968452366907 0.16511169415499868 tensor(140.6983)\n",
      "-286.21042068258123 0.0 -286.21042068258123 0.1793479050983302 tensor(170.0476)\n",
      "22644.88820360178 22644.88820360178 -287.9496244978101 0.26972929067703255 tensor(150.2343)\n",
      "-286.1951019409085 0.0 -286.1951019409085 0.21874720226953073 tensor(149.7428)\n",
      "18374.840583433444 18374.840583433444 -288.04181605072864 0.2812608666350402 tensor(135.5527)\n",
      "-286.33415855732073 0.0 -286.33415855732073 0.13011471300092148 tensor(160.7412)\n",
      "22566.456975146797 22566.456975146797 -287.7425141343549 0.2265123789159334 tensor(149.5198)\n",
      "-286.72179653518356 0.0 -286.72179653518356 0.17481938106608547 tensor(160.0784)\n",
      "16459.514995304504 16459.514995304504 -288.4817307598779 0.13257034679520127 tensor(128.1819)\n",
      "-286.42577042190806 0.0 -286.42577042190806 0.2720852794979817 tensor(165.1675)\n",
      "22977.305637820704 22977.305637820704 -288.055630050912 0.13060372257800945 tensor(151.0458)\n",
      "-286.25609405453264 0.0 -286.25609405453264 0.15043753857087844 tensor(154.3636)\n",
      "26025.923618049466 26025.923618049466 -288.07396475359786 0.05399165789058604 tensor(161.2019)\n",
      "-286.20794310600434 0.0 -286.20794310600434 0.25077100883653536 tensor(166.1787)\n",
      "29900.430226985478 29900.430226985478 -288.37793789526154 0.23063248281243443 tensor(172.7447)\n",
      "-286.4272730402737 0.0 -286.4272730402737 0.15804655963222453 tensor(198.2398)\n",
      "27537.653471058013 27537.653471058013 -288.13051775230787 0.17241412273158743 tensor(165.3187)\n",
      "-286.04412510562724 0.0 -286.04412510562724 0.24239928016856607 tensor(148.2804)\n",
      "21896.503850363177 21896.503850363177 -288.24094822607884 0.3037052012277614 tensor(147.6868)\n",
      "-285.836261847311 0.0 -285.836261847311 0.16413368188747046 tensor(173.2472)\n",
      "20117.431936538516 20117.431936538516 -288.0419466460455 0.27027447260774695 tensor(141.6314)\n",
      "-286.48003747391095 0.0 -286.48003747391095 0.03237084157043265 tensor(163.3375)\n",
      "18909.009405988465 18909.009405988465 -288.08319116472325 0.18793183984729508 tensor(137.3095)\n",
      "-285.8771155010381 0.0 -285.8771155010381 0.3087568274942574 tensor(148.7187)\n",
      "22011.247679149885 22011.247679149885 -287.82795569095 0.26226323175116123 tensor(148.1758)\n",
      "-286.4769361078992 0.0 -286.4769361078992 0.12759530029512484 tensor(152.2833)\n",
      "17717.415666174256 17717.415666174256 -288.0809986834448 0.2089149191838412 tensor(132.9860)\n",
      "-286.1196445809014 0.0 -286.1196445809014 0.192506630028097 tensor(136.7118)\n",
      "26507.53417435881 26507.53417435881 -288.2155407759508 0.23524289790397707 tensor(162.6188)\n",
      "-286.15136448064663 0.0 -286.15136448064663 0.05100707292984313 tensor(153.6110)\n",
      "22175.020924653356 22175.020924653356 -288.2953722627629 0.14849165832706449 tensor(148.8204)\n",
      "-286.32150408162147 0.0 -286.32150408162147 0.24016062510571418 tensor(157.2196)\n",
      "16289.456931676084 16289.456931676084 -288.0278094597686 0.23283883018545457 tensor(127.5679)\n",
      "-286.34853318121515 0.0 -286.34853318121515 0.030699772368506927 tensor(145.0145)\n",
      "20313.0803694026 20313.0803694026 -288.3404507537452 0.07873922312947941 tensor(142.4023)\n",
      "-285.73069101226434 0.0 -285.73069101226434 0.08185346366587838 tensor(155.4054)\n",
      "18593.110834676998 18593.110834676998 -287.9033997214919 0.15569874131848738 tensor(136.0425)\n",
      "-286.545279906754 0.0 -286.545279906754 0.039415716196531086 tensor(157.6633)\n",
      "18607.220045485836 18607.220045485836 -288.3803648414616 0.2701000756745268 tensor(136.2769)\n",
      "-286.4885239888924 0.0 -286.4885239888924 0.11071399247893081 tensor(150.1905)\n",
      "30651.917033537626 30651.917033537626 -287.9660120611736 0.07504849860627712 tensor(174.8342)\n",
      "-285.8943116261421 0.0 -285.8943116261421 0.2835986305650341 tensor(148.0424)\n",
      "24801.899067966013 24801.899067966013 -288.38287303342406 0.1184950542872861 tensor(157.3332)\n",
      "-286.9630032866477 0.0 -286.9630032866477 0.17380554243271756 tensor(176.6306)\n",
      "18774.857721629447 18774.857721629447 -288.5536020942847 0.354582758049612 tensor(136.8355)\n",
      "-285.84400321409015 0.0 -285.84400321409015 0.13232843665756663 tensor(153.4026)\n",
      "23170.15961477202 23170.15961477202 -288.5107799427317 0.17570394525755184 tensor(152.0293)\n",
      "-286.14982178150206 0.0 -286.14982178150206 0.11706018663654402 tensor(162.8826)\n",
      "24082.212051133407 24082.212051133407 -288.35963459311046 0.2139454647598429 tensor(154.9131)\n",
      "-285.9074739047886 0.0 -285.9074739047886 0.19127543225279436 tensor(173.9151)\n",
      "20457.682451706565 20457.682451706565 -288.2168229932179 0.09597774014339697 tensor(142.9668)\n",
      "-285.9801751642565 0.0 -285.9801751642565 0.1913236722012857 tensor(173.0188)\n",
      "22728.546117105034 22728.546117105034 -288.1631154928738 0.1282479628771282 tensor(150.6650)\n",
      "-286.08836935328054 0.0 -286.08836935328054 0.21197530338365264 tensor(156.4979)\n",
      "23947.748419528347 23947.748419528347 -288.5137283549285 0.20246694766410306 tensor(154.6429)\n",
      "-286.5075770090614 0.0 -286.5075770090614 0.08342878079664541 tensor(155.8240)\n",
      "35875.453592816135 35875.453592816135 -288.3720356648861 0.18497275425610563 tensor(188.6589)\n",
      "-285.94232558521213 0.0 -285.94232558521213 0.26837270429246823 tensor(159.7253)\n",
      "34224.75287720226 34224.75287720226 -288.30183921896753 0.1419415139422681 tensor(184.6101)\n",
      "-285.7853166462131 0.0 -285.7853166462131 0.1746135621776867 tensor(152.9177)\n",
      "32169.249983853057 32169.249983853057 -288.03491851654974 0.09643492599136996 tensor(178.1531)\n",
      "-285.95367517711634 0.0 -285.95367517711634 0.1676878408823445 tensor(162.1201)\n",
      "21121.750509871155 21121.750509871155 -288.3865454130831 0.1257321366871952 tensor(145.1724)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.7382818993632 0.0 -286.7382818993632 0.21422861956986836 tensor(180.4364)\n",
      "32286.215908836282 32286.215908836282 -288.528141196586 0.19490587215473668 tensor(179.2502)\n",
      "-286.16637286871463 0.0 -286.16637286871463 0.11926035289795994 tensor(173.8123)\n",
      "17964.738339488846 17964.738339488846 -288.23274408642476 0.16495345586593335 tensor(133.1403)\n",
      "-286.2948922360148 0.0 -286.2948922360148 0.1221195234678075 tensor(154.0058)\n",
      "28204.30900667056 28204.30900667056 -287.92143430928115 0.3131659354765757 tensor(167.6665)\n",
      "-286.072719867648 0.0 -286.072719867648 0.34747524233604626 tensor(146.0601)\n",
      "24487.279472826685 24487.279472826685 -288.26789801078553 0.07812000901436336 tensor(156.2495)\n",
      "-286.5187916459133 0.0 -286.5187916459133 0.2054130716103536 tensor(139.1427)\n",
      "22299.57135237942 22299.57135237942 -287.7516303980363 0.08002116815391783 tensor(148.9008)\n",
      "-285.9980879487114 0.0 -285.9980879487114 0.10600255382478622 tensor(149.5517)\n",
      "19188.299649262462 19188.299649262462 -288.2399579452674 0.15577570784783898 tensor(138.3313)\n",
      "-285.87720760014105 0.0 -285.87720760014105 0.29359946131557474 tensor(149.3047)\n",
      "20310.293467968986 20310.293467968986 -287.8620446329101 0.19510405867931943 tensor(142.2645)\n",
      "-286.4858165471335 0.0 -286.4858165471335 0.17365308380755706 tensor(157.7675)\n",
      "20180.14051211789 20180.14051211789 -288.08834773060613 0.20774387013755638 tensor(141.9532)\n",
      "-286.2814111943349 0.0 -286.2814111943349 0.13832837739918022 tensor(154.8963)\n",
      "26695.033190326438 26695.033190326438 -288.2317458111935 0.2169724653116283 tensor(163.1708)\n",
      "-286.1970893913747 0.0 -286.1970893913747 0.23427934883344942 tensor(159.3326)\n",
      "28930.9310861715 28930.9310861715 -288.32680605646755 0.2929509966041193 tensor(169.0142)\n",
      "-286.24651429466945 0.0 -286.24651429466945 0.2158088149272018 tensor(167.3189)\n",
      "22911.339243188162 22911.339243188162 -288.01588900319496 0.1439983779786336 tensor(150.4015)\n",
      "-286.491914958139 0.0 -286.491914958139 0.13962845335982024 tensor(150.6607)\n",
      "26175.686344587073 26175.686344587073 -288.092247091581 0.19920028325295794 tensor(161.2453)\n",
      "-286.2276298857022 0.0 -286.2276298857022 0.13347710448515687 tensor(152.0540)\n",
      "36190.814991934894 36190.814991934894 -288.0776432851827 0.2517673261213629 tensor(189.8352)\n",
      "-286.08728771856454 0.0 -286.08728771856454 0.11475796347511381 tensor(187.4257)\n",
      "19695.156870961342 19695.156870961342 -288.1479763912188 0.19671564147861978 tensor(140.2888)\n",
      "-286.1522744557142 0.0 -286.1522744557142 0.08620125188275221 tensor(155.8436)\n",
      "21034.038386389384 21034.038386389384 -288.2967833548574 0.2221239503226523 tensor(144.9376)\n",
      "-286.22676030330814 0.0 -286.22676030330814 0.062624704855606 tensor(142.7003)\n",
      "26165.015012162658 26165.015012162658 -288.00886661968855 0.2393141346453709 tensor(161.5930)\n",
      "-286.4581796058052 0.0 -286.4581796058052 0.04214978203784832 tensor(156.1933)\n",
      "33339.4613730033 33339.4613730033 -287.73164842411893 0.06540930788144822 tensor(182.0650)\n",
      "-286.55090793593956 0.0 -286.55090793593956 0.11694966990580222 tensor(152.6934)\n",
      "26593.2878372211 26593.2878372211 -288.4881664763263 0.06039869479548884 tensor(162.7923)\n",
      "-286.44869836470116 0.0 -286.44869836470116 0.30728485415667206 tensor(187.4414)\n",
      "24072.737477564253 24072.737477564253 -287.9362651672004 0.18252291691360326 tensor(155.0090)\n",
      "-286.9432585502857 0.0 -286.9432585502857 0.1447180195807678 tensor(152.1330)\n",
      "30794.19495789722 30794.19495789722 -288.1450319754533 0.2570629843174064 tensor(174.2650)\n",
      "-285.8810750528174 0.0 -285.8810750528174 0.21549920169026335 tensor(167.7093)\n",
      "21382.21266829067 21382.21266829067 -288.58043916754116 0.22332873948832946 tensor(145.4683)\n",
      "-286.2215590776615 0.0 -286.2215590776615 0.2243095966586257 tensor(161.3778)\n",
      "22022.71855597936 22022.71855597936 -288.11795962752774 0.2570066653413948 tensor(147.5422)\n",
      "-286.2103836559587 0.0 -286.2103836559587 0.21043967791664783 tensor(158.6662)\n",
      "26452.333612656977 26452.333612656977 -288.07668137424605 0.05473137476335528 tensor(161.4284)\n",
      "-286.22093772045014 0.0 -286.22093772045014 0.13175375451351387 tensor(162.6805)\n",
      "19894.606901623607 19894.606901623607 -288.5167423049552 0.047814441525170066 tensor(140.7199)\n",
      "-286.1642034891299 0.0 -286.1642034891299 0.10565810576399509 tensor(190.3671)\n",
      "19724.258399688548 19724.258399688548 -288.2971040784801 0.19387288150453058 tensor(140.3908)\n",
      "-285.99542809634016 0.0 -285.99542809634016 0.12377849201766401 tensor(192.3068)\n",
      "22074.251318172624 22074.251318172624 -288.17924400494866 0.09325243308000551 tensor(148.4604)\n",
      "-286.388410558013 0.0 -286.388410558013 0.23480039395486735 tensor(173.8051)\n",
      "24411.573182849133 24411.573182849133 -288.1867125141824 0.2421047941819062 tensor(156.1259)\n",
      "-286.45249561441585 0.0 -286.45249561441585 0.09626781223648681 tensor(159.7154)\n",
      "22112.333805458526 22112.333805458526 -288.525194083221 0.20896976091426045 tensor(148.3749)\n",
      "-286.08225293937505 0.0 -286.08225293937505 0.1315625523218773 tensor(159.1265)\n",
      "24003.290542694085 24003.290542694085 -288.2197820647325 0.2419312490628046 tensor(154.5750)\n",
      "-286.22147930004013 0.0 -286.22147930004013 0.10311669219598187 tensor(158.3791)\n",
      "19506.313264517783 19506.313264517783 -288.13253286353813 0.1634605559063556 tensor(139.3281)\n",
      "-286.521055529764 0.0 -286.521055529764 0.28132996576960984 tensor(162.7725)\n",
      "20339.57479270225 20339.57479270225 -288.07084542987116 0.14628328069809798 tensor(141.5221)\n",
      "-286.28206289605833 0.0 -286.28206289605833 0.1169472805677953 tensor(168.9287)\n",
      "19945.919142030034 19945.919142030034 -288.0276625980314 0.137705533451122 tensor(140.7829)\n",
      "-286.53993266706556 0.0 -286.53993266706556 0.08262084359254945 tensor(163.3917)\n",
      "23427.130629896907 23427.130629896907 -287.9527208329722 0.20798002741846364 tensor(152.9792)\n",
      "-286.3498825382214 0.0 -286.3498825382214 0.29647602175316595 tensor(161.1420)\n",
      "21806.55801290687 21806.55801290687 -288.6485734114047 0.3288296803890127 tensor(147.5254)\n",
      "== Era 5 | Epoch 0 metrics ==\n",
      "\tloss 11861.2\n",
      "\tforce 12004.3\n",
      "\tdkl -287.228\n",
      "\tlogp 85.6799\n",
      "\tlogq -201.548\n",
      "\tess 0.170873\n",
      "-286.3848512622946 0.0 -286.3848512622946 0.13982461292075257 tensor(160.9911)\n",
      "22527.576179046635 22527.576179046635 -288.1761044751608 0.08622562726753592 tensor(149.8365)\n",
      "-286.169909129555 0.0 -286.169909129555 0.071926464123611 tensor(188.3496)\n",
      "24023.092325677848 24023.092325677848 -287.85685638209884 0.18694019214537388 tensor(154.8254)\n",
      "-286.47653806447215 0.0 -286.47653806447215 0.2340745173576289 tensor(152.8965)\n",
      "26818.229379519027 26818.229379519027 -288.34585099993546 0.20700043705137913 tensor(163.5696)\n",
      "-286.3097995054467 0.0 -286.3097995054467 0.29725819161284356 tensor(137.6103)\n",
      "25122.57024385818 25122.57024385818 -287.9726041113517 0.12191923574687777 tensor(157.5792)\n",
      "-286.0907897419446 0.0 -286.0907897419446 0.18445853325195818 tensor(157.5224)\n",
      "24078.82131057814 24078.82131057814 -288.22021690062246 0.18522501188013066 tensor(154.6676)\n",
      "-286.37161309960936 0.0 -286.37161309960936 0.2945984229899324 tensor(160.6199)\n",
      "23961.11544326437 23961.11544326437 -288.01798139905765 0.20386679103011804 tensor(154.5397)\n",
      "-286.2740112930094 0.0 -286.2740112930094 0.12215428185071495 tensor(163.3992)\n",
      "17304.98665064675 17304.98665064675 -288.0937434490779 0.17446617515939905 tensor(131.0876)\n",
      "-286.26883453236104 0.0 -286.26883453236104 0.12912503769521624 tensor(157.7180)\n",
      "17936.632975519708 17936.632975519708 -288.0948433127773 0.19524019389082098 tensor(133.7362)\n",
      "-286.3019472314279 0.0 -286.3019472314279 0.06632008414987102 tensor(144.6182)\n",
      "25185.282764480726 25185.282764480726 -287.975641915378 0.26785524600510074 tensor(158.2653)\n",
      "-286.20053987669746 0.0 -286.20053987669746 0.26095128318647026 tensor(158.3544)\n",
      "18454.84518525561 18454.84518525561 -287.9115992658166 0.2820087649725819 tensor(135.7615)\n",
      "-286.3233668122485 0.0 -286.3233668122485 0.15167444211864145 tensor(139.9178)\n",
      "18650.81699529147 18650.81699529147 -288.3211633596229 0.2700951421181584 tensor(136.4483)\n",
      "-286.1133596416099 0.0 -286.1133596416099 0.1859426451433809 tensor(160.7503)\n",
      "28632.61559635983 28632.61559635983 -288.1704514968925 0.3053997944060777 tensor(169.0433)\n",
      "-286.2529092038457 0.0 -286.2529092038457 0.14734615978840299 tensor(144.3079)\n",
      "19853.959131053605 19853.959131053605 -288.15597862654784 0.25437131173059513 tensor(140.7774)\n",
      "-286.706008869175 0.0 -286.706008869175 0.19187881655307013 tensor(162.1638)\n",
      "28667.49799508368 28667.49799508368 -288.4288242880029 0.16884703339144658 tensor(166.9919)\n",
      "-286.4385353973414 0.0 -286.4385353973414 0.17327276887845905 tensor(154.4706)\n",
      "27122.503798069178 27122.503798069178 -287.9900709641648 0.12563711529210322 tensor(164.2481)\n",
      "-286.21735889892574 0.0 -286.21735889892574 0.0838744450506878 tensor(201.4762)\n",
      "18652.425093672773 18652.425093672773 -287.9040545311989 0.3304247377221927 tensor(136.5198)\n",
      "-286.4775320661711 0.0 -286.4775320661711 0.14097794335136857 tensor(167.0332)\n",
      "21630.223443149076 21630.223443149076 -288.27366786305345 0.13084649381096833 tensor(146.9005)\n",
      "-286.4597989676236 0.0 -286.4597989676236 0.14592914838134402 tensor(142.1418)\n",
      "18871.310427579316 18871.310427579316 -287.9187061959901 0.16624741465210088 tensor(137.2346)\n",
      "-286.44709017491004 0.0 -286.44709017491004 0.22620104112366324 tensor(138.6675)\n",
      "23210.672424694894 23210.672424694894 -288.0579941180587 0.20345943853182577 tensor(152.2265)\n",
      "-286.6228214040102 0.0 -286.6228214040102 0.31629160632857994 tensor(168.8586)\n",
      "20232.50790229094 20232.50790229094 -288.1666471198988 0.22743614633988943 tensor(142.1158)\n",
      "-286.77791835826633 0.0 -286.77791835826633 0.25076829069282164 tensor(144.8100)\n",
      "21574.461591564308 21574.461591564308 -287.8100421511126 0.12989777954475856 tensor(146.7654)\n",
      "-286.2483215307206 0.0 -286.2483215307206 0.3258137084537949 tensor(164.8414)\n",
      "22063.623191410778 22063.623191410778 -288.07734551942747 0.14393277602553822 tensor(148.3669)\n",
      "-286.1172812322005 0.0 -286.1172812322005 0.22393470820390662 tensor(204.8357)\n",
      "19506.26288483782 19506.26288483782 -288.2470543432465 0.36883878074331716 tensor(139.5648)\n",
      "-286.2610006085362 0.0 -286.2610006085362 0.22586976845671838 tensor(166.2105)\n",
      "30200.337909469115 30200.337909469115 -288.06874382728154 0.1307419367586842 tensor(172.8216)\n",
      "-286.1715425364158 0.0 -286.1715425364158 0.12049572105169813 tensor(154.7984)\n",
      "20690.66414973917 20690.66414973917 -288.18822656400323 0.20375921947861206 tensor(143.6365)\n",
      "-286.4127171746253 0.0 -286.4127171746253 0.18638069301086935 tensor(142.4311)\n",
      "19048.795068886495 19048.795068886495 -288.39439286138474 0.18499379170574023 tensor(137.7522)\n",
      "-286.29384211678774 0.0 -286.29384211678774 0.14089980071665756 tensor(149.3580)\n",
      "21093.208999448318 21093.208999448318 -287.5583849654583 0.2915322553439576 tensor(145.0690)\n",
      "-286.5371498331133 0.0 -286.5371498331133 0.2730112692367528 tensor(143.8308)\n",
      "20558.328361138138 20558.328361138138 -288.28892421559044 0.06184454316749311 tensor(142.6288)\n",
      "-286.47345966947137 0.0 -286.47345966947137 0.16894676120406882 tensor(145.0568)\n",
      "18902.45183507104 18902.45183507104 -287.98624176378837 0.2594057925850342 tensor(137.4056)\n",
      "-286.4945952395277 0.0 -286.4945952395277 0.20113997795942914 tensor(171.4022)\n",
      "26724.290975204174 26724.290975204174 -288.6219234076791 0.10049309217662651 tensor(163.1719)\n",
      "-286.3799382487359 0.0 -286.3799382487359 0.21056816236609904 tensor(162.7118)\n",
      "22682.013284495923 22682.013284495923 -287.8277366624694 0.3055615874657138 tensor(150.4485)\n",
      "-286.6144797754831 0.0 -286.6144797754831 0.18516786954021525 tensor(141.6601)\n",
      "21038.27666676878 21038.27666676878 -288.35275374566487 0.08204582773759989 tensor(144.9223)\n",
      "-286.2602891189565 0.0 -286.2602891189565 0.18873199829628012 tensor(174.2919)\n",
      "28062.41968450246 28062.41968450246 -287.9540445811292 0.1549312357754601 tensor(167.2407)\n",
      "-285.85757051488207 0.0 -285.85757051488207 0.09183040439087141 tensor(184.6588)\n",
      "27439.370411048872 27439.370411048872 -288.1841715786269 0.2657108135101259 tensor(165.4305)\n",
      "-286.4227033813904 0.0 -286.4227033813904 0.13080149184271686 tensor(155.1164)\n",
      "32306.879439369513 32306.879439369513 -288.36251758086786 0.27891408676894225 tensor(179.3809)\n",
      "-286.0116731803372 0.0 -286.0116731803372 0.10283487915753341 tensor(164.1784)\n",
      "25839.30682463036 25839.30682463036 -287.82869738620803 0.048970229709117276 tensor(160.5170)\n",
      "-286.49740090901474 0.0 -286.49740090901474 0.17615745062720503 tensor(160.3727)\n",
      "28013.771883283116 28013.771883283116 -288.17307834469943 0.1326614399611343 tensor(167.1252)\n",
      "-285.6938792418373 0.0 -285.6938792418373 0.07543902636279161 tensor(176.5009)\n",
      "24778.18999365327 24778.18999365327 -287.90936472638526 0.08215584593531451 tensor(157.1310)\n",
      "-286.3764845206756 0.0 -286.3764845206756 0.12211254214437421 tensor(156.9364)\n",
      "22021.133007907178 22021.133007907178 -287.83810070198865 0.05049866458664528 tensor(148.1303)\n",
      "-286.61495621491736 0.0 -286.61495621491736 0.10180746203728488 tensor(176.2973)\n",
      "22775.096711587717 22775.096711587717 -288.4007948286262 0.2751352508755351 tensor(150.0250)\n",
      "-286.2910398621845 0.0 -286.2910398621845 0.2363168174783134 tensor(149.8932)\n",
      "22635.24704292976 22635.24704292976 -287.95441059579457 0.12141155845187769 tensor(150.3009)\n",
      "-286.27969893516195 0.0 -286.27969893516195 0.19804370201048133 tensor(154.1396)\n",
      "29383.987843511557 29383.987843511557 -288.12323621872525 0.16756908162052644 tensor(170.8843)\n",
      "-286.482574469778 0.0 -286.482574469778 0.10113511808048181 tensor(178.5459)\n",
      "25782.883716811564 25782.883716811564 -288.0828358413045 0.07634226925100362 tensor(160.2934)\n",
      "-286.7092270233412 0.0 -286.7092270233412 0.17617448013734743 tensor(143.3210)\n",
      "23417.94498576681 23417.94498576681 -288.12702388417347 0.1831669300572054 tensor(152.8279)\n",
      "-286.5529890569836 0.0 -286.5529890569836 0.2202217747119688 tensor(173.0730)\n",
      "28632.021829185975 28632.021829185975 -287.8343172127603 0.2600225054361578 tensor(168.1278)\n",
      "-286.4708633982318 0.0 -286.4708633982318 0.16046924169624865 tensor(183.8605)\n",
      "19184.497293100496 19184.497293100496 -287.9773791385247 0.25158127308318345 tensor(138.3590)\n",
      "-286.61441930997046 0.0 -286.61441930997046 0.24857243656060135 tensor(140.9369)\n",
      "35399.26324428177 35399.26324428177 -288.27012768236386 0.319002939208344 tensor(184.5634)\n",
      "-286.01582699425177 0.0 -286.01582699425177 0.06840517580070339 tensor(147.2027)\n",
      "23767.479242553334 23767.479242553334 -288.041236680536 0.30108554807777194 tensor(154.0094)\n",
      "-286.44026872829033 0.0 -286.44026872829033 0.17256768690062735 tensor(156.6107)\n",
      "28781.086011339496 28781.086011339496 -288.2086621686261 0.16758492491561147 tensor(169.5065)\n",
      "-286.2915060884675 0.0 -286.2915060884675 0.22473128914067528 tensor(149.0843)\n",
      "18406.63649952572 18406.63649952572 -287.81546165354354 0.10232059223047027 tensor(135.5575)\n",
      "-286.7165137248993 0.0 -286.7165137248993 0.15481973993916243 tensor(158.3360)\n",
      "17134.140469894817 17134.140469894817 -288.3655725747901 0.14631850748801242 tensor(130.4099)\n",
      "-286.1207867019642 0.0 -286.1207867019642 0.18948899525803115 tensor(149.5995)\n",
      "25526.882176205352 25526.882176205352 -288.3861043403244 0.278161259954439 tensor(159.3703)\n",
      "-286.23903811726007 0.0 -286.23903811726007 0.2965129037350015 tensor(160.4504)\n",
      "21825.938779473126 21825.938779473126 -287.95660567755675 0.2642290413538055 tensor(147.5980)\n",
      "-286.7397577225224 0.0 -286.7397577225224 0.08233496668755219 tensor(157.5202)\n",
      "25402.085117433904 25402.085117433904 -288.2926903264587 0.1023767454650107 tensor(158.9855)\n",
      "-286.338102840141 0.0 -286.338102840141 0.10859252116742417 tensor(215.6849)\n",
      "22632.84402025117 22632.84402025117 -288.11983354625056 0.3007168214571651 tensor(150.1230)\n",
      "-286.7584927974841 0.0 -286.7584927974841 0.33477867976985587 tensor(173.9694)\n",
      "26441.42924959365 26441.42924959365 -288.301981540194 0.10931790457046588 tensor(161.8687)\n",
      "-286.9440969660361 0.0 -286.9440969660361 0.25093931416686205 tensor(152.2248)\n",
      "20433.160385534113 20433.160385534113 -288.3212552395051 0.16979296524591855 tensor(142.2046)\n",
      "-286.4518385964781 0.0 -286.4518385964781 0.20443551792054962 tensor(154.9614)\n",
      "23953.008198714288 23953.008198714288 -288.3586081452 0.279445453111472 tensor(154.4714)\n",
      "-286.2821764249248 0.0 -286.2821764249248 0.20081988906539908 tensor(199.9464)\n",
      "33806.224932796744 33806.224932796744 -288.056417837204 0.08508070642765707 tensor(182.4072)\n",
      "-285.9227029505292 0.0 -285.9227029505292 0.11373495384665162 tensor(167.1406)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27958.50679232544 27958.50679232544 -288.2966551439023 0.19286580868432462 tensor(163.9601)\n",
      "-286.4797627522033 0.0 -286.4797627522033 0.07811362030583703 tensor(148.1422)\n",
      "21180.912273406586 21180.912273406586 -288.44936874868677 0.13943360775931582 tensor(145.4348)\n",
      "-286.69214649501464 0.0 -286.69214649501464 0.14031344264756274 tensor(164.3497)\n",
      "27653.80453501371 27653.80453501371 -288.3503238926605 0.16379168719307263 tensor(166.1107)\n",
      "-286.5229748137177 0.0 -286.5229748137177 0.22328707916552662 tensor(172.0494)\n",
      "18978.2745603812 18978.2745603812 -288.3035356350615 0.10711937408197916 tensor(136.8900)\n",
      "-286.70210836875356 0.0 -286.70210836875356 0.1702354599587314 tensor(175.4810)\n",
      "25303.834752597635 25303.834752597635 -288.1242508819921 0.21995941519325043 tensor(158.6727)\n",
      "-286.2409051241623 0.0 -286.2409051241623 0.23110730884735647 tensor(157.8309)\n",
      "27144.042387531506 27144.042387531506 -287.69811209288355 0.131790883572475 tensor(164.1271)\n",
      "-286.33128420486446 0.0 -286.33128420486446 0.1377975029267613 tensor(165.2717)\n",
      "37927.3902168469 37927.3902168469 -288.40946960743906 0.3605189546143698 tensor(190.6232)\n",
      "-286.1942807930037 0.0 -286.1942807930037 0.3566159533366182 tensor(162.2453)\n",
      "28273.86155986554 28273.86155986554 -288.2287839711924 0.12796968551170093 tensor(166.8324)\n",
      "-286.73602451481355 0.0 -286.73602451481355 0.06747806774496197 tensor(151.2757)\n",
      "26762.613221528853 26762.613221528853 -288.14634053718277 0.18726213351053805 tensor(163.7376)\n",
      "-286.58262925820316 0.0 -286.58262925820316 0.16689040909784733 tensor(199.9330)\n",
      "21812.946247960193 21812.946247960193 -287.559201932623 0.11905130151791612 tensor(145.9478)\n",
      "-286.3220839757167 0.0 -286.3220839757167 0.10653238839191892 tensor(143.9388)\n",
      "20360.39689394621 20360.39689394621 -288.302666038538 0.26442795128290086 tensor(141.7966)\n",
      "-286.79312672813035 0.0 -286.79312672813035 0.3178345390098294 tensor(162.9898)\n",
      "19431.989054621718 19431.989054621718 -288.14632586433015 0.11843798295424182 tensor(137.9644)\n",
      "-286.48484895258224 0.0 -286.48484895258224 0.11899655180206013 tensor(154.9999)\n",
      "34122.70684790111 34122.70684790111 -288.07196099018586 0.09996123265112489 tensor(183.7651)\n",
      "-286.3086844763288 0.0 -286.3086844763288 0.06884038772263525 tensor(182.3719)\n",
      "25816.65595074863 25816.65595074863 -288.26029047537884 0.15418796297821105 tensor(160.7038)\n",
      "-286.49341098420643 0.0 -286.49341098420643 0.1861262752613331 tensor(144.7111)\n",
      "45524.45480673839 45524.45480673839 -288.3511520030398 0.1812362503408909 tensor(210.3170)\n",
      "-286.4919942456128 0.0 -286.4919942456128 0.10022295235078522 tensor(195.1619)\n",
      "18075.086771176888 18075.086771176888 -287.9792327230133 0.18003542638006162 tensor(134.4792)\n",
      "-286.7026026549919 0.0 -286.7026026549919 0.19855049174532383 tensor(135.3680)\n",
      "56038.873615705 56038.873615705 -288.2402036470012 0.07933954916593003 tensor(235.5322)\n",
      "-286.5169503977085 0.0 -286.5169503977085 0.2333650759228369 tensor(161.4473)\n",
      "34829.45171984587 34829.45171984587 -288.0448187000536 0.2376150568150856 tensor(184.4709)\n",
      "-286.4242991646879 0.0 -286.4242991646879 0.2040886846005196 tensor(162.4893)\n",
      "28996.320518032335 28996.320518032335 -288.08265184360044 0.13241176603640736 tensor(170.1044)\n",
      "-286.60079929314463 0.0 -286.60079929314463 0.13374421358627017 tensor(146.7406)\n",
      "20796.362673757656 20796.362673757656 -288.2041504534874 0.27288666559471525 tensor(143.9738)\n",
      "-286.6103279549038 0.0 -286.6103279549038 0.23679380276886497 tensor(171.9034)\n",
      "20357.012494594383 20357.012494594383 -288.2587286356587 0.11509295958519813 tensor(142.4522)\n",
      "-286.1784882462394 0.0 -286.1784882462394 0.09999812479170184 tensor(184.0165)\n",
      "22184.664772692835 22184.664772692835 -287.8924365597645 0.3007309843652745 tensor(148.1903)\n",
      "-286.5663537404264 0.0 -286.5663537404264 0.35138534432207635 tensor(153.1100)\n",
      "22477.21349500763 22477.21349500763 -288.1554963522059 0.1692304724947806 tensor(149.6601)\n",
      "-286.81248707838046 0.0 -286.81248707838046 0.37928976754842014 tensor(146.3855)\n",
      "17983.66615697847 17983.66615697847 -287.86460307570104 0.17564257917630413 tensor(133.9021)\n",
      "-286.6933877272663 0.0 -286.6933877272663 0.1503169091804606 tensor(144.1642)\n",
      "20943.838487046138 20943.838487046138 -287.99136038675175 0.21845630776672703 tensor(144.6536)\n",
      "-286.82175821430314 0.0 -286.82175821430314 0.23460629061147056 tensor(159.1991)\n",
      "26773.99803416642 26773.99803416642 -288.19662631629154 0.11025700148132307 tensor(162.4832)\n",
      "-285.89066744441345 0.0 -285.89066744441345 0.04813558189375264 tensor(151.4937)\n",
      "18184.81532822499 18184.81532822499 -288.1421529466973 0.16627409502799953 tensor(134.7037)\n",
      "-286.86048880411465 0.0 -286.86048880411465 0.19916720622240885 tensor(159.6616)\n",
      "29839.661102789483 29839.661102789483 -287.71901159797034 0.3139743677091625 tensor(172.1216)\n",
      "-286.32420311975864 0.0 -286.32420311975864 0.12300532887945342 tensor(171.9271)\n",
      "25587.892190390583 25587.892190390583 -288.353881486203 0.22582600428208016 tensor(159.8530)\n",
      "-286.71217306658747 0.0 -286.71217306658747 0.19849408310894384 tensor(135.1472)\n",
      "22248.085160543975 22248.085160543975 -288.0075506321362 0.20620493061381304 tensor(149.0111)\n",
      "-286.4361173149328 0.0 -286.4361173149328 0.0743780501803187 tensor(179.9985)\n",
      "25566.38832023571 25566.38832023571 -288.03153797863285 0.30473152347725513 tensor(159.2283)\n",
      "-286.66153405616024 0.0 -286.66153405616024 0.13486320332793236 tensor(164.7608)\n",
      "21951.778359046017 21951.778359046017 -288.08060472545344 0.1320564032419546 tensor(147.9020)\n",
      "-286.212713641127 0.0 -286.212713641127 0.105328433202425 tensor(167.1854)\n",
      "31731.50293808579 31731.50293808579 -287.9568235695824 0.3721637185604591 tensor(176.9739)\n",
      "-286.0787917292062 0.0 -286.0787917292062 0.09790276575278031 tensor(169.4341)\n",
      "50029.4203554066 50029.4203554066 -288.2733066481138 0.25230352325173444 tensor(211.6139)\n",
      "-286.6370346489875 0.0 -286.6370346489875 0.33330720575641637 tensor(155.6734)\n",
      "23486.57466008441 23486.57466008441 -288.0819008906825 0.08328020870967939 tensor(153.3688)\n",
      "-286.2798135351803 0.0 -286.2798135351803 0.23187581735046778 tensor(152.2176)\n",
      "26471.923508973563 26471.923508973563 -288.47914388463266 0.24381782966878487 tensor(162.0890)\n",
      "-286.4989999484093 0.0 -286.4989999484093 0.2813074964997703 tensor(158.9421)\n",
      "23945.39802428069 23945.39802428069 -288.39893502775703 0.2117942473558808 tensor(154.7786)\n",
      "-286.10456624722974 0.0 -286.10456624722974 0.20661667874064477 tensor(151.8639)\n",
      "28137.927075615335 28137.927075615335 -288.39706367093004 0.1382207734901076 tensor(167.4061)\n",
      "-286.3793521521909 0.0 -286.3793521521909 0.1999583438793255 tensor(153.5072)\n",
      "22096.66747928651 22096.66747928651 -287.92075176479034 0.16377502355724624 tensor(148.5987)\n",
      "-286.53256473610446 0.0 -286.53256473610446 0.033527205483648535 tensor(147.9160)\n",
      "21607.651902474554 21607.651902474554 -288.0668109325002 0.24440252265100543 tensor(146.9178)\n",
      "-286.4922548398166 0.0 -286.4922548398166 0.3046395224893935 tensor(162.7303)\n",
      "16524.899562282946 16524.899562282946 -288.46503280264074 0.07233805765938896 tensor(128.3668)\n",
      "== Era 6 | Epoch 0 metrics ==\n",
      "\tloss 12879.5\n",
      "\tforce 13022.8\n",
      "\tdkl -287.321\n",
      "\tlogp 85.9368\n",
      "\tlogq -201.384\n",
      "\tess 0.186278\n",
      "-285.7448216075601 0.0 -285.7448216075601 0.07353451364491656 tensor(160.8271)\n",
      "30923.307241006954 30923.307241006954 -288.25561512186755 0.1321048791838578 tensor(171.4331)\n",
      "-286.9427905186932 0.0 -286.9427905186932 0.10833679971701864 tensor(167.2801)\n",
      "30740.580178818735 30740.580178818735 -288.2955684827415 0.20009133443222227 tensor(175.2409)\n",
      "-286.5107934085521 0.0 -286.5107934085521 0.15155812061874296 tensor(144.8301)\n",
      "24126.182029309064 24126.182029309064 -288.52986978991675 0.27288365556033123 tensor(155.1361)\n",
      "-286.4636196331052 0.0 -286.4636196331052 0.24692436259450234 tensor(154.2439)\n",
      "30302.617573427568 30302.617573427568 -287.71944750576256 0.20818890298318077 tensor(169.4444)\n",
      "-286.52670667386974 0.0 -286.52670667386974 0.22163981837605146 tensor(142.6248)\n",
      "22294.32366696255 22294.32366696255 -288.3425013034513 0.22900813021094474 tensor(147.7310)\n",
      "-286.18055432747985 0.0 -286.18055432747985 0.11610663384766906 tensor(181.3277)\n",
      "21968.7869074848 21968.7869074848 -288.2271584521902 0.14232235985364175 tensor(146.4375)\n",
      "-286.1437714483505 0.0 -286.1437714483505 0.22217525699223184 tensor(167.5466)\n",
      "22296.638301058596 22296.638301058596 -287.9960109362109 0.09625025993705595 tensor(148.9569)\n",
      "-285.86854329669296 0.0 -285.86854329669296 0.17699605147417502 tensor(169.6829)\n",
      "28373.292844605567 28373.292844605567 -288.11064053674437 0.08867572739540149 tensor(167.3051)\n",
      "-286.4832162570616 0.0 -286.4832162570616 0.23069300279863814 tensor(177.0568)\n",
      "35935.060148837416 35935.060148837416 -288.6715814901536 0.07396200419056549 tensor(184.0056)\n",
      "-286.5511436194137 0.0 -286.5511436194137 0.03582499637740769 tensor(155.3904)\n",
      "36206.20927251499 36206.20927251499 -287.5721207723471 0.21262185227085598 tensor(184.2890)\n",
      "-286.1088574173524 0.0 -286.1088574173524 0.217935545441054 tensor(171.0991)\n",
      "31889.208581740517 31889.208581740517 -287.7670670316443 0.2674601413601003 tensor(178.3352)\n",
      "-286.4725867543797 0.0 -286.4725867543797 0.16957679746548798 tensor(167.0867)\n",
      "27186.235052158914 27186.235052158914 -288.01726572544055 0.1645839683726668 tensor(162.4334)\n",
      "-286.5299061929769 0.0 -286.5299061929769 0.12149969910007807 tensor(155.7765)\n",
      "30345.690124949724 30345.690124949724 -288.1213988025796 0.3004508873203975 tensor(173.9628)\n",
      "-286.3032770184138 0.0 -286.3032770184138 0.14424387250674414 tensor(163.7879)\n",
      "40369.02698684961 40369.02698684961 -287.9427004725753 0.04633437856786605 tensor(198.1050)\n",
      "-286.4055704576812 0.0 -286.4055704576812 0.08711426413718303 tensor(160.5980)\n",
      "20483.271897527804 20483.271897527804 -288.3080893826956 0.0949555194378043 tensor(143.0094)\n",
      "-286.64624532330197 0.0 -286.64624532330197 0.3204929470918681 tensor(165.8512)\n",
      "36708.2065190192 36708.2065190192 -288.32096665015763 0.23197662905449573 tensor(190.4023)\n",
      "-286.1795283886696 0.0 -286.1795283886696 0.10620171383172017 tensor(150.0382)\n",
      "31337.013083046742 31337.013083046742 -287.8709127377452 0.22602359753595913 tensor(176.7256)\n",
      "-286.0217801094272 0.0 -286.0217801094272 0.18497246552818666 tensor(155.2867)\n",
      "17682.514601259285 17682.514601259285 -288.0271133203108 0.282253162260148 tensor(132.8297)\n",
      "-286.05234363728454 0.0 -286.05234363728454 0.2820366674287881 tensor(186.1560)\n",
      "35479.8422405258 35479.8422405258 -287.6161835411785 0.20706800391836347 tensor(187.9706)\n",
      "-286.4935605623653 0.0 -286.4935605623653 0.17824386274399565 tensor(143.1116)\n",
      "20687.57527453296 20687.57527453296 -288.1047167699445 0.21205058425053633 tensor(143.6207)\n",
      "-286.0770499093087 0.0 -286.0770499093087 0.17662015179915436 tensor(166.8856)\n",
      "26297.994905559113 26297.994905559113 -287.8033251927594 0.2547281834550872 tensor(161.1952)\n",
      "-286.1742469805704 0.0 -286.1742469805704 0.2501446403849965 tensor(166.4643)\n",
      "20540.48506133143 20540.48506133143 -288.37772785584264 0.18600404206264698 tensor(143.1813)\n",
      "-286.452232343944 0.0 -286.452232343944 0.14202739618314222 tensor(135.0046)\n",
      "30191.76566024954 30191.76566024954 -288.62865254221083 0.2600697391391668 tensor(172.7621)\n",
      "-286.1487860675412 0.0 -286.1487860675412 0.11294888967800772 tensor(150.8079)\n",
      "32900.22221103595 32900.22221103595 -288.02941335713706 0.1736682519913628 tensor(175.3176)\n",
      "-286.6466976522879 0.0 -286.6466976522879 0.14403540520726896 tensor(167.1970)\n",
      "27174.732238787088 27174.732238787088 -288.2472562659534 0.2205772513611303 tensor(164.5375)\n",
      "-286.64212266319487 0.0 -286.64212266319487 0.14662730354049305 tensor(155.9279)\n",
      "17911.12747373612 17911.12747373612 -288.3725534331992 0.2636738996367563 tensor(133.8559)\n",
      "-286.6648841499583 0.0 -286.6648841499583 0.09589764551106228 tensor(144.1671)\n",
      "20020.99986382687 20020.99986382687 -287.89602902530595 0.25277607550163056 tensor(141.4172)\n",
      "-286.43137047772575 0.0 -286.43137047772575 0.19314647844210436 tensor(159.5843)\n",
      "22186.920418612648 22186.920418612648 -288.38002166250214 0.10521695768180547 tensor(147.5845)\n",
      "-286.54542689277366 0.0 -286.54542689277366 0.18321067317856163 tensor(139.0115)\n",
      "21546.33960734727 21546.33960734727 -288.1028287243862 0.23775643399017748 tensor(146.4688)\n",
      "-286.2191412338393 0.0 -286.2191412338393 0.1550332542324085 tensor(199.0370)\n",
      "19530.787389829293 19530.787389829293 -288.1391225410807 0.08693413026405722 tensor(139.5075)\n",
      "-286.87609057360436 0.0 -286.87609057360436 0.1042520841598457 tensor(161.3909)\n",
      "25750.764512069873 25750.764512069873 -287.69081829818936 0.16673895796729016 tensor(160.2782)\n",
      "-286.3284186391056 0.0 -286.3284186391056 0.14200153543064198 tensor(162.0611)\n",
      "20494.41445294742 20494.41445294742 -288.2047342964845 0.09436957686767256 tensor(143.0467)\n",
      "-286.66957226047464 0.0 -286.66957226047464 0.14449457251862022 tensor(151.3249)\n",
      "21787.291727499112 21787.291727499112 -288.4742884785271 0.3081769283677181 tensor(147.4570)\n",
      "-286.25509117510734 0.0 -286.25509117510734 0.16283375880049977 tensor(155.2905)\n",
      "35621.67415205996 35621.67415205996 -287.8119210546946 0.147483121763581 tensor(188.4216)\n",
      "-286.63864548766367 0.0 -286.63864548766367 0.22024872279408947 tensor(172.2093)\n",
      "27414.697456149985 27414.697456149985 -288.21087426625843 0.4668752475908853 tensor(165.0842)\n",
      "-286.97008658515756 0.0 -286.97008658515756 0.2914579860933886 tensor(157.8108)\n",
      "21893.817089582488 21893.817089582488 -288.14152945469294 0.2403530841090364 tensor(147.8530)\n",
      "-286.5250392469594 0.0 -286.5250392469594 0.11011558974530321 tensor(179.0933)\n",
      "25097.184867508167 25097.184867508167 -288.0339783271326 0.33927862455544994 tensor(158.0918)\n",
      "-286.7488342593463 0.0 -286.7488342593463 0.20797238202930995 tensor(186.1299)\n",
      "23331.404363854574 23331.404363854574 -287.9471488622334 0.10933219188918968 tensor(152.5193)\n",
      "-286.50696213752985 0.0 -286.50696213752985 0.08681099640864556 tensor(152.9526)\n",
      "25091.791064575613 25091.791064575613 -288.35709025314287 0.2636469924248891 tensor(158.2794)\n",
      "-286.4264273372298 0.0 -286.4264273372298 0.16225646711469763 tensor(168.1183)\n",
      "25532.351151202456 25532.351151202456 -288.01562720808295 0.2581130637550912 tensor(159.5847)\n",
      "-286.6883234806917 0.0 -286.6883234806917 0.30581290285348645 tensor(201.3472)\n",
      "33879.28758308804 33879.28758308804 -288.4435327433995 0.4042502804979224 tensor(183.4608)\n",
      "-286.7727367584788 0.0 -286.7727367584788 0.19187364809363425 tensor(169.0067)\n",
      "29731.80096715449 29731.80096715449 -288.4701503074924 0.24576536126215082 tensor(172.3385)\n",
      "-286.495141845525 0.0 -286.495141845525 0.2515109231877926 tensor(185.7553)\n",
      "22956.402925600996 22956.402925600996 -288.2049169900642 0.38318526745904363 tensor(150.7122)\n",
      "-286.65080600879753 0.0 -286.65080600879753 0.13778779361969834 tensor(193.9202)\n",
      "27577.454020030214 27577.454020030214 -288.41725965947006 0.10487741539015895 tensor(165.7955)\n",
      "-286.5142147968986 0.0 -286.5142147968986 0.2320846276588647 tensor(167.5325)\n",
      "23217.993480970486 23217.993480970486 -288.31063412090737 0.25617222681162155 tensor(152.1571)\n",
      "-286.11960288262947 0.0 -286.11960288262947 0.10098916203900628 tensor(158.4636)\n",
      "28255.129803899028 28255.129803899028 -288.3689037023499 0.258741032110091 tensor(167.2210)\n",
      "-286.4828385247822 0.0 -286.4828385247822 0.2477336191534393 tensor(193.0679)\n",
      "24472.748548444248 24472.748548444248 -287.74308012465974 0.3000243780156979 tensor(156.0071)\n",
      "-286.7427990074673 0.0 -286.7427990074673 0.24315236392999 tensor(174.0728)\n",
      "22289.02926982764 22289.02926982764 -288.1641686126385 0.24864563741484508 tensor(145.4120)\n",
      "-286.6969858878478 0.0 -286.6969858878478 0.2659673897787896 tensor(176.2624)\n",
      "23675.23939392439 23675.23939392439 -288.16823861472363 0.18210162049636608 tensor(153.7133)\n",
      "-286.28598189851886 0.0 -286.28598189851886 0.27385311538443896 tensor(170.1247)\n",
      "46737.65219935015 46737.65219935015 -288.31447504922323 0.19968506746626116 tensor(213.7581)\n",
      "-286.4661574121061 0.0 -286.4661574121061 0.11804629106577495 tensor(174.1657)\n",
      "18114.07851922809 18114.07851922809 -288.53176055462745 0.07208059558506412 tensor(134.5458)\n",
      "-286.7134611906371 0.0 -286.7134611906371 0.15681214342924168 tensor(192.4907)\n",
      "29303.763179881105 29303.763179881105 -288.23698292060396 0.21540587089117838 tensor(170.9306)\n",
      "-286.71826432627654 0.0 -286.71826432627654 0.21604567243973616 tensor(151.4155)\n",
      "33957.07562163518 33957.07562163518 -288.1802852038144 0.3089559496418238 tensor(183.7687)\n",
      "-286.30728704314015 0.0 -286.30728704314015 0.23962678676578966 tensor(147.3560)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33331.56520296979 33331.56520296979 -288.4050308632264 0.17093248168197042 tensor(181.7066)\n",
      "-286.8974465791176 0.0 -286.8974465791176 0.13211741495537271 tensor(139.9096)\n",
      "25372.704086255522 25372.704086255522 -288.37268731161976 0.37642936973324176 tensor(158.9987)\n",
      "-286.33816760643793 0.0 -286.33816760643793 0.06978035473281015 tensor(145.1814)\n",
      "23048.127015965718 23048.127015965718 -287.99142862212256 0.2365390862535243 tensor(151.7385)\n",
      "-286.5838858475015 0.0 -286.5838858475015 0.1649489493516032 tensor(173.0642)\n",
      "20378.00255407058 20378.00255407058 -287.8234318608211 0.1646989551977042 tensor(142.4871)\n",
      "-286.1246728293569 0.0 -286.1246728293569 0.1364022705656823 tensor(165.5897)\n",
      "21544.541008429558 21544.541008429558 -288.06438290411745 0.27149724495031774 tensor(146.6611)\n",
      "-286.37468364734957 0.0 -286.37468364734957 0.15329447533337204 tensor(155.0557)\n",
      "23742.087118479503 23742.087118479503 -288.3184926304711 0.31780992051977874 tensor(151.1523)\n",
      "-286.5063451750442 0.0 -286.5063451750442 0.17076044836286738 tensor(148.3404)\n",
      "30641.12353916283 30641.12353916283 -288.2199214413488 0.23655597018166777 tensor(174.9669)\n",
      "-286.38776315513456 0.0 -286.38776315513456 0.2375265371583864 tensor(151.4936)\n",
      "24527.79101120859 24527.79101120859 -287.99544639188844 0.10476216209955656 tensor(153.0348)\n",
      "-286.4116561233475 0.0 -286.4116561233475 0.1277751971599298 tensor(162.1727)\n",
      "25675.005315567763 25675.005315567763 -287.8148362324871 0.29160955120387283 tensor(160.2627)\n",
      "-286.3110958542221 0.0 -286.3110958542221 0.25388622218522416 tensor(193.7315)\n",
      "25860.321825040326 25860.321825040326 -288.3431929979484 0.05992410480689113 tensor(160.2191)\n",
      "-286.15524332956926 0.0 -286.15524332956926 0.15873343564151154 tensor(159.2992)\n",
      "19932.820237964785 19932.820237964785 -288.02779385176126 0.11841786088131005 tensor(141.2338)\n",
      "-286.3322530490577 0.0 -286.3322530490577 0.12066306849002949 tensor(173.7632)\n",
      "33986.74210855886 33986.74210855886 -288.0368417989213 0.2958702466717978 tensor(183.4371)\n",
      "-286.7056967196628 0.0 -286.7056967196628 0.11301258048100461 tensor(134.0401)\n",
      "31422.12968858691 31422.12968858691 -287.76308579507315 0.3127187143326484 tensor(175.0870)\n",
      "-286.3977720519615 0.0 -286.3977720519615 0.2549549191209178 tensor(161.8153)\n",
      "24692.620142777567 24692.620142777567 -288.2568042448211 0.2596954692334381 tensor(156.9116)\n",
      "-286.34203687558045 0.0 -286.34203687558045 0.1552498375557257 tensor(180.6487)\n",
      "60444.97774633394 60444.97774633394 -288.2214282787844 0.05043734172343539 tensor(243.7482)\n",
      "-286.89674970213537 0.0 -286.89674970213537 0.13238572680891783 tensor(146.6272)\n",
      "23606.019368616617 23606.019368616617 -288.09951278658775 0.1954813328131947 tensor(153.5018)\n",
      "-286.7508626263333 0.0 -286.7508626263333 0.08248648177512799 tensor(161.5609)\n",
      "21170.41147644068 21170.41147644068 -288.27811164446706 0.11052538121143791 tensor(145.3793)\n",
      "-286.6384308045769 0.0 -286.6384308045769 0.2099478134320163 tensor(138.4266)\n",
      "26043.524057847157 26043.524057847157 -288.19464026291075 0.334461914354975 tensor(161.2434)\n",
      "-286.51387306046047 0.0 -286.51387306046047 0.16456191973792134 tensor(164.0828)\n",
      "26019.230948621993 26019.230948621993 -288.5265654732464 0.20295963465385813 tensor(160.9025)\n",
      "-286.8722206274785 0.0 -286.8722206274785 0.15687819989524507 tensor(140.6202)\n",
      "24167.882005410956 24167.882005410956 -288.41535599894087 0.15844559287010454 tensor(154.8328)\n",
      "-286.55640307793027 0.0 -286.55640307793027 0.23333131186335707 tensor(202.6338)\n",
      "21640.566769859754 21640.566769859754 -287.9143230183338 0.21063315453778372 tensor(147.0603)\n",
      "-286.38636106650677 0.0 -286.38636106650677 0.0828784855665353 tensor(163.4502)\n",
      "21359.213736346814 21359.213736346814 -288.0583220313039 0.13288877265040522 tensor(145.8549)\n",
      "-286.5531610625529 0.0 -286.5531610625529 0.26162494398177755 tensor(188.6580)\n",
      "18718.924642382437 18718.924642382437 -288.10038564737727 0.18042836152777686 tensor(136.6326)\n",
      "-286.4315694788008 0.0 -286.4315694788008 0.1007377702907284 tensor(177.1996)\n",
      "23161.956432710278 23161.956432710278 -288.37097079574585 0.31032072835278635 tensor(152.0354)\n",
      "-286.7610505051576 0.0 -286.7610505051576 0.22271448831247184 tensor(143.4152)\n",
      "23483.66068539206 23483.66068539206 -287.8791775363085 0.22824255172020388 tensor(153.0500)\n",
      "-286.5414336272373 0.0 -286.5414336272373 0.1586602083439515 tensor(162.5341)\n",
      "23075.94224865446 23075.94224865446 -288.20254965475317 0.09891714133103148 tensor(151.4135)\n",
      "-286.4381037237206 0.0 -286.4381037237206 0.28597898456053195 tensor(156.8215)\n",
      "30581.55684262045 30581.55684262045 -288.3358578706952 0.2219810945836157 tensor(174.5778)\n",
      "-286.4320647121944 0.0 -286.4320647121944 0.1473582774885548 tensor(171.1114)\n",
      "31001.47334415098 31001.47334415098 -287.77010312722416 0.2494705668135377 tensor(174.6778)\n",
      "-286.04702555366947 0.0 -286.04702555366947 0.22994065554305135 tensor(155.3305)\n",
      "21970.207773728675 21970.207773728675 -287.9258870581037 0.14385728412872623 tensor(147.8509)\n",
      "-286.5557307144974 0.0 -286.5557307144974 0.08018258769071188 tensor(143.4433)\n",
      "26660.041762080844 26660.041762080844 -288.2516768108925 0.12904274604103944 tensor(160.4023)\n",
      "-285.8840929354628 0.0 -285.8840929354628 0.12692758625487716 tensor(152.5383)\n",
      "25142.547030808433 25142.547030808433 -288.0378676659451 0.2703858382377212 tensor(158.4126)\n",
      "-286.50172062545715 0.0 -286.50172062545715 0.18429784743281868 tensor(160.1410)\n",
      "17151.545774146718 17151.545774146718 -287.66690730702567 0.33294809181931384 tensor(130.7954)\n",
      "-286.6010001142626 0.0 -286.6010001142626 0.2584045532424507 tensor(154.8096)\n",
      "29412.465898219354 29412.465898219354 -288.0015087219448 0.19411057288502273 tensor(171.2151)\n",
      "-286.6358032273912 0.0 -286.6358032273912 0.2594993754018986 tensor(207.6780)\n",
      "25266.049845845253 25266.049845845253 -287.81516155003885 0.1309538268320028 tensor(155.6836)\n",
      "-286.8084447446446 0.0 -286.8084447446446 0.2201687328319668 tensor(159.3136)\n",
      "32625.29000164562 32625.29000164562 -288.036424630604 0.17936222112955882 tensor(180.3519)\n",
      "-286.65607723998676 0.0 -286.65607723998676 0.11656240375373748 tensor(157.7995)\n",
      "35040.40496478479 35040.40496478479 -288.2921064997365 0.2887951650710407 tensor(186.2149)\n",
      "-286.0766521855204 0.0 -286.0766521855204 0.32316093132305956 tensor(173.3567)\n",
      "28734.925281259624 28734.925281259624 -287.8730129611461 0.14380545252816399 tensor(169.2838)\n",
      "-286.9578211973834 0.0 -286.9578211973834 0.2873579190996352 tensor(155.1189)\n",
      "29935.380589850654 29935.380589850654 -287.46978040439024 0.3393129249497387 tensor(169.6734)\n",
      "-286.60175557246833 0.0 -286.60175557246833 0.3265145719273295 tensor(196.2158)\n",
      "25615.10870030535 25615.10870030535 -288.5165845295527 0.3026572127309887 tensor(159.4268)\n",
      "-286.4938500391436 0.0 -286.4938500391436 0.13638982345060124 tensor(143.5589)\n",
      "18308.420794341204 18308.420794341204 -288.3970163575199 0.13244629870094166 tensor(135.1115)\n",
      "-286.4735125328457 0.0 -286.4735125328457 0.11793707440984053 tensor(165.2869)\n",
      "36525.49396787509 36525.49396787509 -287.88106615985345 0.1446048732514755 tensor(186.9702)\n",
      "-287.0785308067659 0.0 -287.0785308067659 0.2568926694145353 tensor(162.1278)\n",
      "43342.81524900217 43342.81524900217 -287.80811967555115 0.12679978437514616 tensor(205.7974)\n",
      "-286.4704028877707 0.0 -286.4704028877707 0.14536796732588447 tensor(177.0627)\n",
      "21534.885462603048 21534.885462603048 -288.351734969365 0.3501859676676101 tensor(146.9071)\n",
      "-286.8692636840298 0.0 -286.8692636840298 0.22979837682319237 tensor(149.6144)\n",
      "31298.303370981157 31298.303370981157 -288.1519175959145 0.23509834778687158 tensor(175.5433)\n",
      "-286.16478422457953 0.0 -286.16478422457953 0.1997709484252074 tensor(163.0010)\n",
      "25486.812508425024 25486.812508425024 -288.04128204322535 0.1512248997311727 tensor(159.4739)\n",
      "-286.24579094539945 0.0 -286.24579094539945 0.3011939653351159 tensor(151.4988)\n",
      "28530.12365923274 28530.12365923274 -287.94835314667813 0.33181491889186865 tensor(168.1041)\n",
      "-286.83349502444537 0.0 -286.83349502444537 0.20521710089946418 tensor(177.7747)\n",
      "23266.429111590398 23266.429111590398 -288.0055210549148 0.14016824158019633 tensor(152.4332)\n",
      "== Era 7 | Epoch 0 metrics ==\n",
      "\tloss 13315.3\n",
      "\tforce 13458.5\n",
      "\tdkl -287.31\n",
      "\tlogp 86.1404\n",
      "\tlogq -201.17\n",
      "\tess 0.197914\n",
      "-286.21157340082334 0.0 -286.21157340082334 0.36466164390808803 tensor(149.4633)\n",
      "21066.250222318296 21066.250222318296 -288.30965059464324 0.09675650623324225 tensor(144.9991)\n",
      "-286.4622506243221 0.0 -286.4622506243221 0.253639787456966 tensor(192.6975)\n",
      "26323.357034762663 26323.357034762663 -287.9764146902155 0.19698364523767686 tensor(162.0269)\n",
      "-286.38166277883283 0.0 -286.38166277883283 0.3794631222848598 tensor(142.9914)\n",
      "16829.21326909198 16829.21326909198 -288.35696553123887 0.2846675406888037 tensor(129.7752)\n",
      "-286.5853795198409 0.0 -286.5853795198409 0.3253091313937625 tensor(141.1652)\n",
      "21564.608704531198 21564.608704531198 -287.93336200974517 0.12033084283119833 tensor(146.6679)\n",
      "-286.6072961424934 0.0 -286.6072961424934 0.02802181189430641 tensor(150.4535)\n",
      "41511.222932703895 41511.222932703895 -287.81701010798304 0.06583539270027329 tensor(202.9830)\n",
      "-286.57857242902674 0.0 -286.57857242902674 0.22783425099096605 tensor(148.0345)\n",
      "22939.47711439456 22939.47711439456 -287.87417121860096 0.46830192424567696 tensor(151.3089)\n",
      "-286.2831352591719 0.0 -286.2831352591719 0.23935898063613886 tensor(181.5616)\n",
      "21060.822826038908 21060.822826038908 -288.08333432309905 0.3455306031796638 tensor(144.9146)\n",
      "-286.189039525626 0.0 -286.189039525626 0.22354535745701895 tensor(171.2241)\n",
      "42244.72566886668 42244.72566886668 -288.02933338269713 0.20703104139477338 tensor(203.4436)\n",
      "-286.22029534824094 0.0 -286.22029534824094 0.33716923728139986 tensor(157.2947)\n",
      "39793.60138627766 39793.60138627766 -288.27539105724725 0.12462340410045902 tensor(197.4038)\n",
      "-286.30244911657593 0.0 -286.30244911657593 0.16599486517585282 tensor(177.2968)\n",
      "25783.873992571822 25783.873992571822 -288.4146930571946 0.15331062082811178 tensor(160.3726)\n",
      "-286.2089332387361 0.0 -286.2089332387361 0.18988193756755928 tensor(183.4720)\n",
      "27865.212632623115 27865.212632623115 -287.94052647185293 0.23321804031470472 tensor(166.5063)\n",
      "-286.36423478875224 0.0 -286.36423478875224 0.0790606105694652 tensor(167.0161)\n",
      "30325.180584241964 30325.180584241964 -287.9561168434137 0.13446030041419862 tensor(173.8637)\n",
      "-286.70809209868673 0.0 -286.70809209868673 0.25126350725017427 tensor(156.3929)\n",
      "26319.24557758058 26319.24557758058 -288.0074150945592 0.20829014489707062 tensor(161.3652)\n",
      "-286.1427819788503 0.0 -286.1427819788503 0.1958223287452213 tensor(168.0517)\n",
      "29731.12730756143 29731.12730756143 -287.87748432176204 0.19703707221215902 tensor(172.0786)\n",
      "-287.1219326706247 0.0 -287.1219326706247 0.22672905619599812 tensor(156.4568)\n",
      "23518.635517854185 23518.635517854185 -288.734564059946 0.12941106759062343 tensor(153.1657)\n",
      "-286.55130429353494 0.0 -286.55130429353494 0.18143612276606538 tensor(165.8328)\n",
      "29358.759695913082 29358.759695913082 -288.0320153274114 0.34048726064935453 tensor(171.0862)\n",
      "-286.2052826070567 0.0 -286.2052826070567 0.2152185707531161 tensor(154.7943)\n",
      "32692.618244979316 32692.618244979316 -288.14467424913664 0.2714083994506261 tensor(180.3184)\n",
      "-286.3767902421283 0.0 -286.3767902421283 0.1769478501789672 tensor(151.9021)\n",
      "26912.667028115116 26912.667028115116 -288.3504866283482 0.29252330496813256 tensor(162.8061)\n",
      "-286.41350859506525 0.0 -286.41350859506525 0.21829045747339726 tensor(156.0878)\n",
      "39027.60537913691 39027.60537913691 -288.2526696854834 0.32074777793093706 tensor(197.0741)\n",
      "-286.4720429293475 0.0 -286.4720429293475 0.2566561168594445 tensor(144.2578)\n",
      "25821.7518846512 25821.7518846512 -287.8079297711552 0.20085017602344873 tensor(160.5755)\n",
      "-285.97567819302606 0.0 -285.97567819302606 0.2940132277231859 tensor(172.5480)\n",
      "18554.8298566804 18554.8298566804 -288.3049591630694 0.21266053224312959 tensor(136.0694)\n",
      "-286.534151754177 0.0 -286.534151754177 0.10368366843578812 tensor(163.4777)\n",
      "21259.907036393954 21259.907036393954 -288.3101502254319 0.1906800674025227 tensor(145.5996)\n",
      "-286.7445471550793 0.0 -286.7445471550793 0.09403658926528388 tensor(179.5627)\n",
      "33540.31925942404 33540.31925942404 -288.17962021647656 0.11290815221262554 tensor(182.1530)\n",
      "-286.47006809024026 0.0 -286.47006809024026 0.3191997558439289 tensor(151.6832)\n",
      "26267.94641327546 26267.94641327546 -288.391399154747 0.2634663239778402 tensor(161.9956)\n",
      "-286.3469020113257 0.0 -286.3469020113257 0.17661945757486489 tensor(142.3361)\n",
      "24582.453739244906 24582.453739244906 -287.91804411611935 0.17409632087422633 tensor(152.3799)\n",
      "-286.7290984072768 0.0 -286.7290984072768 0.2586726622262028 tensor(200.0057)\n",
      "33816.20335805685 33816.20335805685 -288.18195192534813 0.18293222398792255 tensor(182.4540)\n",
      "-286.3841145624315 0.0 -286.3841145624315 0.19988567807632776 tensor(174.7824)\n",
      "31045.696435470556 31045.696435470556 -287.72050240003256 0.35168218579678967 tensor(175.9526)\n",
      "-286.75842331222196 0.0 -286.75842331222196 0.29076833577133576 tensor(196.5944)\n",
      "19163.891721788103 19163.891721788103 -288.3148471142515 0.11838493598600507 tensor(138.2624)\n",
      "-286.56231879923564 0.0 -286.56231879923564 0.15469615490326544 tensor(162.2734)\n",
      "26231.73478730845 26231.73478730845 -288.05727801135924 0.09807384694555106 tensor(158.7766)\n",
      "-286.27883808537257 0.0 -286.27883808537257 0.08683645948636262 tensor(194.0775)\n",
      "42768.00203300169 42768.00203300169 -288.0336513625322 0.2254015002447022 tensor(205.1193)\n",
      "-286.7368627576173 0.0 -286.7368627576173 0.10947263165055109 tensor(160.3429)\n",
      "30969.764387228937 30969.764387228937 -288.33759510498135 0.3638662392265256 tensor(174.9746)\n",
      "-286.68118233017105 0.0 -286.68118233017105 0.19084967382345364 tensor(183.1358)\n",
      "25921.997980414704 25921.997980414704 -288.1861871579289 0.18936265529460225 tensor(161.0193)\n",
      "-286.3901592512801 0.0 -286.3901592512801 0.04542211149859425 tensor(158.5689)\n",
      "28968.42568461854 28968.42568461854 -287.606167693589 0.21454680801247555 tensor(169.9105)\n",
      "-286.4684453599853 0.0 -286.4684453599853 0.1125612550045809 tensor(178.5586)\n",
      "38427.169999085614 38427.169999085614 -287.9317626493344 0.1371964126190137 tensor(189.7556)\n",
      "-286.4432399164074 0.0 -286.4432399164074 0.22215118298414777 tensor(148.6726)\n",
      "22886.638410107622 22886.638410107622 -288.38841723523086 0.1779723772688713 tensor(150.8840)\n",
      "-286.8004177209266 0.0 -286.8004177209266 0.06750202691166361 tensor(175.0048)\n",
      "32173.801709070976 32173.801709070976 -288.2517575867961 0.05956669620571061 tensor(176.5286)\n",
      "-286.84701548650236 0.0 -286.84701548650236 0.21031276996382942 tensor(188.5717)\n",
      "24334.957352886864 24334.957352886864 -288.20630844465074 0.19062208206634637 tensor(154.2158)\n",
      "-286.2381365187134 0.0 -286.2381365187134 0.2009620154085082 tensor(149.3618)\n",
      "38756.5216339466 38756.5216339466 -287.9757888029856 0.26693002732359117 tensor(186.7154)\n",
      "-286.6558154722591 0.0 -286.6558154722591 0.29303723149611716 tensor(160.0497)\n",
      "23364.934442098667 23364.934442098667 -288.1339454018288 0.23967004805457193 tensor(152.6700)\n",
      "-286.4241090903373 0.0 -286.4241090903373 0.18431366416968215 tensor(156.4088)\n",
      "19923.864388054808 19923.864388054808 -287.8616099014858 0.31390201557947145 tensor(140.9983)\n",
      "-286.5832875282468 0.0 -286.5832875282468 0.18069377415285126 tensor(189.0892)\n",
      "39042.687827729045 39042.687827729045 -287.9985832593577 0.33993867152160295 tensor(188.5287)\n",
      "-286.46409692163803 0.0 -286.46409692163803 0.024711552415707588 tensor(140.2873)\n",
      "23479.861638570128 23479.861638570128 -288.2180700777346 0.16512745709589036 tensor(153.1541)\n",
      "-286.62856034906105 0.0 -286.62856034906105 0.2491180134859919 tensor(170.2326)\n",
      "33390.12464446684 33390.12464446684 -288.1026151339625 0.30852875593884677 tensor(182.3155)\n",
      "-286.7986510240821 0.0 -286.7986510240821 0.3411762892425748 tensor(142.3502)\n",
      "20868.800335056258 20868.800335056258 -288.150555858745 0.19873064324967782 tensor(144.2409)\n",
      "-286.6349147842492 0.0 -286.6349147842492 0.11114446160520806 tensor(162.1736)\n",
      "29710.49136872607 29710.49136872607 -288.06866528563137 0.11766075810704751 tensor(168.5958)\n",
      "-286.5446179755609 0.0 -286.5446179755609 0.25719782034737315 tensor(167.7571)\n",
      "27761.68887447575 27761.68887447575 -288.7495297837961 0.2460839443739365 tensor(166.4772)\n",
      "-286.51573532320145 0.0 -286.51573532320145 0.1549397844599703 tensor(176.9167)\n",
      "28144.549436893543 28144.549436893543 -288.2025142299515 0.20457542729068615 tensor(167.6553)\n",
      "-286.76816963952024 0.0 -286.76816963952024 0.29034753151699993 tensor(203.6472)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26391.745446696055 26391.745446696055 -288.3340861235174 0.2883365073684297 tensor(162.0164)\n",
      "-286.68894503008664 0.0 -286.68894503008664 0.08670579283613039 tensor(167.5100)\n",
      "23883.661724018868 23883.661724018868 -288.5054464286691 0.1801344826650062 tensor(154.4185)\n",
      "-286.5927184516541 0.0 -286.5927184516541 0.11679488193891184 tensor(200.7802)\n",
      "21293.329420524162 21293.329420524162 -287.8666124551879 0.30063998766202715 tensor(145.6931)\n",
      "-286.37298988082 0.0 -286.37298988082 0.35194058324364674 tensor(197.5455)\n",
      "29343.66251115444 29343.66251115444 -288.24526837225295 0.25323359190072553 tensor(169.3390)\n",
      "-286.5957784599935 0.0 -286.5957784599935 0.24908419820003672 tensor(142.1839)\n",
      "31947.409620594757 31947.409620594757 -288.12750083430115 0.10406359526193001 tensor(177.8800)\n",
      "-286.76380623734565 0.0 -286.76380623734565 0.22083220448735955 tensor(156.8642)\n",
      "32450.10986093465 32450.10986093465 -288.1204881208329 0.2831497826651419 tensor(179.5333)\n",
      "-286.80472023674383 0.0 -286.80472023674383 0.20350739238334142 tensor(152.1103)\n",
      "28175.557384280117 28175.557384280117 -288.1535717744771 0.24754000424159855 tensor(167.2270)\n",
      "-286.6056667129533 0.0 -286.6056667129533 0.23406715308984485 tensor(202.6739)\n",
      "22760.14987359711 22760.14987359711 -288.03000357754684 0.13105851137678287 tensor(148.2789)\n",
      "-286.3740513931564 0.0 -286.3740513931564 0.19028252812073917 tensor(145.1907)\n",
      "30298.5906247119 30298.5906247119 -288.33868414654955 0.2613360747000272 tensor(170.8669)\n",
      "-286.33719998402853 0.0 -286.33719998402853 0.16819874910585064 tensor(154.6171)\n",
      "16156.69696518693 16156.69696518693 -288.00976934524516 0.22064031388213473 tensor(126.9960)\n",
      "-286.834785957145 0.0 -286.834785957145 0.2671979728419568 tensor(159.0768)\n",
      "20646.22083777834 20646.22083777834 -288.00296109894 0.2606031004045291 tensor(143.4781)\n",
      "-286.5917110163092 0.0 -286.5917110163092 0.257450749265733 tensor(165.4447)\n",
      "21788.379779218976 21788.379779218976 -288.1585837259368 0.16409226458127618 tensor(147.4851)\n",
      "-286.68831570674536 0.0 -286.68831570674536 0.14161175652169888 tensor(145.1104)\n",
      "28420.642114269023 28420.642114269023 -288.2381978603379 0.13738262689218853 tensor(168.1230)\n",
      "-286.7045731971645 0.0 -286.7045731971645 0.3526218663737609 tensor(160.8990)\n",
      "41909.970328689975 41909.970328689975 -288.11640165503593 0.21927498017487806 tensor(202.2871)\n",
      "-286.6573322593779 0.0 -286.6573322593779 0.274057933647051 tensor(145.9944)\n",
      "21838.872011780775 21838.872011780775 -288.2619950824149 0.12165028678127547 tensor(147.6612)\n",
      "-286.95880070965575 0.0 -286.95880070965575 0.15322903471790378 tensor(149.5927)\n",
      "25344.557749224106 25344.557749224106 -288.2308008064887 0.16194259840921832 tensor(157.9983)\n",
      "-286.8284972457143 0.0 -286.8284972457143 0.2745345878277591 tensor(170.6712)\n",
      "44210.517474299064 44210.517474299064 -288.2574997244724 0.11809612433549817 tensor(207.3609)\n",
      "-286.9357536971081 0.0 -286.9357536971081 0.15423919011275258 tensor(164.8659)\n",
      "20878.27055285982 20878.27055285982 -287.76913549334006 0.1744887355740003 tensor(144.3852)\n",
      "-286.49037557571575 0.0 -286.49037557571575 0.13476215106505762 tensor(167.7802)\n",
      "30935.324184152567 30935.324184152567 -288.18094615790056 0.17459136188168933 tensor(175.0747)\n",
      "-286.4761700191196 0.0 -286.4761700191196 0.11668449689571005 tensor(161.5258)\n",
      "21993.691987631944 21993.691987631944 -287.85165013257114 0.266076476298395 tensor(148.2032)\n",
      "-286.97253869880575 0.0 -286.97253869880575 0.22328243860356242 tensor(174.1215)\n",
      "29596.142301015792 29596.142301015792 -288.1155860980231 0.18650157211349144 tensor(171.8363)\n",
      "-286.3385875272589 0.0 -286.3385875272589 0.21269348564345342 tensor(175.6499)\n",
      "23286.85472127764 23286.85472127764 -288.1949437202563 0.23892344734215196 tensor(152.3812)\n",
      "-286.70758697947076 0.0 -286.70758697947076 0.1514894158131587 tensor(155.6091)\n",
      "25002.526125123703 25002.526125123703 -288.0387873360428 0.29525982382486005 tensor(157.6582)\n",
      "-286.5265151255222 0.0 -286.5265151255222 0.3226143131236051 tensor(165.3871)\n",
      "86186.05013262176 86186.05013262176 -288.24295586549846 0.2227762656966225 tensor(286.4991)\n",
      "-286.9442830120561 0.0 -286.9442830120561 0.28419082195083845 tensor(172.1696)\n",
      "33142.89267505646 33142.89267505646 -288.2857430498416 0.33185549218132987 tensor(181.0841)\n",
      "-286.5206414173931 0.0 -286.5206414173931 0.33743908757784735 tensor(177.8935)\n",
      "27551.308208654606 27551.308208654606 -287.97210679979014 0.28027483500240213 tensor(165.6122)\n",
      "-286.7853303335655 0.0 -286.7853303335655 0.26648465038740343 tensor(184.7718)\n",
      "25276.489202282144 25276.489202282144 -288.3936068698119 0.3049493513075341 tensor(158.9751)\n",
      "-286.6625208259537 0.0 -286.6625208259537 0.21934955004086193 tensor(148.1205)\n",
      "41579.5792946103 41579.5792946103 -288.20350228463485 0.2494906332072956 tensor(200.6299)\n",
      "-286.07007994219714 0.0 -286.07007994219714 0.1459296943651911 tensor(145.3863)\n",
      "17696.390518040527 17696.390518040527 -288.2538299906946 0.24743641385126164 tensor(132.9295)\n",
      "-286.40343341197587 0.0 -286.40343341197587 0.180372336302756 tensor(158.5923)\n",
      "22347.34418485372 22347.34418485372 -288.1788690587409 0.2714002537141972 tensor(149.3663)\n",
      "-286.71248205294796 0.0 -286.71248205294796 0.22199456645550722 tensor(175.6731)\n",
      "34283.480036595334 34283.480036595334 -288.198194049451 0.31331075742367487 tensor(184.9624)\n",
      "-286.8667690069322 0.0 -286.8667690069322 0.18313511758018405 tensor(132.2456)\n",
      "32348.648916543396 32348.648916543396 -288.2574949696615 0.37473616326372267 tensor(178.5073)\n",
      "-286.5515771492885 0.0 -286.5515771492885 0.2574143548794591 tensor(176.8444)\n",
      "22536.985360947638 22536.985360947638 -288.26884696658357 0.08423161023880649 tensor(147.7917)\n",
      "-286.6623658381244 0.0 -286.6623658381244 0.15490343926360226 tensor(156.5154)\n",
      "32276.744566806672 32276.744566806672 -287.843314891619 0.3100140594673283 tensor(168.8654)\n",
      "-286.5116901109552 0.0 -286.5116901109552 0.03758510214230815 tensor(173.2939)\n",
      "24614.507631861048 24614.507631861048 -288.06639178748213 0.35678209865211874 tensor(156.5728)\n",
      "-286.3650053114417 0.0 -286.3650053114417 0.32358629510517517 tensor(148.0065)\n",
      "27519.07774647634 27519.07774647634 -288.1342013926738 0.19136120346287236 tensor(165.9255)\n",
      "-286.6152460557205 0.0 -286.6152460557205 0.3145799698898874 tensor(164.9999)\n",
      "33780.92011042022 33780.92011042022 -287.8567897496408 0.15443686623196973 tensor(183.6204)\n",
      "-286.498259365526 0.0 -286.498259365526 0.09185566518283923 tensor(164.4119)\n",
      "24165.9683210755 24165.9683210755 -288.09257629179444 0.3230905939303228 tensor(153.2052)\n",
      "-286.6571581440627 0.0 -286.6571581440627 0.27119528084310074 tensor(171.2023)\n",
      "26570.786800302616 26570.786800302616 -287.9359238248188 0.18220542985888843 tensor(162.8089)\n",
      "-286.5325975852319 0.0 -286.5325975852319 0.07785963256086781 tensor(165.3108)\n",
      "28513.445192447805 28513.445192447805 -287.8685065061105 0.3189660853486543 tensor(168.6595)\n",
      "-286.75115496117957 0.0 -286.75115496117957 0.24335039559315322 tensor(186.6903)\n",
      "31123.234656191868 31123.234656191868 -288.25454661060024 0.2443649757134719 tensor(175.7728)\n",
      "-286.32501079425396 0.0 -286.32501079425396 0.21341522070962504 tensor(182.1585)\n",
      "30988.668148737048 30988.668148737048 -288.1656837797765 0.22915228053752687 tensor(175.8721)\n",
      "-286.28084822395044 0.0 -286.28084822395044 0.3012985480527398 tensor(171.2155)\n",
      "26444.47276512931 26444.47276512931 -288.43623494508586 0.08917319550348177 tensor(162.6744)\n",
      "-286.45983897421536 0.0 -286.45983897421536 0.15611431035636644 tensor(171.6700)\n",
      "24553.13166286041 24553.13166286041 -288.20854024337143 0.26826913307869804 tensor(156.6278)\n",
      "-286.45091322858843 0.0 -286.45091322858843 0.25894376902903404 tensor(150.9846)\n",
      "47689.741920678214 47689.741920678214 -287.93935035166623 0.1369646405997141 tensor(214.6173)\n",
      "-286.5825764074208 0.0 -286.5825764074208 0.08102495487414335 tensor(158.1366)\n",
      "33156.201363180706 33156.201363180706 -287.9659225778883 0.1715977477572745 tensor(181.8805)\n",
      "-286.76034925671655 0.0 -286.76034925671655 0.1822599519362749 tensor(146.5431)\n",
      "20288.89009826477 20288.89009826477 -288.4169425145048 0.16578439396051162 tensor(142.4856)\n",
      "-286.43572440522667 0.0 -286.43572440522667 0.2589657186929565 tensor(178.8010)\n",
      "41531.092863676255 41531.092863676255 -288.01638643195884 0.20555626214238262 tensor(202.9020)\n",
      "-286.71771981342187 0.0 -286.71771981342187 0.19014972858080206 tensor(176.6681)\n",
      "22827.566556667072 22827.566556667072 -287.96880321210926 0.2869612213692713 tensor(150.4343)\n",
      "-286.3759241678508 0.0 -286.3759241678508 0.25173446513674 tensor(185.0966)\n",
      "23673.785771304632 23673.785771304632 -287.93939994228145 0.1935007492939143 tensor(153.7409)\n",
      "-286.80478345245 0.0 -286.80478345245 0.11712549892921922 tensor(177.2234)\n",
      "29180.4304146507 29180.4304146507 -288.1255360503053 0.28092326474465523 tensor(170.5012)\n",
      "-286.7556685818145 0.0 -286.7556685818145 0.24315149128560984 tensor(190.8780)\n",
      "30003.77921253004 30003.77921253004 -288.1760050110108 0.1511742499791259 tensor(172.6755)\n",
      "-286.6134050587619 0.0 -286.6134050587619 0.20881773727605507 tensor(164.1407)\n",
      "33807.48068571217 33807.48068571217 -287.9736246229432 0.3907771518098133 tensor(181.4108)\n",
      "== Era 8 | Epoch 0 metrics ==\n",
      "\tloss 14683.1\n",
      "\tforce 14826.4\n",
      "\tdkl -287.363\n",
      "\tlogp 85.951\n",
      "\tlogq -201.412\n",
      "\tess 0.2208\n",
      "-286.6429569657137 0.0 -286.6429569657137 0.12162630747174699 tensor(189.9067)\n",
      "30968.714201063558 30968.714201063558 -288.35638326676514 0.2508622048671828 tensor(171.4881)\n",
      "-286.6384460990935 0.0 -286.6384460990935 0.244767841699976 tensor(153.4721)\n",
      "20274.671030145808 20274.671030145808 -288.1563574911597 0.349542913078697 tensor(142.3306)\n",
      "-287.0163750974318 0.0 -287.0163750974318 0.19148069677763307 tensor(166.9448)\n",
      "42617.81087752562 42617.81087752562 -288.22536851059675 0.34793918194111595 tensor(205.4396)\n",
      "-286.7452393465517 0.0 -286.7452393465517 0.18414261465941395 tensor(182.1099)\n",
      "29270.66370279763 29270.66370279763 -288.3754206147853 0.32189230160875587 tensor(170.8296)\n",
      "-286.33756026920133 0.0 -286.33756026920133 0.17386590329865784 tensor(157.9281)\n",
      "46733.98649390653 46733.98649390653 -288.0682027302986 0.14548000742745829 tensor(215.7749)\n",
      "-286.5395274599764 0.0 -286.5395274599764 0.17512366512009242 tensor(155.7054)\n",
      "29637.154849760547 29637.154849760547 -287.8957826527348 0.2003609137218742 tensor(171.7211)\n",
      "-286.5692479118802 0.0 -286.5692479118802 0.24455851607629556 tensor(172.5789)\n",
      "25116.045775605387 25116.045775605387 -287.88855155981133 0.2414477907018337 tensor(158.0339)\n",
      "-286.90964489909754 0.0 -286.90964489909754 0.18691892284611833 tensor(173.1220)\n",
      "37357.482947871635 37357.482947871635 -287.8933417450372 0.2298844118890794 tensor(192.9479)\n",
      "-286.4254571296582 0.0 -286.4254571296582 0.08058350723758212 tensor(153.5324)\n",
      "24935.700531600214 24935.700531600214 -288.1342513075871 0.09648216229569226 tensor(157.7784)\n",
      "-286.388704284852 0.0 -286.388704284852 0.12410827017200181 tensor(175.3458)\n",
      "43156.94659683264 43156.94659683264 -287.90463030279017 0.27595710162743725 tensor(206.9233)\n",
      "-286.497659062797 0.0 -286.497659062797 0.1207865293192545 tensor(164.2451)\n",
      "24156.883177322263 24156.883177322263 -288.4444114777416 0.20334785639327765 tensor(155.2680)\n",
      "-286.6073138232545 0.0 -286.6073138232545 0.13337335339936676 tensor(153.4405)\n",
      "31018.59971910618 31018.59971910618 -288.1807438730445 0.29689665130058457 tensor(170.9722)\n",
      "-286.6614276412054 0.0 -286.6614276412054 0.2813049836543208 tensor(146.3427)\n",
      "36441.49629692904 36441.49629692904 -288.15894827183934 0.23968360968597477 tensor(184.7395)\n",
      "-286.51389638232115 0.0 -286.51389638232115 0.25797762017456805 tensor(213.9608)\n",
      "26756.113485240596 26756.113485240596 -287.9974478404528 0.2451793530905501 tensor(162.1233)\n",
      "-286.3221345263888 0.0 -286.3221345263888 0.2402578989894918 tensor(168.7475)\n",
      "30857.107928483085 30857.107928483085 -288.2832020401123 0.2970983331437073 tensor(172.2207)\n",
      "-286.5976655225621 0.0 -286.5976655225621 0.2827596334967263 tensor(174.3089)\n",
      "34260.22182794794 34260.22182794794 -288.3543220445332 0.31298258879123464 tensor(184.1575)\n",
      "-286.3579873740694 0.0 -286.3579873740694 0.13839578210949768 tensor(164.1308)\n",
      "27291.82279900194 27291.82279900194 -288.0428136937779 0.23410712675045103 tensor(161.0761)\n",
      "-286.7067829102175 0.0 -286.7067829102175 0.17804028418116055 tensor(161.6920)\n",
      "28328.984487025118 28328.984487025118 -288.2578921084174 0.03809902425651077 tensor(168.3787)\n",
      "-286.45397806721786 0.0 -286.45397806721786 0.13736985485658582 tensor(188.7170)\n",
      "35111.649473349695 35111.649473349695 -288.34984965386525 0.16139186401522063 tensor(186.9598)\n",
      "-286.44340142540403 0.0 -286.44340142540403 0.2580144324514151 tensor(196.4966)\n",
      "32498.58728991256 32498.58728991256 -287.80719994427034 0.1077202879767563 tensor(179.3144)\n",
      "-286.67544245767624 0.0 -286.67544245767624 0.19839391018418312 tensor(236.0939)\n",
      "27369.953027031122 27369.953027031122 -288.08839766561556 0.3601883121600452 tensor(164.9755)\n",
      "-286.8123756083804 0.0 -286.8123756083804 0.18862340422576732 tensor(133.5128)\n",
      "26518.090167131544 26518.090167131544 -288.4273328593292 0.23449601481980553 tensor(162.6329)\n",
      "-286.90557007053746 0.0 -286.90557007053746 0.3042977825985111 tensor(182.2277)\n",
      "37839.27498623458 37839.27498623458 -288.022967376422 0.08102924680827034 tensor(194.1935)\n",
      "-286.68483170435667 0.0 -286.68483170435667 0.3203243935626822 tensor(196.0809)\n",
      "30278.23792973245 30278.23792973245 -287.97854195517675 0.10369871523881175 tensor(173.3306)\n",
      "-286.68279398388444 0.0 -286.68279398388444 0.18648128555696997 tensor(188.7527)\n",
      "54460.94401416514 54460.94401416514 -288.1974441747743 0.2736850188459014 tensor(226.3007)\n",
      "-286.6364179590038 0.0 -286.6364179590038 0.23982372221697706 tensor(165.9202)\n",
      "34525.18834829543 34525.18834829543 -288.4035743902011 0.12332693497935135 tensor(185.3593)\n",
      "-286.8510796156192 0.0 -286.8510796156192 0.25006382216310163 tensor(170.2892)\n",
      "25760.121544017104 25760.121544017104 -288.100002733758 0.17424870269337495 tensor(159.9487)\n",
      "-287.0401647887257 0.0 -287.0401647887257 0.21036942792801555 tensor(190.0388)\n",
      "49761.46612893008 49761.46612893008 -287.6736873587662 0.17765966957390691 tensor(217.9392)\n",
      "-286.75701622329234 0.0 -286.75701622329234 0.08246563277274936 tensor(192.5761)\n",
      "41394.880230357056 41394.880230357056 -287.9234892919201 0.2919888273960032 tensor(193.9780)\n",
      "-286.6403224231848 0.0 -286.6403224231848 0.2878221189920095 tensor(168.5538)\n",
      "54442.220907780444 54442.220907780444 -288.1603852311286 0.07247197559339608 tensor(231.0131)\n",
      "-287.1917025542531 0.0 -287.1917025542531 0.13458571359512955 tensor(185.6169)\n",
      "38003.50930334942 38003.50930334942 -287.81518663177894 0.0926592326805799 tensor(193.4592)\n",
      "-286.86725895535085 0.0 -286.86725895535085 0.1708976525608458 tensor(163.5914)\n",
      "28217.317376366118 28217.317376366118 -288.1945218036342 0.27875747860163136 tensor(167.9386)\n",
      "-286.47846187522384 0.0 -286.47846187522384 0.20261071156446586 tensor(178.8249)\n",
      "29034.889495430212 29034.889495430212 -287.75190718257556 0.3376877088689621 tensor(170.1526)\n",
      "-286.51703651754724 0.0 -286.51703651754724 0.25400196497039135 tensor(192.8171)\n",
      "34912.23151805916 34912.23151805916 -288.0315236868879 0.20089823714972554 tensor(185.7929)\n",
      "-286.7376552778421 0.0 -286.7376552778421 0.19355900900008663 tensor(192.1893)\n",
      "24477.165089432347 24477.165089432347 -288.13903738640715 0.3510025219499702 tensor(156.2910)\n",
      "-286.6542912815338 0.0 -286.6542912815338 0.07105611303406126 tensor(143.9654)\n",
      "27200.924178282126 27200.924178282126 -288.3200456438126 0.16802782764025384 tensor(164.2102)\n",
      "-286.74987478669095 0.0 -286.74987478669095 0.2022602034209552 tensor(188.3427)\n",
      "27332.56093296573 27332.56093296573 -288.1859684587821 0.24867967240819444 tensor(165.2027)\n",
      "-286.6828907272777 0.0 -286.6828907272777 0.3674451631516162 tensor(172.3043)\n",
      "23705.047216142368 23705.047216142368 -288.24162974725334 0.2830527727286602 tensor(153.7501)\n",
      "-286.73102823039665 0.0 -286.73102823039665 0.20734587721748335 tensor(158.2143)\n",
      "34981.26991083532 34981.26991083532 -288.12166947058176 0.19913344187288806 tensor(186.7800)\n",
      "-286.20843451224835 0.0 -286.20843451224835 0.2918225357995473 tensor(154.5560)\n",
      "30262.70727169391 30262.70727169391 -288.08405545451234 0.23187089784595508 tensor(173.3471)\n",
      "-286.7718959610084 0.0 -286.7718959610084 0.23660616876012946 tensor(188.0993)\n",
      "37983.647632951615 37983.647632951615 -287.8734286127111 0.23216821503608853 tensor(193.7209)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.23514710809434 0.0 -286.23514710809434 0.1400074389289302 tensor(178.7152)\n",
      "23049.86885887923 23049.86885887923 -288.03295312951195 0.26476172590038954 tensor(151.5239)\n",
      "-286.87773890589233 0.0 -286.87773890589233 0.19954941237977275 tensor(185.7843)\n",
      "36904.57836125448 36904.57836125448 -287.8699683752664 0.16980275901617972 tensor(190.8515)\n",
      "-286.98102191102254 0.0 -286.98102191102254 0.21878809772352076 tensor(146.6684)\n",
      "56865.21121008001 56865.21121008001 -288.0733563950155 0.3976256351523512 tensor(229.3597)\n",
      "-286.9387012004107 0.0 -286.9387012004107 0.28772970247960034 tensor(160.7471)\n",
      "37897.010232110835 37897.010232110835 -288.3071493993833 0.15932416654930243 tensor(191.2314)\n",
      "-286.53212349034357 0.0 -286.53212349034357 0.26896251001767374 tensor(220.9754)\n",
      "31088.38097107392 31088.38097107392 -288.1497600924496 0.23119466352553444 tensor(175.1177)\n",
      "-286.8379147595121 0.0 -286.8379147595121 0.3398327070781594 tensor(190.7170)\n",
      "30926.305707327072 30926.305707327072 -287.6669524075952 0.2910103835790896 tensor(175.2222)\n",
      "-286.81896740955005 0.0 -286.81896740955005 0.2366507831787413 tensor(186.3923)\n",
      "32945.087136854956 32945.087136854956 -288.21101411081196 0.2085801788461877 tensor(181.2111)\n",
      "-286.87682376376455 0.0 -286.87682376376455 0.19715434495792797 tensor(155.3819)\n",
      "35357.694891397645 35357.694891397645 -288.07393938919415 0.36172375995012634 tensor(183.5413)\n",
      "-286.7649699698164 0.0 -286.7649699698164 0.35654786232897784 tensor(146.6261)\n",
      "30515.82568779188 30515.82568779188 -287.8245656842452 0.1194743055235504 tensor(174.4168)\n",
      "-286.39289017284057 0.0 -286.39289017284057 0.3227041999639995 tensor(159.5350)\n",
      "31475.93478372837 31475.93478372837 -288.1683729424505 0.22509879727201235 tensor(176.1059)\n",
      "-286.5367249952715 0.0 -286.5367249952715 0.09874397358946367 tensor(158.0213)\n",
      "32396.34485881898 32396.34485881898 -288.004229432628 0.05391830991326489 tensor(179.6228)\n",
      "-286.63286914348356 0.0 -286.63286914348356 0.29241191225019536 tensor(205.0386)\n",
      "28012.767178722086 28012.767178722086 -287.6679041858989 0.08929816690589772 tensor(167.1768)\n",
      "-286.46705720168745 0.0 -286.46705720168745 0.21249141598402496 tensor(213.0710)\n",
      "27972.162521381353 27972.162521381353 -288.2646316526419 0.23588673370277657 tensor(166.7712)\n",
      "-286.4776439295683 0.0 -286.4776439295683 0.3216853105174276 tensor(152.6076)\n",
      "35741.537383451454 35741.537383451454 -287.81135829279674 0.1985247107935613 tensor(185.8453)\n",
      "-286.5453972751462 0.0 -286.5453972751462 0.1627603278252879 tensor(175.8206)\n",
      "27712.087725520672 27712.087725520672 -288.04853959544164 0.2366290596668839 tensor(166.1755)\n",
      "-286.5277022352071 0.0 -286.5277022352071 0.11159841489922735 tensor(158.4961)\n",
      "22912.98143125935 22912.98143125935 -287.9789685721198 0.32787515702417186 tensor(151.2331)\n",
      "-286.6734019674517 0.0 -286.6734019674517 0.17187220201788864 tensor(165.0972)\n",
      "30695.104126784412 30695.104126784412 -287.8351469857317 0.1660095728831878 tensor(175.1341)\n",
      "-286.6685942812869 0.0 -286.6685942812869 0.19514347906237167 tensor(149.9004)\n",
      "25178.985837719014 25178.985837719014 -288.0862132920401 0.2321616123660179 tensor(158.5609)\n",
      "-286.7922147525099 0.0 -286.7922147525099 0.07587558032999858 tensor(176.9852)\n",
      "24016.035114145052 24016.035114145052 -287.98206247425276 0.22919374166741072 tensor(154.9574)\n",
      "-286.77691122188946 0.0 -286.77691122188946 0.26853726982446763 tensor(165.1533)\n",
      "47089.48291864631 47089.48291864631 -288.2058904999295 0.16281555804985964 tensor(214.2193)\n",
      "-286.6183435389848 0.0 -286.6183435389848 0.20997000056814077 tensor(254.4426)\n",
      "23956.30902745878 23956.30902745878 -288.14429574337737 0.22185742675241718 tensor(153.5582)\n",
      "-287.06341210907783 0.0 -287.06341210907783 0.116123984219361 tensor(141.7480)\n",
      "32105.97851700545 32105.97851700545 -287.99706822895945 0.30680815161026576 tensor(178.9220)\n",
      "-286.47511508832065 0.0 -286.47511508832065 0.11856230532483208 tensor(161.0839)\n",
      "33428.2922439839 33428.2922439839 -287.8253172354935 0.09724066146827016 tensor(181.4759)\n",
      "-286.69107057717406 0.0 -286.69107057717406 0.17144310264394377 tensor(190.7370)\n",
      "81433.6377463078 81433.6377463078 -288.4893076296852 0.2150858177654918 tensor(248.8532)\n",
      "-286.55038903542146 0.0 -286.55038903542146 0.22643464676003303 tensor(174.3124)\n",
      "32523.081604484458 32523.081604484458 -288.1455554112951 0.21651803165275746 tensor(179.6742)\n",
      "-286.7289424765849 0.0 -286.7289424765849 0.2385271206730317 tensor(184.6300)\n",
      "32584.51904541713 32584.51904541713 -288.4270790252835 0.2639703333955241 tensor(175.7778)\n",
      "-286.59437866108334 0.0 -286.59437866108334 0.20321583970187063 tensor(176.4832)\n",
      "30134.46041276698 30134.46041276698 -288.2195104384168 0.38449639817999615 tensor(173.3259)\n",
      "-286.87937229938836 0.0 -286.87937229938836 0.33229564783546456 tensor(173.0310)\n",
      "38207.88518499268 38207.88518499268 -288.1407230502175 0.11199089838321344 tensor(195.0106)\n",
      "-286.22259259086445 0.0 -286.22259259086445 0.16017872482748943 tensor(192.4215)\n",
      "27946.054514003514 27946.054514003514 -288.2532112369357 0.19619849274797108 tensor(164.8904)\n",
      "-286.4714106265702 0.0 -286.4714106265702 0.23551266343638685 tensor(182.7584)\n",
      "47430.205543077114 47430.205543077114 -287.8614632493479 0.060841271611810674 tensor(213.2898)\n",
      "-286.5280294910391 0.0 -286.5280294910391 0.11836694333905473 tensor(212.2492)\n",
      "36634.16551957345 36634.16551957345 -288.12077239060716 0.2971814543526759 tensor(190.6745)\n",
      "-286.89836866416937 0.0 -286.89836866416937 0.08465490777970804 tensor(174.5461)\n",
      "30423.29156948549 30423.29156948549 -288.00954647255446 0.04816781224915071 tensor(172.8592)\n",
      "-286.6871999917365 0.0 -286.6871999917365 0.23225831573455716 tensor(154.6311)\n",
      "27380.428234622254 27380.428234622254 -288.0661337189451 0.22320977830727667 tensor(165.0890)\n",
      "-286.71687778644826 0.0 -286.71687778644826 0.03029680373498569 tensor(176.2365)\n",
      "42063.958419427196 42063.958419427196 -288.13684721163594 0.09152624166601166 tensor(204.6375)\n",
      "-286.8265069486854 0.0 -286.8265069486854 0.2318711316226093 tensor(214.7991)\n",
      "32954.359769987226 32954.359769987226 -288.0081460342397 0.3269203984208722 tensor(181.1306)\n",
      "-286.56837056086334 0.0 -286.56837056086334 0.2353930840461151 tensor(194.5569)\n",
      "29929.412656997483 29929.412656997483 -288.24820765729885 0.35654257379399207 tensor(172.0528)\n",
      "-286.2787300987989 0.0 -286.2787300987989 0.24973361730547292 tensor(171.1179)\n",
      "46446.6371661164 46446.6371661164 -288.19155130449184 0.25013288171310083 tensor(214.2529)\n",
      "-286.56392818360445 0.0 -286.56392818360445 0.33486316749147077 tensor(197.9445)\n",
      "39237.53246523517 39237.53246523517 -287.9681816353351 0.2753157103186032 tensor(197.2692)\n",
      "-286.9073944072553 0.0 -286.9073944072553 0.21196921154724666 tensor(192.6661)\n",
      "40331.93095662204 40331.93095662204 -288.23716936020924 0.08792617106584047 tensor(200.3972)\n",
      "-286.66981309137316 0.0 -286.66981309137316 0.16035926512764007 tensor(178.5613)\n",
      "38645.07946426176 38645.07946426176 -288.00503431591403 0.15013536243841646 tensor(194.5683)\n",
      "-286.6233579435079 0.0 -286.6233579435079 0.21025833856145404 tensor(183.0966)\n",
      "28161.63846414937 28161.63846414937 -287.9287618669755 0.30791683533054537 tensor(167.1854)\n",
      "-286.75758476356253 0.0 -286.75758476356253 0.2563490291217816 tensor(157.5353)\n",
      "32097.058675313212 32097.058675313212 -288.0961773813125 0.2597043686404546 tensor(178.5870)\n",
      "-286.5649854576029 0.0 -286.5649854576029 0.19048003972409652 tensor(171.9538)\n",
      "43218.483396632895 43218.483396632895 -288.30752789422854 0.26818327857599733 tensor(205.3126)\n",
      "-286.7541170286472 0.0 -286.7541170286472 0.1497329675508475 tensor(175.9790)\n",
      "26903.430002528145 26903.430002528145 -287.962130527342 0.2844187636023505 tensor(163.7869)\n",
      "-286.4279108769082 0.0 -286.4279108769082 0.10323578346404672 tensor(172.5693)\n",
      "25154.449115480853 25154.449115480853 -288.11024859862886 0.42999006393676337 tensor(158.4761)\n",
      "-286.4893792919263 0.0 -286.4893792919263 0.0891589719259271 tensor(148.9543)\n",
      "23310.58352203795 23310.58352203795 -288.14931160595427 0.2141925710293427 tensor(152.2261)\n",
      "-286.95879210496753 0.0 -286.95879210496753 0.3289989355100452 tensor(171.2642)\n",
      "40385.10251731313 40385.10251731313 -288.0891468507832 0.1396635305896396 tensor(200.5544)\n",
      "-286.6566702505332 0.0 -286.6566702505332 0.22646706421908447 tensor(210.6462)\n",
      "64799.37495791122 64799.37495791122 -288.11307100754675 0.3901310161220529 tensor(240.8902)\n",
      "-286.6836527368945 0.0 -286.6836527368945 0.11029721571098049 tensor(211.7511)\n",
      "23845.05734854934 23845.05734854934 -288.09723291167506 0.17389617970906907 tensor(153.8779)\n",
      "-286.822363616916 0.0 -286.822363616916 0.1909982589826085 tensor(207.3599)\n",
      "50618.90265264145 50618.90265264145 -288.2418077833034 0.14487958788551072 tensor(222.5762)\n",
      "-286.51918480149743 0.0 -286.51918480149743 0.22347192404221977 tensor(189.4120)\n",
      "23480.65598936976 23480.65598936976 -288.02424089530825 0.093173170022644 tensor(153.1096)\n",
      "-286.82754198867235 0.0 -286.82754198867235 0.2627811184093672 tensor(139.8523)\n",
      "42815.068204518495 42815.068204518495 -288.1691671164193 0.153251888955317 tensor(203.5108)\n",
      "-286.6094985315991 0.0 -286.6094985315991 0.22956217986888944 tensor(191.4951)\n",
      "76663.96253055485 76663.96253055485 -288.0344183246118 0.1664468543590055 tensor(275.5122)\n",
      "-286.4363464126865 0.0 -286.4363464126865 0.07149626702568883 tensor(191.8741)\n",
      "42754.40996869915 42754.40996869915 -288.18037059567587 0.2804458724282213 tensor(205.7148)\n",
      "-286.99485194950296 0.0 -286.99485194950296 0.1522045387633706 tensor(218.6098)\n",
      "42786.62357074983 42786.62357074983 -288.1391513787509 0.15522750950595082 tensor(199.5782)\n",
      "-286.7873564202284 0.0 -286.7873564202284 0.21122177518788232 tensor(175.8193)\n",
      "44031.80341182334 44031.80341182334 -288.1601791675908 0.26369165247301746 tensor(209.3067)\n",
      "-286.46374911153305 0.0 -286.46374911153305 0.23621967459288143 tensor(169.8619)\n",
      "41923.41670385703 41923.41670385703 -287.8263755651805 0.43941997112879705 tensor(202.7677)\n",
      "-286.72960412492546 0.0 -286.72960412492546 0.2349363962888116 tensor(176.2328)\n",
      "22995.003527881032 22995.003527881032 -288.30696147005165 0.15256828656619917 tensor(150.9185)\n",
      "-286.7732867623642 0.0 -286.7732867623642 0.2777373595289952 tensor(168.5408)\n",
      "39867.1858510596 39867.1858510596 -288.22071769462633 0.2711626833691358 tensor(195.4263)\n",
      "== Era 9 | Epoch 0 metrics ==\n",
      "\tloss 17984.8\n",
      "\tforce 18128.1\n",
      "\tdkl -287.37\n",
      "\tlogp 86.0896\n",
      "\tlogq -201.281\n",
      "\tess 0.208193\n",
      "-286.9181147514958 0.0 -286.9181147514958 0.36396113947263475 tensor(197.4714)\n",
      "46620.373173286396 46620.373173286396 -288.0497737022338 0.11269115256924432 tensor(214.6523)\n",
      "-286.7397638922615 0.0 -286.7397638922615 0.19088910991777314 tensor(169.0240)\n",
      "29834.24650140834 29834.24650140834 -288.0795530433961 0.27226623767408675 tensor(172.4772)\n",
      "-286.9742751528868 0.0 -286.9742751528868 0.20159047288708654 tensor(157.0248)\n",
      "34064.20097149187 34064.20097149187 -288.2213891126037 0.16688630424308717 tensor(184.1427)\n",
      "-286.6509381937567 0.0 -286.6509381937567 0.1735853316123802 tensor(162.8167)\n",
      "25991.09974265112 25991.09974265112 -288.3060458967933 0.3043542039939408 tensor(161.0946)\n",
      "-286.74402224740106 0.0 -286.74402224740106 0.22956671891494135 tensor(186.4613)\n",
      "28335.839995543654 28335.839995543654 -288.00047126303787 0.43303380039560124 tensor(167.9692)\n",
      "-286.72748785034776 0.0 -286.72748785034776 0.1724788362441504 tensor(157.5912)\n",
      "46281.69573123145 46281.69573123145 -288.2204038603812 0.2715554808002053 tensor(214.1312)\n",
      "-286.7128856393332 0.0 -286.7128856393332 0.27188274709884314 tensor(150.9163)\n",
      "37590.1927610036 37590.1927610036 -287.8582242456388 0.19317800003065774 tensor(190.6913)\n",
      "-286.78992110489196 0.0 -286.78992110489196 0.14460831683526398 tensor(180.7321)\n",
      "34935.54830168742 34935.54830168742 -287.7156344722682 0.290099527129308 tensor(185.6281)\n",
      "-286.50831777076496 0.0 -286.50831777076496 0.1663587659437257 tensor(198.6117)\n",
      "44158.247401537 44158.247401537 -287.94826752158536 0.2509661663282869 tensor(209.2331)\n",
      "-286.75763265155183 0.0 -286.75763265155183 0.31574214453342214 tensor(166.3939)\n",
      "27368.904489062676 27368.904489062676 -288.062790369587 0.21382128817552587 tensor(164.6681)\n",
      "-286.560138262476 0.0 -286.560138262476 0.1772971529993363 tensor(158.4727)\n",
      "52586.39672946076 52586.39672946076 -287.65829627396954 0.3330289350533016 tensor(227.9642)\n",
      "-286.97899085378896 0.0 -286.97899085378896 0.35159729610395796 tensor(161.0669)\n",
      "32334.48569563334 32334.48569563334 -288.21998891429985 0.0931763980986105 tensor(171.3921)\n",
      "-286.90006297944205 0.0 -286.90006297944205 0.1615115850978584 tensor(196.1083)\n",
      "34174.13784555784 34174.13784555784 -288.12057116810917 0.3223222388770521 tensor(185.0013)\n",
      "-286.94570973447577 0.0 -286.94570973447577 0.10515781988271469 tensor(200.8599)\n",
      "29965.275345892143 29965.275345892143 -288.39795240514354 0.1896810008890989 tensor(172.3858)\n",
      "-286.74675840074013 0.0 -286.74675840074013 0.145535356102978 tensor(165.6305)\n",
      "23922.577678571837 23922.577678571837 -288.03181154765264 0.20045487498840958 tensor(152.5147)\n",
      "-286.5197548462762 0.0 -286.5197548462762 0.262260448552488 tensor(156.1126)\n",
      "105539.36866517483 105539.36866517483 -288.1411177975172 0.3113684349355109 tensor(308.6770)\n",
      "-286.5244730322535 0.0 -286.5244730322535 0.12043582432377307 tensor(181.5652)\n",
      "36506.78310400163 36506.78310400163 -287.8131878978313 0.14449958547288497 tensor(183.4253)\n",
      "-287.10050580194627 0.0 -287.10050580194627 0.29159892357513134 tensor(142.3126)\n",
      "27491.312605509716 27491.312605509716 -288.03000537039225 0.36631270222425166 tensor(155.4988)\n",
      "-286.7937243181006 0.0 -286.7937243181006 0.09453961126754326 tensor(199.5553)\n",
      "31515.904224809303 31515.904224809303 -288.0931922941412 0.27963495706045916 tensor(176.6553)\n",
      "-286.6041628178134 0.0 -286.6041628178134 0.20746176630857452 tensor(211.7258)\n",
      "39400.730229413464 39400.730229413464 -287.84981227693606 0.25541427522639804 tensor(196.2709)\n",
      "-286.8889483028169 0.0 -286.8889483028169 0.2387011281540354 tensor(202.0507)\n",
      "52586.17663689473 52586.17663689473 -288.31366835120104 0.17045631115456122 tensor(227.4778)\n",
      "-286.62374774642035 0.0 -286.62374774642035 0.22839813391366617 tensor(167.2137)\n",
      "24938.149909668246 24938.149909668246 -288.3505218669783 0.32877796550278654 tensor(157.7878)\n",
      "-286.64362840024546 0.0 -286.64362840024546 0.3302576957631957 tensor(180.7904)\n",
      "32470.87964141995 32470.87964141995 -288.2359291123339 0.1975149056409337 tensor(180.3954)\n",
      "-286.711291836987 0.0 -286.711291836987 0.2605590448211284 tensor(162.1658)\n",
      "25000.74072950796 25000.74072950796 -287.93593776861894 0.1322229923501355 tensor(157.9062)\n",
      "-286.55359988579755 0.0 -286.55359988579755 0.1602148751010135 tensor(228.6432)\n",
      "33397.23908091222 33397.23908091222 -288.2300072397452 0.29301058072507136 tensor(180.6719)\n",
      "-286.6541120341893 0.0 -286.6541120341893 0.18648951553148685 tensor(178.2775)\n",
      "28733.940334205225 28733.940334205225 -287.79978809399006 0.23971627519925648 tensor(169.2471)\n",
      "-286.5307312037038 0.0 -286.5307312037038 0.18651590780187383 tensor(184.3311)\n",
      "32317.092941269155 32317.092941269155 -287.9685211872036 0.17965945702009323 tensor(179.6092)\n",
      "-286.6638922704962 0.0 -286.6638922704962 0.4554316111561436 tensor(181.9512)\n",
      "26566.256437930642 26566.256437930642 -288.20497702142416 0.35861291326553585 tensor(158.7851)\n",
      "-287.13736745655433 0.0 -287.13736745655433 0.2935061272312575 tensor(171.5790)\n",
      "36994.59230615742 36994.59230615742 -287.91640945386445 0.2596096522239732 tensor(192.0067)\n",
      "-286.8235875573009 0.0 -286.8235875573009 0.13147267719827968 tensor(152.3823)\n",
      "28193.10661379543 28193.10661379543 -287.8443572638412 0.26019875959594624 tensor(167.4784)\n",
      "-286.8939747319168 0.0 -286.8939747319168 0.22843116967048532 tensor(168.1929)\n",
      "28696.53355057985 28696.53355057985 -288.0416604012669 0.35691215706488355 tensor(169.0469)\n",
      "-286.8249222041702 0.0 -286.8249222041702 0.28327525051361396 tensor(184.8152)\n",
      "37511.20519331413 37511.20519331413 -288.0645249837621 0.28428085145176246 tensor(192.3626)\n",
      "-286.3646268471325 0.0 -286.3646268471325 0.41800419403753925 tensor(170.0437)\n",
      "32363.570317195892 32363.570317195892 -287.9873436046687 0.266544267858828 tensor(179.6621)\n",
      "-286.89380457800837 0.0 -286.89380457800837 0.17368253268977976 tensor(172.0907)\n",
      "30877.33778558393 30877.33778558393 -288.18639651659566 0.30216957187619964 tensor(175.1529)\n",
      "-286.66963302785814 0.0 -286.66963302785814 0.20186358078002328 tensor(159.1614)\n",
      "22274.86211430715 22274.86211430715 -288.04357098002276 0.24101148540899814 tensor(149.1810)\n",
      "-286.1840528552124 0.0 -286.1840528552124 0.04038355074385487 tensor(228.5261)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29545.839601755917 29545.839601755917 -288.4465730929619 0.47428446769830945 tensor(171.6324)\n",
      "-286.8151212339759 0.0 -286.8151212339759 0.273896469550297 tensor(178.4583)\n",
      "33188.38437750572 33188.38437750572 -288.42573690510267 0.2661439264663623 tensor(181.3265)\n",
      "-286.8457000405217 0.0 -286.8457000405217 0.4055879646505006 tensor(175.7673)\n",
      "26187.467106153097 26187.467106153097 -287.764546675734 0.19408951557778947 tensor(160.5654)\n",
      "-286.5367729033023 0.0 -286.5367729033023 0.2349166899233862 tensor(175.3840)\n",
      "29040.124023825392 29040.124023825392 -288.0832697460643 0.16832868328932768 tensor(169.9603)\n",
      "-286.3983647482503 0.0 -286.3983647482503 0.06131807077005022 tensor(173.6732)\n",
      "30794.413639064853 30794.413639064853 -287.8960162582364 0.2992857938128901 tensor(175.4131)\n",
      "-286.6032350169363 0.0 -286.6032350169363 0.28029650946655027 tensor(163.7994)\n",
      "38401.75597004997 38401.75597004997 -288.22061612992644 0.21854761268187697 tensor(195.4205)\n",
      "-286.44760726806146 0.0 -286.44760726806146 0.1997375149591836 tensor(163.9204)\n",
      "128505.28786239479 128505.28786239479 -288.04001360126927 0.22905097348478587 tensor(343.3975)\n",
      "-286.7622888137299 0.0 -286.7622888137299 0.2715752471182853 tensor(186.7701)\n",
      "22920.365675003624 22920.365675003624 -287.99795510358126 0.17376335109067612 tensor(151.1656)\n",
      "-286.6903484609779 0.0 -286.6903484609779 0.2928313472271597 tensor(182.7889)\n",
      "35564.92118504454 35564.92118504454 -288.0829010940548 0.22713555180161712 tensor(188.3915)\n",
      "-286.790960122529 0.0 -286.790960122529 0.3090327770683561 tensor(170.9830)\n",
      "28221.320218481356 28221.320218481356 -288.42499182251686 0.3281651741660622 tensor(167.9621)\n",
      "-286.9541978708615 0.0 -286.9541978708615 0.30611023057433806 tensor(165.3802)\n",
      "33243.16296823923 33243.16296823923 -288.08673175381523 0.1818495289635739 tensor(182.2124)\n",
      "-286.7790774046691 0.0 -286.7790774046691 0.3671335314988146 tensor(155.0604)\n",
      "32344.52931550261 32344.52931550261 -287.8811364830509 0.14279529036077082 tensor(179.5265)\n",
      "-286.662671210369 0.0 -286.662671210369 0.1859696582561995 tensor(190.7245)\n",
      "56068.98045628042 56068.98045628042 -288.00019741316794 0.2778679730668992 tensor(223.1196)\n",
      "-286.76577294320657 0.0 -286.76577294320657 0.2687390388551765 tensor(157.3890)\n",
      "27392.702716498454 27392.702716498454 -287.8339942436993 0.1011404755998065 tensor(161.7109)\n",
      "-286.4281258726193 0.0 -286.4281258726193 0.298709714372571 tensor(171.0518)\n",
      "27626.75460623105 27626.75460623105 -288.03903397516365 0.18067046153460664 tensor(165.1469)\n",
      "-286.62950186200356 0.0 -286.62950186200356 0.2975366543256179 tensor(162.5707)\n",
      "23751.03130059829 23751.03130059829 -288.0464530330403 0.3039840655075881 tensor(154.0192)\n",
      "-286.53931578171114 0.0 -286.53931578171114 0.31875346026286877 tensor(175.0344)\n",
      "29681.50824170142 29681.50824170142 -287.7769623277959 0.17791322858414363 tensor(171.8815)\n",
      "-286.5705279223637 0.0 -286.5705279223637 0.34453325728859224 tensor(179.2440)\n",
      "24748.60900901408 24748.60900901408 -288.0362633228075 0.15498994502362787 tensor(152.8746)\n",
      "-286.7025530417326 0.0 -286.7025530417326 0.3245384403906894 tensor(194.7903)\n",
      "43329.351104751826 43329.351104751826 -288.0821597061598 0.25602673767092265 tensor(207.1247)\n",
      "-286.5530745256726 0.0 -286.5530745256726 0.1801103711773051 tensor(151.7700)\n",
      "39891.54639895608 39891.54639895608 -288.167122313595 0.10817291153487497 tensor(195.4179)\n",
      "-287.14153109792204 0.0 -287.14153109792204 0.0723333635067632 tensor(180.8109)\n",
      "48428.475489833465 48428.475489833465 -287.7286089258945 0.1929925079213773 tensor(217.4326)\n",
      "-286.5469184181822 0.0 -286.5469184181822 0.18999128179769664 tensor(178.2295)\n",
      "36444.39418289595 36444.39418289595 -287.6396932543639 0.22565812089539886 tensor(190.9817)\n",
      "-286.7296734259961 0.0 -286.7296734259961 0.4267863741474863 tensor(195.6182)\n",
      "32062.44088428573 32062.44088428573 -287.5102249818823 0.18297153061328145 tensor(178.7539)\n",
      "-286.46331484114404 0.0 -286.46331484114404 0.15422388922643826 tensor(202.7239)\n",
      "35551.10727112354 35551.10727112354 -288.436970121224 0.33059486059963483 tensor(187.7714)\n",
      "-286.76470887058184 0.0 -286.76470887058184 0.15773948614229027 tensor(143.8460)\n",
      "25019.579632492292 25019.579632492292 -287.88057678514593 0.23088909047507433 tensor(158.0154)\n",
      "-286.65743384892784 0.0 -286.65743384892784 0.2642503171742394 tensor(180.3921)\n",
      "28432.664741914246 28432.664741914246 -288.225167261155 0.23163970971851902 tensor(168.6822)\n",
      "-286.5211586481963 0.0 -286.5211586481963 0.3782901845454986 tensor(187.9186)\n",
      "43943.46259199413 43943.46259199413 -287.3264336365537 0.22053506068653303 tensor(209.3744)\n",
      "-286.8952941566835 0.0 -286.8952941566835 0.23586332109104455 tensor(170.7480)\n",
      "33544.96537259205 33544.96537259205 -287.5596484680479 0.2156256703794352 tensor(183.2111)\n",
      "-286.63748968247774 0.0 -286.63748968247774 0.17645732042911494 tensor(187.8761)\n",
      "37371.847592675585 37371.847592675585 -288.0659328383442 0.13795964447364853 tensor(191.7845)\n",
      "-286.65493122275734 0.0 -286.65493122275734 0.2448501157655578 tensor(193.3960)\n",
      "33588.99788609509 33588.99788609509 -287.97701873430964 0.27168493999789406 tensor(182.3200)\n",
      "-286.98450915789044 0.0 -286.98450915789044 0.35914232768084836 tensor(161.9037)\n",
      "30897.065834972418 30897.065834972418 -287.81853572650084 0.11486306936743625 tensor(175.7178)\n",
      "-286.7838088234063 0.0 -286.7838088234063 0.27362880656244987 tensor(175.4430)\n",
      "24318.29841154289 24318.29841154289 -288.23766158377543 0.31856251901390203 tensor(155.9153)\n",
      "-286.9654484071141 0.0 -286.9654484071141 0.27802968215995083 tensor(183.8580)\n",
      "53003.35940233398 53003.35940233398 -287.89816340073 0.40380723425319043 tensor(228.3008)\n",
      "-287.1795282461975 0.0 -287.1795282461975 0.2711887302888133 tensor(190.2309)\n",
      "44795.92115243882 44795.92115243882 -287.9079380167402 0.31791168258238756 tensor(211.2512)\n",
      "-286.6861220271674 0.0 -286.6861220271674 0.3287220003193488 tensor(176.3605)\n",
      "34397.39545060044 34397.39545060044 -288.09835279212024 0.2553708505906432 tensor(184.8298)\n",
      "-286.82665957027245 0.0 -286.82665957027245 0.17257500025884212 tensor(186.2487)\n",
      "35677.83137674509 35677.83137674509 -288.00302196594265 0.21914649599534522 tensor(188.0564)\n",
      "-286.8103208741142 0.0 -286.8103208741142 0.3265541133751065 tensor(201.0885)\n",
      "22964.176079906378 22964.176079906378 -287.8506917413568 0.26189765080300775 tensor(151.3768)\n",
      "-286.51681649210803 0.0 -286.51681649210803 0.3224951409291503 tensor(151.3020)\n",
      "29102.56814445139 29102.56814445139 -287.7752651677765 0.18926685481062508 tensor(170.0502)\n",
      "-286.89597456019175 0.0 -286.89597456019175 0.3232544245439992 tensor(157.7417)\n",
      "33281.80795856127 33281.80795856127 -288.13139945104984 0.29426714983410096 tensor(181.8718)\n",
      "-287.2362481426943 0.0 -287.2362481426943 0.1781113137431888 tensor(140.2386)\n",
      "27658.486005439492 27658.486005439492 -288.2250286533931 0.22581205266709903 tensor(165.8785)\n",
      "-286.6775308323926 0.0 -286.6775308323926 0.05889455253184818 tensor(190.6208)\n",
      "26975.508295002823 26975.508295002823 -288.06100298276976 0.3071081993074894 tensor(164.1237)\n",
      "-286.4653239821323 0.0 -286.4653239821323 0.22721654543113662 tensor(188.5579)\n",
      "24490.581420311646 24490.581420311646 -288.1751416925391 0.30061369466611587 tensor(156.2134)\n",
      "-286.4663883764984 0.0 -286.4663883764984 0.34440364941997975 tensor(201.7979)\n",
      "33976.30968205599 33976.30968205599 -288.2071774669376 0.251730762344781 tensor(183.8798)\n",
      "-286.6801632462045 0.0 -286.6801632462045 0.17611753971882843 tensor(184.2607)\n",
      "31175.08193599104 31175.08193599104 -288.44263032487754 0.03666764717395973 tensor(176.1212)\n",
      "-286.56645976575703 0.0 -286.56645976575703 0.18223319225070592 tensor(173.7990)\n",
      "79460.48500616074 79460.48500616074 -287.8952571304777 0.2821191086685494 tensor(272.2458)\n",
      "-286.9108275893958 0.0 -286.9108275893958 0.18259358288825336 tensor(187.0789)\n",
      "34472.94653250713 34472.94653250713 -287.879863085658 0.1918914097910847 tensor(185.6483)\n",
      "-286.98235136327446 0.0 -286.98235136327446 0.3364620470226559 tensor(201.7397)\n",
      "34082.011686515776 34082.011686515776 -288.21478674506744 0.2133192573865039 tensor(178.5943)\n",
      "-286.6722242783728 0.0 -286.6722242783728 0.3230185499274405 tensor(201.0995)\n",
      "43779.37229490653 43779.37229490653 -288.28855896867776 0.11899569958331836 tensor(205.8975)\n",
      "-286.85431395684446 0.0 -286.85431395684446 0.2587392677674893 tensor(158.0151)\n",
      "38457.831101247015 38457.831101247015 -288.2423241430233 0.04483074990903199 tensor(195.1264)\n",
      "-286.4377470924859 0.0 -286.4377470924859 0.2284911536522594 tensor(166.1159)\n",
      "29872.49275554312 29872.49275554312 -288.1958502558207 0.38491780545918486 tensor(172.5588)\n",
      "-286.8714704554742 0.0 -286.8714704554742 0.26389852602965097 tensor(218.5221)\n",
      "41068.6971197321 41068.6971197321 -287.80601168463136 0.2790405255926503 tensor(196.6970)\n",
      "-286.57528687772736 0.0 -286.57528687772736 0.25174353591461057 tensor(164.7925)\n",
      "36761.851095842445 36761.851095842445 -288.20781867426194 0.37061265784766584 tensor(191.4669)\n",
      "-286.31629794663604 0.0 -286.31629794663604 0.23883194623995546 tensor(170.1860)\n",
      "26252.454964622742 26252.454964622742 -288.2386837672211 0.2893566234317824 tensor(160.7404)\n",
      "-286.9162140652839 0.0 -286.9162140652839 0.3308585769076157 tensor(176.9275)\n",
      "31257.93013480053 31257.93013480053 -287.88507441518396 0.1532795394845151 tensor(176.6085)\n",
      "-286.6971605926143 0.0 -286.6971605926143 0.2615900245361232 tensor(189.2856)\n",
      "36126.434406031665 36126.434406031665 -287.7078513100279 0.2640230517259568 tensor(188.6052)\n",
      "-286.5588030153909 0.0 -286.5588030153909 0.08306189253376338 tensor(187.5290)\n",
      "26238.062550471153 26238.062550471153 -287.97327133419475 0.037707320937749776 tensor(161.8823)\n",
      "-286.63667500578623 0.0 -286.63667500578623 0.2678450864058287 tensor(178.7725)\n",
      "39882.086461483865 39882.086461483865 -288.0567873142387 0.3004106043614563 tensor(199.3843)\n",
      "-286.9350508972602 0.0 -286.9350508972602 0.23670195392742424 tensor(167.1881)\n",
      "24717.205245563528 24717.205245563528 -287.9700680139134 0.27365720190738724 tensor(156.9748)\n",
      "-286.6339931949768 0.0 -286.6339931949768 0.2703073979374453 tensor(158.4839)\n",
      "45274.18681466376 45274.18681466376 -287.94340218097005 0.3399606164241097 tensor(211.8320)\n",
      "-287.2746460787248 0.0 -287.2746460787248 0.21212313281731804 tensor(229.8887)\n",
      "35998.43409728282 35998.43409728282 -287.96420396608335 0.43179756367207245 tensor(189.2205)\n",
      "-286.79595025766247 0.0 -286.79595025766247 0.18175756940199161 tensor(209.5193)\n",
      "18090.428103429287 18090.428103429287 -288.00170940882754 0.1845702574447351 tensor(134.4699)\n",
      "-287.0645974940003 0.0 -287.0645974940003 0.31006168501595677 tensor(193.4344)\n",
      "37027.29053404361 37027.29053404361 -288.1052692664364 0.2420612187366094 tensor(192.2220)\n",
      "-286.54001302182337 0.0 -286.54001302182337 0.3370761499748632 tensor(188.5485)\n",
      "36211.15813878632 36211.15813878632 -288.20225675960216 0.23047520666584376 tensor(190.0005)\n",
      "-286.8340388654 0.0 -286.8340388654 0.23158668104060565 tensor(220.3455)\n",
      "36818.941600626335 36818.941600626335 -287.8430015072239 0.38509833181633907 tensor(191.7765)\n",
      "Accept rate: 0.267578125\n",
      "Topological susceptibility = 1.25 +/- 0.12\n",
      "... vs HMC estimate = 1.23 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "flow_model, flow_act = flow_train(param, with_force=True, pre_model=pre_flow_model)\n",
    "flow_eval(flow_model,flow_act)\n",
    "flow = flow_model['layers']\n",
    "# flow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.7829)\n",
      "tensor(24.9007)\n"
     ]
    }
   ],
   "source": [
    "def test_force(x = None):\n",
    "    model = flow_model\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "    if x == None:\n",
    "        pre_model = pre_flow_model\n",
    "        pre_layers, pre_prior = pre_model['layers'], pre_model['prior']\n",
    "        pre_xi = pre_prior.sample_n(1)\n",
    "        x = ft_flow(pre_layers, pre_xi)\n",
    "    xi = ft_flow_inv(layers, x)\n",
    "    f = ft_force(param, layers, xi)\n",
    "    f_s = torch.linalg.norm(f)\n",
    "    print(f_s)\n",
    "\n",
    "test_force()\n",
    "test_force(field_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latsize = (8, 8)\n",
      "volume = 64\n",
      "beta = 2.0\n",
      "trajs = 2\n",
      "tau = 2\n",
      "steps = 8\n",
      "seed = 1331\n",
      "nth = 2\n",
      "nth_interop = 2\n",
      "Initial configuration:  plaq: 0.6627686419055754  topo: 0.0\n",
      "plaq(x) 0.6627686419055754  force.norm 21.091837451367958\n",
      "Traj:    1  ACCEPT:  dH: -0.49041166   exp(-dH):  1.6329883    plaq:  0.62473448   topo:  2.0\n",
      "plaq(x) 0.6247344841194027  force.norm 21.8840629070871\n",
      "Traj:    2  ACCEPT:  dH:  0.66073851   exp(-dH):  0.51646978   plaq:  0.66851193   topo:  0.0\n",
      "plaq(x) 0.6685119259671379  force.norm 19.583396204466677\n",
      "Traj:    3  REJECT:  dH:  0.62826715   exp(-dH):  0.5335155    plaq:  0.66851193   topo:  0.0\n",
      "plaq(x) 0.6685119259671379  force.norm 19.540474594479193\n",
      "Traj:    4  REJECT:  dH:  0.25176081   exp(-dH):  0.77743067   plaq:  0.66851193   topo:  0.0\n",
      "plaq(x) 0.6685119259671379  force.norm 18.73962959721593\n",
      "Traj:    5  ACCEPT:  dH:  0.26645544   exp(-dH):  0.76609014   plaq:  0.73566717   topo:  1.0\n",
      "plaq(x) 0.735667166271016  force.norm 18.993473339448784\n",
      "Traj:    6  ACCEPT:  dH:  0.15850783   exp(-dH):  0.85341628   plaq:  0.69898425   topo:  2.0\n",
      "plaq(x) 0.6989842543137255  force.norm 19.000686567424456\n",
      "Traj:    7  ACCEPT:  dH: -0.6771935    exp(-dH):  1.9683458    plaq:  0.677385     topo:  1.0\n",
      "plaq(x) 0.6773849952159252  force.norm 21.02736720137215\n",
      "Traj:    8  ACCEPT:  dH: -0.10548912   exp(-dH):  1.111254     plaq:  0.6712748    topo: -1.0\n",
      "Run times:  [0.012176017044112086, 0.011070439009927213, 0.011035870062187314, 0.011333368951454759]\n",
      "Per trajectory:  [0.006088008522056043, 0.005535219504963607, 0.005517935031093657, 0.005666684475727379]\n"
     ]
    }
   ],
   "source": [
    "field_run = run(param, field_run[0])\n",
    "field_run = torch.reshape(field_run,(1,)+field_run.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plaq(field_run[0]) 0.5729559235604118\n",
      "tensor([18.9736], grad_fn=<AddBackward0>) tensor([-18.9736], grad_fn=<AddBackward0>)\n",
      "original_action tensor(17.6616, grad_fn=<AddBackward0>)\n",
      "eff_action tensor([1.6352], grad_fn=<AddBackward0>)\n",
      "plaq(x) -0.20566029157065324  logJ tensor([18.9736], grad_fn=<AddBackward0>)  force.norm 15.38544434986163\n",
      "plaq(y) 0.5729560026167126\n",
      "plaq(x) 0.5729559235604118  force.norm 20.91876473600617\n"
     ]
    }
   ],
   "source": [
    "flows = flow\n",
    "\n",
    "print(f'plaq(field_run[0]) {action(param, field_run[0]) / (-param.beta*param.volume)}')\n",
    "# field.requires_grad_(True)\n",
    "x = field_run\n",
    "logJ = 0.0\n",
    "for layer in reversed(flows):\n",
    "    x, lJ = layer.reverse(x)\n",
    "    logJ += lJ\n",
    "\n",
    "# x is the prior distribution now\n",
    "    \n",
    "x.requires_grad_(True)\n",
    "    \n",
    "y = x\n",
    "logJy = 0.0\n",
    "for layer in flows:\n",
    "    y, lJ = layer.forward(y)\n",
    "    logJy += lJ\n",
    "    \n",
    "s = action(param, y[0]) - logJy\n",
    "\n",
    "print(logJ,logJy)\n",
    "\n",
    "\n",
    "# print(\"eff_action\", s + 136.3786)\n",
    "\n",
    "print(\"original_action\", action(param, y[0]) + 91)\n",
    "\n",
    "print(\"eff_action\", s + 56)\n",
    "\n",
    "s.backward()\n",
    "\n",
    "f = x.grad\n",
    "\n",
    "x.requires_grad_(False)\n",
    "\n",
    "print(f'plaq(x) {action(param, x[0]) / (-param.beta*param.volume)}  logJ {logJ}  force.norm {torch.linalg.norm(f)}')\n",
    "\n",
    "print(f'plaq(y) {action(param, y[0]) / (-param.beta*param.volume)}')\n",
    "\n",
    "print(f'plaq(x) {action(param, field_run[0]) / (-param.beta*param.volume)}  force.norm {torch.linalg.norm(force(param, field_run[0]))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 8, 8])\n",
      "tensor(30.5185)\n",
      "tensor(30.5185)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x = ft_flow_inv(flow, field_run)\n",
    "# x = field_run\n",
    "#for layer in reversed(flows):\n",
    "#    x, lJ = layer.reverse(x)\n",
    "ff = ft_force(param, flow, x)\n",
    "print(torch.linalg.norm(ff))\n",
    "fff = ft_force(param, flow, x)\n",
    "print(torch.linalg.norm(fff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-54.6079], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ft_flow_inv(flow, field_run)\n",
    "ft_action(param, flow, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattern(l):\n",
    "    return [x for y in l for x in y]\n",
    "\n",
    "def average(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "def sub_avg(l):\n",
    "    avg = average(l)\n",
    "    return np.array([x - avg for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_hmc_info_list = []\n",
    "def ft_leapfrog(param, flow, x, p):\n",
    "    mom_norm = torch.sum(p*p)\n",
    "    info_list = []\n",
    "    dt = param.dt\n",
    "    x_ = x + 0.5*dt*p\n",
    "    f = ft_force(param, flow, x_)\n",
    "    p_ = p + (-dt)*f\n",
    "    info = np.array((float(torch.linalg.norm(f)),\n",
    "                     float(ft_action(param, flow, x_).detach()),\n",
    "                     float(torch.sum(p*p_)/np.sqrt(mom_norm*torch.sum(p_*p_)))))\n",
    "    info_list.append(info)\n",
    "    for i in range(param.nstep-1):\n",
    "        x_ = x_ + dt*p_\n",
    "        f = ft_force(param, flow, x_)\n",
    "        info = np.array((float(torch.linalg.norm(f)),\n",
    "                        float(ft_action(param, flow, x_).detach()),\n",
    "                        float(torch.sum(p*p_)/np.sqrt(mom_norm*torch.sum(p_*p_)))))\n",
    "        info_list.append(info)\n",
    "        p_ = p_ + (-dt)*f\n",
    "    x_ = x_ + 0.5*dt*p_\n",
    "    print(np.sqrt(average([l[0]**2 for l in info_list])),\n",
    "          (info_list[0][1], info_list[-1][1]),\n",
    "          info_list[-1][2])\n",
    "    ft_hmc_info_list.append(info_list)\n",
    "    return (x_, p_)\n",
    "\n",
    "def ft_hmc(param, flow, field):\n",
    "    x = ft_flow_inv(flow, field)\n",
    "    p = torch.randn_like(x)\n",
    "    act0 = ft_action(param, flow, x).detach() + 0.5*torch.sum(p*p)\n",
    "    x_, p_ = ft_leapfrog(param, flow, x, p)\n",
    "    xr = regularize(x_)\n",
    "    act = ft_action(param, flow, xr).detach() + 0.5*torch.sum(p_*p_)\n",
    "    prob = torch.rand([], dtype=torch.float64)\n",
    "    dH = act-act0\n",
    "    exp_mdH = torch.exp(-dH)\n",
    "    acc = prob < exp_mdH\n",
    "    # ADJUST ME\n",
    "    newx = xr if acc else x\n",
    "    # newx = xr\n",
    "    newfield = ft_flow(flow, newx)\n",
    "    return (float(dH), float(exp_mdH), acc, newfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_run(param, flow, field = None):\n",
    "    if field == None:\n",
    "        field = param.initializer()\n",
    "    ft_hmc_info_list = []\n",
    "    with open(param.uniquestr(), \"w\") as O:\n",
    "        params = param.summary()\n",
    "        O.write(params)\n",
    "        put(params)\n",
    "        plaq, topo = (action(param, field) / (-param.beta*param.volume), topocharge(field))\n",
    "        status = f\"Initial configuration:  plaq: {plaq}  topo: {topo}\\n\"\n",
    "        O.write(status)\n",
    "        put(status)\n",
    "        ts = []\n",
    "        for n in range(param.nrun):\n",
    "            t = -timer()\n",
    "            for i in range(param.ntraj):\n",
    "                field_run = torch.reshape(field,(1,)+field.shape)\n",
    "                dH, exp_mdH, acc, field_run = ft_hmc(param, flow, field_run)\n",
    "                field = field_run[0]\n",
    "                plaq = action(param, field) / (-param.beta*param.volume)\n",
    "                topo = topocharge(field)\n",
    "                ifacc = \"ACCEPT\" if acc else \"REJECT\"\n",
    "                status = f\"Traj: {n*param.ntraj+i+1:4}  {ifacc}:  dH: {dH:< 12.8}  exp(-dH): {exp_mdH:< 12.8}  plaq: {plaq:< 12.8}  topo: {topo:< 3.3}\\n\"\n",
    "                O.write(status)\n",
    "                if (i+1) % (param.ntraj//param.nprint) == 0:\n",
    "                    put(status)\n",
    "            t += timer()\n",
    "            ts.append(t)\n",
    "        print(\"Run times: \", ts)\n",
    "        print(\"Per trajectory: \", [t/param.ntraj for t in ts])\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latsize = (8, 8)\n",
      "volume = 64\n",
      "beta = 2.0\n",
      "trajs = 4\n",
      "tau = 0.5\n",
      "steps = 64\n",
      "seed = 1331\n",
      "nth = 2\n",
      "nth_interop = 2\n",
      "Initial configuration:  plaq: 0.7629951284651968  topo: -1.0\n",
      "13.22268982123488 (-53.34181291527922, -54.876554449401496) 0.9655721914591343\n",
      "Traj:    1  ACCEPT:  dH:  0.0030688103  exp(-dH):  0.99693589   plaq:  0.68926726   topo: -1.0\n",
      "21.852915596175038 (-54.85201954833743, -52.21010307281895) 0.9534584595204836\n",
      "Traj:    2  ACCEPT:  dH: -0.079341423  exp(-dH):  1.0825739    plaq:  0.63487933   topo: -2.0\n",
      "20.332651317477275 (-52.29965736350433, -52.47600352890689) 0.9622497587200374\n",
      "Traj:    3  ACCEPT:  dH: -0.048030786  exp(-dH):  1.049203     plaq:  0.69466522   topo: -1.0\n",
      "27.52295044775975 (-52.42782795609963, -53.22876146049952) 0.9555116848770403\n",
      "Traj:    4  ACCEPT:  dH:  1.252823     exp(-dH):  0.28569713   plaq:  0.70510825   topo:  0.0\n",
      "21.40765677353727 (-53.19172805413828, -54.22214120009521) 0.9576481950578482\n",
      "Traj:    5  ACCEPT:  dH: -0.0062113797  exp(-dH):  1.0062307    plaq:  0.65030742   topo: -1.0\n",
      "16.841830740299418 (-54.22748315514579, -53.90301698814448) 0.9601574801340895\n",
      "Traj:    6  ACCEPT:  dH:  0.24558276   exp(-dH):  0.78224855   plaq:  0.6817835    topo: -2.0\n",
      "18.642018998549183 (-53.60296202582548, -53.36213511418938) 0.9567156725909565\n",
      "Traj:    7  ACCEPT:  dH: -0.12258184   exp(-dH):  1.1304116    plaq:  0.78131451   topo:  0.0\n",
      "17.50636669030151 (-53.368187333986874, -54.102793172134604) 0.9543939137393328\n",
      "Traj:    8  ACCEPT:  dH: -0.011091152  exp(-dH):  1.0111529    plaq:  0.78403228   topo: -1.0\n",
      "29.96678608387395 (-54.1318048331397, -51.96387634217653) 0.9742582017203346\n",
      "Traj:    9  ACCEPT:  dH: -0.65660702   exp(-dH):  1.9282388    plaq:  0.70033335   topo:  0.0\n",
      "13.568331323938978 (-52.24272615056604, -55.196593466721154) 0.9784165716667839\n",
      "Traj:   10  ACCEPT:  dH:  0.028866478  exp(-dH):  0.97154618   plaq:  0.7793283    topo:  0.0\n",
      "26.76217986431581 (-55.2427829496262, -53.23526281926979) 0.9363660804731317\n",
      "Traj:   11  ACCEPT:  dH:  0.0074899877  exp(-dH):  0.99253799   plaq:  0.71177033   topo:  0.0\n",
      "22.426853582033733 (-53.21290055570764, -52.67714911646016) 0.9708587200059952\n",
      "Traj:   12  ACCEPT:  dH:  0.72721795   exp(-dH):  0.48325155   plaq:  0.6347181    topo:  1.0\n",
      "16.65748654911526 (-52.65180344946798, -53.35282960295459) 0.9670082936476552\n",
      "Traj:   13  ACCEPT:  dH:  0.010087434  exp(-dH):  0.98996327   plaq:  0.69443945   topo:  1.0\n",
      "28.033647314789693 (-53.35015657568346, -52.17616338117715) 0.9151446944828661\n",
      "Traj:   14  ACCEPT:  dH: -0.043516711  exp(-dH):  1.0444774    plaq:  0.67539184   topo:  2.0\n",
      "20.712767166784396 (-52.1964396912344, -53.59243422886683) 0.9613416976972291\n",
      "Traj:   15  ACCEPT:  dH: -0.22871109   exp(-dH):  1.2569788    plaq:  0.77471588   topo:  1.0\n",
      "16.777240050073022 (-53.6478135401468, -54.00864939201826) 0.9744333509035364\n",
      "Traj:   16  ACCEPT:  dH:  0.2685369    exp(-dH):  0.76449721   plaq:  0.76536955   topo: -1.0\n",
      "Run times:  [55.79683412401937, 57.87450488610193, 56.88082876102999, 57.00176548003219]\n",
      "Per trajectory:  [13.949208531004842, 14.468626221525483, 14.220207190257497, 14.250441370008048]\n"
     ]
    }
   ],
   "source": [
    "param = Param(\n",
    "    beta = 2.0,\n",
    "    lat = (8, 8),\n",
    "    tau = 0.5, # 0.3\n",
    "    nstep = 64, # 3\n",
    "    # ADJUST ME\n",
    "    ntraj = 4, # 2**16 # 2**10 # 2**15\n",
    "    nprint = 4,\n",
    "    #\n",
    "    seed = 1331)\n",
    "\n",
    "# field = ft_run(param, pre_flow)\n",
    "field = ft_run(param, pre_flow, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latsize = (8, 8)\n",
      "volume = 64\n",
      "beta = 2.0\n",
      "trajs = 4\n",
      "tau = 0.5\n",
      "steps = 64\n",
      "seed = 1331\n",
      "nth = 2\n",
      "nth_interop = 2\n",
      "Initial configuration:  plaq: 0.635313317826161  topo: 0.0\n",
      "20.78557074806181 (-50.70482292494995, -53.69532464920362) 0.94443367886955\n",
      "Traj:    1  ACCEPT:  dH: -0.1493157    exp(-dH):  1.1610395    plaq:  0.66644803   topo:  1.0\n",
      "28.214570380777243 (-53.64952198450136, -54.10207440344347) 0.9293616738812421\n",
      "Traj:    2  ACCEPT:  dH:  0.096385415  exp(-dH):  0.90811395   plaq:  0.76428727   topo:  1.0\n",
      "18.847970377810025 (-54.09168794183857, -54.316912234755506) 0.9535372516104789\n",
      "Traj:    3  ACCEPT:  dH:  0.13176509   exp(-dH):  0.87654688   plaq:  0.74819831   topo:  0.0\n",
      "17.4003441477011 (-54.33298820802238, -56.12852759824926) 0.9407703828248026\n",
      "Traj:    4  ACCEPT:  dH: -0.13929567   exp(-dH):  1.1494639    plaq:  0.75147884   topo:  0.0\n",
      "16.556162048299715 (-56.11146213578058, -54.08786736404058) 0.977222502981708\n",
      "Traj:    5  ACCEPT:  dH: -0.010062502  exp(-dH):  1.0101133    plaq:  0.78854405   topo:  1.0\n",
      "28.14977918361849 (-54.028138815660114, -54.157816136152206) 0.9713989353727439\n",
      "Traj:    6  ACCEPT:  dH: -0.14567468   exp(-dH):  1.1568198    plaq:  0.73964296   topo:  1.0\n",
      "26.67667195157716 (-54.141928449515234, -51.69979332726899) 0.930395874965605\n",
      "Traj:    7  ACCEPT:  dH:  0.74385823   exp(-dH):  0.47527665   plaq:  0.6619682    topo:  1.0\n",
      "11.241844141673692 (-51.790884023390504, -53.25653117578951) 0.9854783796180947\n",
      "Traj:    8  ACCEPT:  dH:  0.0029241866  exp(-dH):  0.99708008   plaq:  0.77636666   topo:  1.0\n",
      "18.979296295205845 (-53.342099256359205, -53.73208435989462) 0.981908636172076\n",
      "Traj:    9  ACCEPT:  dH:  0.001917772  exp(-dH):  0.99808407   plaq:  0.66656571   topo:  1.0\n",
      "20.328196856234676 (-53.732676976329714, -51.25266394925195) 0.9520393162225609\n",
      "Traj:   10  ACCEPT:  dH: -0.28579799   exp(-dH):  1.3308236    plaq:  0.63094852   topo:  1.0\n",
      "28.50368930878601 (-51.32864447253091, -54.25541597452159) 0.948805578024377\n",
      "Traj:   11  ACCEPT:  dH: -0.025505669  exp(-dH):  1.0258337    plaq:  0.73242034   topo:  0.0\n",
      "25.923307359880287 (-54.275344767440785, -54.5696174897319) 0.9405312198355233\n",
      "Traj:   12  REJECT:  dH:  0.062583032  exp(-dH):  0.93933506   plaq:  0.73242045   topo:  0.0\n",
      "37.92062825349643 (-54.136003568973436, -53.72659415822201) 0.9171647393348786\n",
      "Traj:   13  ACCEPT:  dH: -0.41741521   exp(-dH):  1.5180327    plaq:  0.72808226   topo:  1.0\n",
      "12.902694569457289 (-53.748229288454006, -54.70700678985182) 0.983155891910772\n",
      "Traj:   14  ACCEPT:  dH: -0.035297229  exp(-dH):  1.0359276    plaq:  0.74302766   topo:  1.0\n",
      "14.507157755313862 (-54.83164118124549, -51.99959935778175) 0.9889872395179719\n",
      "Traj:   15  ACCEPT:  dH: -0.0030133101  exp(-dH):  1.0030179    plaq:  0.73341548   topo: -1.0\n",
      "7.836441491505284 (-52.00317995057811, -53.37029271721141) 0.9873456309861698\n",
      "Traj:   16  ACCEPT:  dH: -7.2344501e-05  exp(-dH):  1.0000723    plaq:  0.76299513   topo: -1.0\n",
      "Run times:  [60.091177173075266, 61.58664311503526, 59.60149975202512, 59.68139710393734]\n",
      "Per trajectory:  [15.022794293268817, 15.396660778758815, 14.90037493800628, 14.920349275984336]\n"
     ]
    }
   ],
   "source": [
    "param = Param(\n",
    "    beta = 2.0,\n",
    "    lat = (8, 8),\n",
    "    tau = 0.5, # 0.3\n",
    "    nstep = 64, # 3\n",
    "    # ADJUST ME\n",
    "    ntraj = 4, # 2**16 # 2**10 # 2**15\n",
    "    nprint = 4,\n",
    "    #\n",
    "    seed = 1331)\n",
    "\n",
    "# field = ft_run(param, pre_flow)\n",
    "field = ft_run(param, pre_flow, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3476780398265165"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = np.array([l[1] for l in flattern(ft_hmc_info_list)])\n",
    "action_list = sub_avg(action_list)\n",
    "np.sqrt(average(action_list**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.652070381082513"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "force_list = np.array([l[0] for l in flattern(ft_hmc_info_list)])\n",
    "np.sqrt(average(force_list**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17.32528814  24.41830328  35.86739086  40.38043113  28.76035006\n",
      "  23.42855236  29.58922539  33.54458561  33.65143712  33.86083941\n",
      "  33.49291895  31.83862211  27.47076189  24.25968801  22.01808465\n",
      "  18.63787514  14.72785278  10.78893991   9.04838945  12.19247229\n",
      "  15.60845521  16.04484037  14.48102181  13.42641911  14.66221209\n",
      "  17.15532298  17.43832809  12.67743819   6.41088996  12.52344938\n",
      "  15.78009459  10.51769265   8.67199085  11.21120182  12.65614775\n",
      "  12.97190556  12.88566952  12.88993966  12.04653558   9.08958067\n",
      "  17.7111367   14.50481818   7.32864662   8.0942277    7.76810601\n",
      "   7.34379062   7.18410535   7.13059923   7.06343922   6.96975024\n",
      "   6.95233258   7.24697015   8.13272086   9.6659413   11.37533083\n",
      "  12.02592045 431.99648976  17.3099667   18.31988376  18.31030973\n",
      "  17.84059728  17.20681364  16.7225185   14.38948063   6.68696119\n",
      "   5.84353042   6.36965709   7.5283624    8.78319064  10.00651765\n",
      "  11.24919959  12.34706306  12.60897163  13.51418753  24.01165632\n",
      "  31.29971124  25.94277562  22.29662205  20.70033389  21.024617\n",
      "  28.90716778  36.14447002  37.03022548  39.36007002  39.34654544\n",
      "  29.94962509  22.36536695  19.89282997  19.62798038  19.9612841\n",
      "  20.53124925  21.70140027  24.0955417   27.02920046  26.28566794\n",
      "  19.68697266  12.84377053   7.77422042   8.99853054  14.11485644\n",
      "  17.58053722  17.55674289  15.21535081  12.58245509  10.66054866\n",
      "   9.4569165    8.69772762   8.17705317   7.78071047   7.43321618\n",
      "   7.06196106   6.60176433   6.09411119   6.01630566   7.51159379\n",
      "  11.12472948  16.13688851  21.98129542  29.10596766  35.50543246\n",
      "  36.75389242  34.12458117  33.82844021  38.228402    41.07780757\n",
      "  35.36235485  30.31764224  43.64047554  59.45559966  45.64833549\n",
      "  25.37343784  17.21518896  15.81127763  16.9922051   19.15899974\n",
      "  21.10177227  23.83492148  28.74288153  33.66166787  36.06002148\n",
      "  35.10776089  36.3165332   31.27838703  25.27597081  21.16821281\n",
      "  28.6010519   27.76796503  23.07244471  23.54157833  22.80338778\n",
      "  22.53157142  24.94265331  25.26853395  24.50670182  25.2857027\n",
      "  32.66593715  18.79392024  26.08561801  25.16955205  22.63593168\n",
      "  36.87112722 128.67854931 138.67205076  24.67374831  20.80117399\n",
      "  15.59983791  20.78176876  20.86998854  13.6541287   21.09095718\n",
      "  21.97646455  19.08783092  15.89268348  14.66683921  15.74681737\n",
      "  15.93543751  14.46071243  17.93969149  23.95794474  25.06713793\n",
      "  29.7347816   69.84215207  32.03081377  62.87486778  31.2865378\n",
      "  17.50356701  15.01872492  14.72385422  14.83272887  15.01567093\n",
      "  15.25760085  15.54422132  20.58824321  21.68784379  22.85853741\n",
      "  18.13883458  14.18115224  30.00897399  14.56998918  18.16203446\n",
      "  19.3206287   21.99491672  24.94253051  26.71996721  26.76924712\n",
      "  25.59832423  23.96645036  22.28550905  21.63773977  21.69296367\n",
      "  20.30519368  19.39908408  25.6829876   44.31901445  44.72155026\n",
      "  27.93616142  22.63461378  23.47283145  24.62614306  23.85355043\n",
      "  20.7865429   16.89938436  13.79814542  12.03799243  10.57184205\n",
      "  10.59760988  15.73771132  18.25790089  15.20983438  38.29237234\n",
      "  50.66668018  17.2179949   53.52520782  25.11743223  15.44824827\n",
      "  16.26211722  17.18176947  17.63541747  17.89315264  18.09822625\n",
      "  18.26424908  18.36103572  18.35782359  18.23868438  18.00501053\n",
      "  17.66324779  17.22388118  16.86612024  17.19033062  16.32913874\n",
      "  16.30787306  15.31558915  67.42549429  35.62763287  27.86026165\n",
      "  15.07835527  12.29170348  13.00993639  13.1261129   13.04974309\n",
      "  12.96536338  12.91877827  12.90107978  12.88921004  12.85051816\n",
      "  12.70458813  12.21843732  10.83117434   7.9301383    8.72558894\n",
      "  18.03819295  21.74692921  17.3873207   12.16804169   9.34334022\n",
      "   9.42801036  12.33001086  16.06973104  18.09943924  17.64828572\n",
      "  15.74309238  13.34175626  39.33431709 129.4450071  111.79527226\n",
      "  13.86674553  11.69960037  11.99184263  11.69976308  13.05144789\n",
      "  14.99894271  16.19804644  11.3673835   58.38890413  31.03324364\n",
      "  19.75638064  16.67397308  15.29795875  53.8559314   49.77008983]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(force_list[0:300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_latest]",
   "language": "python",
   "name": "conda-env-torch_latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": ""
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
