{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from functools import reduce\n",
    "from field_transformation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Xiao-Yong\n",
    "\n",
    "class Param:\n",
    "    def __init__(self, beta = 6.0, lat = [64, 64], tau = 2.0, nstep = 50, ntraj = 256, nrun = 4, nprint = 256, seed = 11*13, randinit = False, nth = int(os.environ.get('OMP_NUM_THREADS', '2')), nth_interop = 2):\n",
    "        self.beta = beta\n",
    "        self.lat = lat\n",
    "        self.nd = len(lat)\n",
    "        self.volume = reduce(lambda x,y:x*y, lat)\n",
    "        self.tau = tau\n",
    "        self.nstep = nstep\n",
    "        self.dt = self.tau / self.nstep\n",
    "        self.ntraj = ntraj\n",
    "        self.nrun = nrun\n",
    "        self.nprint = nprint\n",
    "        self.seed = seed\n",
    "        self.randinit = randinit\n",
    "        self.nth = nth\n",
    "        self.nth_interop = nth_interop\n",
    "    def initializer(self):\n",
    "        if self.randinit:\n",
    "            return torch.empty((param.nd,) + param.lat).uniform_(-math.pi, math.pi)\n",
    "        else:\n",
    "            return torch.zeros((param.nd,) + param.lat)\n",
    "    def summary(self):\n",
    "        return f\"\"\"latsize = {self.lat}\n",
    "volume = {self.volume}\n",
    "beta = {self.beta}\n",
    "trajs = {self.ntraj}\n",
    "tau = {self.tau}\n",
    "steps = {self.nstep}\n",
    "seed = {self.seed}\n",
    "nth = {self.nth}\n",
    "nth_interop = {self.nth_interop}\n",
    "\"\"\"\n",
    "    def uniquestr(self):\n",
    "        lat = \".\".join(str(x) for x in self.lat)\n",
    "        return f\"out_l{lat}_b{param.beta}_n{param.ntraj}_t{param.tau}_s{param.nstep}.out\"\n",
    "\n",
    "def action(param, f):\n",
    "    return (-param.beta)*torch.sum(torch.cos(plaqphase(f)))\n",
    "\n",
    "def force(param, f):\n",
    "    f.requires_grad_(True)\n",
    "    s = action(param, f)\n",
    "    f.grad = None\n",
    "    s.backward()\n",
    "    ff = f.grad\n",
    "    f.requires_grad_(False)\n",
    "    return ff\n",
    "\n",
    "plaqphase = lambda f: f[0,:] - f[1,:] - torch.roll(f[0,:], shifts=-1, dims=1) + torch.roll(f[1,:], shifts=-1, dims=0)\n",
    "topocharge = lambda f: torch.floor(0.1 + torch.sum(regularize(plaqphase(f))) / (2*math.pi))\n",
    "def regularize(f):\n",
    "    p2 = 2*math.pi\n",
    "    f_ = (f - math.pi) / p2\n",
    "    return p2*(f_ - torch.floor(f_) - 0.5)\n",
    "\n",
    "def leapfrog(param, x, p):\n",
    "    dt = param.dt\n",
    "    x_ = x + 0.5*dt*p\n",
    "    f = force(param, x_)\n",
    "    p_ = p + (-dt)*f\n",
    "    print(f'plaq(x) {action(param, x) / (-param.beta*param.volume)}  force.norm {torch.linalg.norm(f)}')\n",
    "    for i in range(param.nstep-1):\n",
    "        x_ = x_ + dt*p_\n",
    "        p_ = p_ + (-dt)*force(param, x_)\n",
    "    x_ = x_ + 0.5*dt*p_\n",
    "    return (x_, p_)\n",
    "def hmc(param, x):\n",
    "    p = torch.randn_like(x)\n",
    "    act0 = action(param, x) + 0.5*torch.sum(p*p)\n",
    "    x_, p_ = leapfrog(param, x, p)\n",
    "    xr = regularize(x_)\n",
    "    act = action(param, xr) + 0.5*torch.sum(p_*p_)\n",
    "    prob = torch.rand([], dtype=torch.float64)\n",
    "    dH = act-act0\n",
    "    exp_mdH = torch.exp(-dH)\n",
    "    acc = prob < exp_mdH\n",
    "    newx = xr if acc else x\n",
    "    return (dH, exp_mdH, acc, newx)\n",
    "\n",
    "put = lambda s: sys.stdout.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = Param(\n",
    "    beta = 2.0,\n",
    "    lat = (8, 8),\n",
    "    tau = 2, # 0.3\n",
    "    nstep = 8, # 3\n",
    "    # ADJUST ME\n",
    "    ntraj = 2, # 2**16 # 2**10 # 2**15\n",
    "    #\n",
    "    nprint = 2,\n",
    "    seed = 1331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(param.seed)\n",
    "\n",
    "torch.set_num_threads(param.nth)\n",
    "torch.set_num_interop_threads(param.nth_interop)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(param.nth)\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"0\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latsize = (8, 8)\n",
      "volume = 64\n",
      "beta = 2.0\n",
      "trajs = 2\n",
      "tau = 2\n",
      "steps = 8\n",
      "seed = 1331\n",
      "nth = 2\n",
      "nth_interop = 2\n",
      "Initial configuration:  plaq: 1.0  topo: 0.0\n",
      "plaq(x) 1.0  force.norm 9.246826593536493\n",
      "Traj:    1  ACCEPT:  dH: -2.1286122    exp(-dH):  8.4031965    plaq:  0.87165922   topo:  0.0\n",
      "plaq(x) 0.8716592163190823  force.norm 13.60065719819702\n",
      "Traj:    2  ACCEPT:  dH: -0.43065065   exp(-dH):  1.5382581    plaq:  0.85113562   topo:  0.0\n",
      "plaq(x) 0.851135619433136  force.norm 17.54309727438331\n",
      "Traj:    3  ACCEPT:  dH: -0.52286113   exp(-dH):  1.686847     plaq:  0.81229714   topo:  0.0\n",
      "plaq(x) 0.8122971355705815  force.norm 17.226420992986522\n",
      "Traj:    4  ACCEPT:  dH:  0.039753441  exp(-dH):  0.96102636   plaq:  0.78167924   topo:  0.0\n",
      "plaq(x) 0.7816792404187667  force.norm 17.04668749206334\n",
      "Traj:    5  ACCEPT:  dH:  0.42993024   exp(-dH):  0.65055447   plaq:  0.80392524   topo:  0.0\n",
      "plaq(x) 0.803925239737245  force.norm 17.257422008841356\n",
      "Traj:    6  ACCEPT:  dH: -0.96340329   exp(-dH):  2.6206       plaq:  0.78202049   topo:  0.0\n",
      "plaq(x) 0.7820204923371585  force.norm 18.801543612929564\n",
      "Traj:    7  ACCEPT:  dH: -0.74395609   exp(-dH):  2.1042436    plaq:  0.69283802   topo:  0.0\n",
      "plaq(x) 0.6928380205992224  force.norm 20.552012705600852\n",
      "Traj:    8  ACCEPT:  dH: -0.49108779   exp(-dH):  1.6340928    plaq:  0.66276864   topo:  0.0\n",
      "Run times:  [0.034382381942123175, 0.023102940060198307, 0.01823049201630056, 0.013534630998037755]\n",
      "Per trajectory:  [0.017191190971061587, 0.011551470030099154, 0.00911524600815028, 0.006767315499018878]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    }
   ],
   "source": [
    "def run(param, field = param.initializer()):\n",
    "    with open(param.uniquestr(), \"w\") as O:\n",
    "        params = param.summary()\n",
    "        O.write(params)\n",
    "        put(params)\n",
    "        plaq, topo = (action(param, field) / (-param.beta*param.volume), topocharge(field))\n",
    "        status = f\"Initial configuration:  plaq: {plaq}  topo: {topo}\\n\"\n",
    "        O.write(status)\n",
    "        put(status)\n",
    "        ts = []\n",
    "        for n in range(param.nrun):\n",
    "            t = -timer()\n",
    "            for i in range(param.ntraj):\n",
    "                dH, exp_mdH, acc, field = hmc(param, field)\n",
    "                plaq = action(param, field) / (-param.beta*param.volume)\n",
    "                topo = topocharge(field)\n",
    "                ifacc = \"ACCEPT\" if acc else \"REJECT\"\n",
    "                status = f\"Traj: {n*param.ntraj+i+1:4}  {ifacc}:  dH: {dH:< 12.8}  exp(-dH): {exp_mdH:< 12.8}  plaq: {plaq:< 12.8}  topo: {topo:< 3.3}\\n\"\n",
    "                O.write(status)\n",
    "                if (i+1) % (param.ntraj//param.nprint) == 0:\n",
    "                    put(status)\n",
    "            t += timer()\n",
    "            ts.append(t)\n",
    "        print(\"Run times: \", ts)\n",
    "        print(\"Per trajectory: \", [t/param.ntraj for t in ts])\n",
    "    return field\n",
    "field = run(param)\n",
    "field = torch.reshape(field,(1,)+field.shape)\n",
    "field_run = field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_flow(flow, f):\n",
    "    for layer in flow:\n",
    "        f, lJ = layer.forward(f)\n",
    "    return f.detach()\n",
    "\n",
    "def ft_flow_inv(flow, f):\n",
    "    for layer in reversed(flow):\n",
    "        f, lJ = layer.reverse(f)\n",
    "    return f.detach()\n",
    "\n",
    "def ft_action(param, flow, f):\n",
    "    y = f\n",
    "    logJy = 0.0\n",
    "    for layer in flow:\n",
    "        y, lJ = layer.forward(y)\n",
    "        logJy += lJ\n",
    "    action = U1GaugeAction(param.beta)\n",
    "    s = action(y) - logJy\n",
    "    return s\n",
    "\n",
    "def ft_force(param, flow, field, create_graph = False):\n",
    "    # f is the field follows the transformed distribution (close to prior distribution)\n",
    "    f = field\n",
    "    f.requires_grad_(True)\n",
    "    s = ft_action(param, flow, f)\n",
    "    ss = torch.sum(s)\n",
    "    # f.grad = None\n",
    "    ff, = torch.autograd.grad(ss, f, create_graph = create_graph)\n",
    "    f.requires_grad_(False)\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, action, optimizer, metrics, batch_size, with_force = False, pre_model = None):\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "    optimizer.zero_grad()\n",
    "    #\n",
    "    xi = None\n",
    "    if pre_model != None:\n",
    "        pre_layers, pre_prior = pre_model['layers'], pre_model['prior']\n",
    "        pre_xi = pre_prior.sample_n(batch_size)\n",
    "        x = ft_flow(pre_layers, pre_xi)\n",
    "        xi = ft_flow_inv(layers, x)\n",
    "    #\n",
    "    xi, x, logq = apply_flow_to_prior(prior, layers, batch_size=batch_size, xi=xi)\n",
    "    logp = -action(x)\n",
    "    #\n",
    "    force_size = torch.tensor(0.0)\n",
    "    dkl = calc_dkl(logp, logq)\n",
    "    loss = torch.tensor(0.0)\n",
    "    if with_force:\n",
    "        assert pre_model != None\n",
    "        force = ft_force(param, layers, xi, True)\n",
    "        force_size = torch.sum(torch.square(force)) / 1000\n",
    "        loss = force_size\n",
    "    else:\n",
    "        loss = dkl\n",
    "    #\n",
    "    loss.backward()\n",
    "    #\n",
    "    # minimization target\n",
    "    # loss mini\n",
    "    # -> (logq - logp) mini\n",
    "    # -> (action - logJ) mini\n",
    "    #\n",
    "    optimizer.step()\n",
    "    ess = compute_ess(logp, logq)\n",
    "    #\n",
    "    print(grab(loss),\n",
    "          grab(force_size),\n",
    "          grab(dkl),\n",
    "          grab(ess),\n",
    "          torch.linalg.norm(ft_force(param, layers, xi)))\n",
    "    #\n",
    "    metrics['loss'].append(grab(loss))\n",
    "    metrics['force'].append(grab(force_size))\n",
    "    metrics['dkl'].append(grab(dkl))\n",
    "    metrics['logp'].append(grab(logp))\n",
    "    metrics['logq'].append(grab(logq))\n",
    "    metrics['ess'].append(grab(ess))\n",
    "\n",
    "def flow_train(param, with_force = False, pre_model = None):  # packaged from original ipynb by Xiao-Yong Jin\n",
    "    # Theory\n",
    "    lattice_shape = param.lat\n",
    "    link_shape = (2,*param.lat)\n",
    "    beta = param.beta\n",
    "    u1_action = U1GaugeAction(beta)\n",
    "    # Model\n",
    "    prior = MultivariateUniform(torch.zeros(link_shape), 2*np.pi*torch.ones(link_shape))\n",
    "    #\n",
    "    n_layers = 16\n",
    "    n_s_nets = 2\n",
    "    hidden_sizes = [8,8]\n",
    "    kernel_size = 3\n",
    "    layers = make_u1_equiv_layers(lattice_shape=lattice_shape, n_layers=n_layers, n_mixture_comps=n_s_nets,\n",
    "                                  hidden_sizes=hidden_sizes, kernel_size=kernel_size)\n",
    "    set_weights(layers)\n",
    "    model = {'layers': layers, 'prior': prior}\n",
    "    # Training\n",
    "    base_lr = .001\n",
    "    if with_force:\n",
    "        base_lr = .0001\n",
    "    optimizer = torch.optim.Adam(model['layers'].parameters(), lr=base_lr)\n",
    "    #\n",
    "    # ADJUST ME\n",
    "    N_era = 10\n",
    "    N_epoch = 100\n",
    "    #\n",
    "    batch_size = 64\n",
    "    print_freq = N_epoch # epochs\n",
    "    plot_freq = 1 # epochs\n",
    "    history = {\n",
    "        'loss' : [],\n",
    "        'force' : [],\n",
    "        'dkl' : [],\n",
    "        'logp' : [],\n",
    "        'logq' : [],\n",
    "        'ess' : []\n",
    "    }\n",
    "    for era in range(N_era):\n",
    "        for epoch in range(N_epoch):\n",
    "            train_step(model, u1_action, optimizer, history, batch_size,\n",
    "                       with_force = with_force, pre_model = pre_model)\n",
    "            if epoch % print_freq == 0:\n",
    "                print_metrics(history, print_freq, era, epoch)\n",
    "    return model,u1_action\n",
    "\n",
    "def flow_eval(model, u1_action):  # packaged from original ipynb by Xiao-Yong Jin\n",
    "    ensemble_size = 1024\n",
    "    u1_ens = make_mcmc_ensemble(model, u1_action, 64, ensemble_size)\n",
    "    print(\"Accept rate:\", np.mean(u1_ens['accepted']))\n",
    "    Q = grab(topo_charge(torch.stack(u1_ens['x'], axis=0)))\n",
    "    X_mean, X_err = bootstrap(Q**2, Nboot=100, binsize=16)\n",
    "    print(f'Topological susceptibility = {X_mean:.2f} +/- {X_err:.2f}')\n",
    "    print(f'... vs HMC estimate = 1.23 +/- 0.02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-235.34537692516128 0.0 -235.34537692516128 0.044984338671787305 tensor(179.4703)\n",
      "== Era 0 | Epoch 0 metrics ==\n",
      "\tloss -235.345\n",
      "\tforce 0\n",
      "\tdkl -235.345\n",
      "\tlogp 0.326149\n",
      "\tlogq -235.019\n",
      "\tess 0.0449843\n",
      "-239.1383882108473 0.0 -239.1383882108473 0.019970337139737032 tensor(175.4217)\n",
      "-239.51936855245063 0.0 -239.51936855245063 0.01603148961419505 tensor(175.1459)\n",
      "-243.8019138166205 0.0 -243.8019138166205 0.015768733372372272 tensor(167.5826)\n",
      "-246.55102833203563 0.0 -246.55102833203563 0.01712442356040787 tensor(167.7365)\n",
      "-248.18771779704565 0.0 -248.18771779704565 0.024465609045932344 tensor(162.6325)\n",
      "-251.1713251794792 0.0 -251.1713251794792 0.015640384689887384 tensor(158.9293)\n",
      "-253.6046561143978 0.0 -253.6046561143978 0.01766402489483935 tensor(156.8462)\n",
      "-256.6035089734507 0.0 -256.6035089734507 0.016136360062499903 tensor(158.3880)\n",
      "-258.2002477654431 0.0 -258.2002477654431 0.02161296312517467 tensor(158.9310)\n",
      "-260.66395259167905 0.0 -260.66395259167905 0.060672253207140425 tensor(157.5602)\n",
      "-261.51050129106875 0.0 -261.51050129106875 0.017244046794835488 tensor(155.6108)\n",
      "-263.88268395648834 0.0 -263.88268395648834 0.015844088284593834 tensor(156.2127)\n",
      "-265.72487451441157 0.0 -265.72487451441157 0.01591831497507033 tensor(159.5851)\n",
      "-268.92309862451356 0.0 -268.92309862451356 0.016622321134039542 tensor(164.2767)\n",
      "-272.0241642711224 0.0 -272.0241642711224 0.01710701802927439 tensor(153.7520)\n",
      "-274.11069369466315 0.0 -274.11069369466315 0.040158065877438726 tensor(169.2346)\n",
      "-274.36975714026954 0.0 -274.36975714026954 0.015724487163325893 tensor(169.5316)\n",
      "-275.14675011493284 0.0 -275.14675011493284 0.023796942049181865 tensor(172.4833)\n",
      "-275.761612850646 0.0 -275.761612850646 0.056746416725556234 tensor(186.3315)\n",
      "-275.9533526194036 0.0 -275.9533526194036 0.02695020182138144 tensor(181.6524)\n",
      "-277.92933339438304 0.0 -277.92933339438304 0.0183274874457244 tensor(178.4865)\n",
      "-277.3040719811412 0.0 -277.3040719811412 0.043780962047976435 tensor(204.7843)\n",
      "-277.48822171342783 0.0 -277.48822171342783 0.02182243255646872 tensor(191.7634)\n",
      "-278.06223786271016 0.0 -278.06223786271016 0.04285965930211635 tensor(202.0565)\n",
      "-278.6445091297627 0.0 -278.6445091297627 0.017799631148772716 tensor(193.2346)\n",
      "-278.07341156608345 0.0 -278.07341156608345 0.05526647434684295 tensor(199.5358)\n",
      "-277.11815337609517 0.0 -277.11815337609517 0.05599916777712717 tensor(197.8482)\n",
      "-277.6442805656185 0.0 -277.6442805656185 0.020033573510247885 tensor(210.0630)\n",
      "-277.3370575230251 0.0 -277.3370575230251 0.01637935357772341 tensor(204.8906)\n",
      "-278.56514894563907 0.0 -278.56514894563907 0.05438172445363844 tensor(199.7781)\n",
      "-278.17996294130603 0.0 -278.17996294130603 0.0156316904706958 tensor(196.3221)\n",
      "-278.80685372550977 0.0 -278.80685372550977 0.053121918747439434 tensor(200.4471)\n",
      "-278.443509308505 0.0 -278.443509308505 0.04349916158483231 tensor(200.2030)\n",
      "-279.8097920122779 0.0 -279.8097920122779 0.0284749554149418 tensor(196.2518)\n",
      "-279.4003828082482 0.0 -279.4003828082482 0.06091076622325348 tensor(189.8951)\n",
      "-279.65621711727135 0.0 -279.65621711727135 0.09405994003489569 tensor(197.7714)\n",
      "-279.57706730904937 0.0 -279.57706730904937 0.05714902192381919 tensor(182.8704)\n",
      "-280.219380911339 0.0 -280.219380911339 0.02755377547503786 tensor(186.6636)\n",
      "-279.85725988231525 0.0 -279.85725988231525 0.022650157116028153 tensor(182.9743)\n",
      "-278.8965391615815 0.0 -278.8965391615815 0.059727948539627596 tensor(185.8670)\n",
      "-279.78153776116824 0.0 -279.78153776116824 0.017819462732492613 tensor(180.8659)\n",
      "-279.36786324507864 0.0 -279.36786324507864 0.03306339585583853 tensor(183.2178)\n",
      "-280.17195565208254 0.0 -280.17195565208254 0.06088334891470556 tensor(172.4305)\n",
      "-280.62655467294155 0.0 -280.62655467294155 0.09869818421315901 tensor(172.5405)\n",
      "-281.033864475394 0.0 -281.033864475394 0.037990236334002565 tensor(168.3162)\n",
      "-279.82712740450427 0.0 -279.82712740450427 0.054651823084276525 tensor(168.3511)\n",
      "-279.9236218657097 0.0 -279.9236218657097 0.07158546910057662 tensor(169.6106)\n",
      "-279.7595314234702 0.0 -279.7595314234702 0.043024124910688986 tensor(184.6041)\n",
      "-279.9791530282529 0.0 -279.9791530282529 0.15400229289157955 tensor(171.1330)\n",
      "-279.684625431717 0.0 -279.684625431717 0.04784387959064411 tensor(182.5535)\n",
      "-280.5112121098586 0.0 -280.5112121098586 0.0604768085276908 tensor(182.1142)\n",
      "-279.39939126335645 0.0 -279.39939126335645 0.019557998803710876 tensor(177.9111)\n",
      "-280.62392812125296 0.0 -280.62392812125296 0.016270012356661537 tensor(178.3979)\n",
      "-280.24610488594817 0.0 -280.24610488594817 0.05369547032554527 tensor(191.5720)\n",
      "-280.7748156164788 0.0 -280.7748156164788 0.028978345780608823 tensor(178.1314)\n",
      "-279.7077698011542 0.0 -279.7077698011542 0.026961331330857253 tensor(184.6966)\n",
      "-280.1773260079273 0.0 -280.1773260079273 0.024880863486697977 tensor(180.7460)\n",
      "-280.45064807705626 0.0 -280.45064807705626 0.10404694012748375 tensor(191.3968)\n",
      "-280.251017258923 0.0 -280.251017258923 0.03413847363612734 tensor(176.5319)\n",
      "-281.0664174472016 0.0 -281.0664174472016 0.05801214915792266 tensor(180.9439)\n",
      "-280.5050182089579 0.0 -280.5050182089579 0.06380510057137345 tensor(188.1831)\n",
      "-280.6610969845977 0.0 -280.6610969845977 0.054756380142995206 tensor(181.2926)\n",
      "-280.78189883577613 0.0 -280.78189883577613 0.03719134304549099 tensor(191.9081)\n",
      "-279.6787382244495 0.0 -279.6787382244495 0.059751138121171866 tensor(189.5231)\n",
      "-280.93810868392364 0.0 -280.93810868392364 0.08627916116138025 tensor(190.0341)\n",
      "-280.8834026081424 0.0 -280.8834026081424 0.0811071362214918 tensor(193.1875)\n",
      "-280.811306011045 0.0 -280.811306011045 0.035843762767673745 tensor(180.2817)\n",
      "-279.8436005058764 0.0 -279.8436005058764 0.07013096240902882 tensor(189.2950)\n",
      "-280.78598621437334 0.0 -280.78598621437334 0.038114657237717293 tensor(180.7156)\n",
      "-280.9371431947901 0.0 -280.9371431947901 0.022074376248797833 tensor(185.8073)\n",
      "-280.8711116614542 0.0 -280.8711116614542 0.01951538626812846 tensor(195.3805)\n",
      "-281.19535003105557 0.0 -281.19535003105557 0.09415576758716811 tensor(172.3543)\n",
      "-281.1499476923866 0.0 -281.1499476923866 0.08427481802249624 tensor(172.4006)\n",
      "-281.3675784602054 0.0 -281.3675784602054 0.021449600593434925 tensor(182.0137)\n",
      "-280.8822613657403 0.0 -280.8822613657403 0.037440031976337315 tensor(187.1274)\n",
      "-281.2658386424407 0.0 -281.2658386424407 0.08592114355595551 tensor(181.8781)\n",
      "-281.2137056609888 0.0 -281.2137056609888 0.03754954625390278 tensor(177.6654)\n",
      "-280.69161900682263 0.0 -280.69161900682263 0.036134082099353405 tensor(172.8413)\n",
      "-281.2708993718529 0.0 -281.2708993718529 0.015945832644889635 tensor(176.0383)\n",
      "-281.4123645967167 0.0 -281.4123645967167 0.04584880450772819 tensor(173.5191)\n",
      "-281.82529948038416 0.0 -281.82529948038416 0.023209501737370054 tensor(178.9371)\n",
      "-281.3914225279695 0.0 -281.3914225279695 0.04493468584837422 tensor(183.0717)\n",
      "-281.1173299580548 0.0 -281.1173299580548 0.04940227638882876 tensor(177.8064)\n",
      "-281.35818097250865 0.0 -281.35818097250865 0.029010433297839776 tensor(173.8254)\n",
      "-280.9635324420158 0.0 -280.9635324420158 0.017593948752264464 tensor(170.3786)\n",
      "-281.163672346334 0.0 -281.163672346334 0.02034815893266618 tensor(183.1742)\n",
      "-280.96683652401134 0.0 -280.96683652401134 0.05344711038625961 tensor(178.2748)\n",
      "-281.9163615523445 0.0 -281.9163615523445 0.11185461405940941 tensor(184.6953)\n",
      "-281.70041427682406 0.0 -281.70041427682406 0.04205424666403773 tensor(182.1325)\n",
      "-282.14199362769625 0.0 -282.14199362769625 0.02759076381158063 tensor(184.5113)\n",
      "-281.9617139061282 0.0 -281.9617139061282 0.06772586205248128 tensor(179.9613)\n",
      "-281.2654263308126 0.0 -281.2654263308126 0.05586328176301888 tensor(188.3158)\n",
      "-281.16179949245753 0.0 -281.16179949245753 0.07550059090236835 tensor(187.5422)\n",
      "-282.49271997441025 0.0 -282.49271997441025 0.15284506073929935 tensor(169.2043)\n",
      "-281.2829302503189 0.0 -281.2829302503189 0.11276326716938445 tensor(190.4766)\n",
      "-282.5800966808655 0.0 -282.5800966808655 0.01675193920252009 tensor(179.3808)\n",
      "-282.31946216223616 0.0 -282.31946216223616 0.11934360962563464 tensor(170.8425)\n",
      "-281.67640204665884 0.0 -281.67640204665884 0.04957405508060419 tensor(183.8259)\n",
      "-282.67036972007804 0.0 -282.67036972007804 0.09863845099135374 tensor(168.3950)\n",
      "-282.0482254045409 0.0 -282.0482254045409 0.04458755069964662 tensor(178.0375)\n",
      "== Era 1 | Epoch 0 metrics ==\n",
      "\tloss -276.304\n",
      "\tforce 0\n",
      "\tdkl -276.304\n",
      "\tlogp 64.6121\n",
      "\tlogq -211.692\n",
      "\tess 0.0456754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-282.2183491919442 0.0 -282.2183491919442 0.035489424739586224 tensor(176.1671)\n",
      "-281.80745413557906 0.0 -281.80745413557906 0.03223995457395436 tensor(176.2737)\n",
      "-281.5786820609213 0.0 -281.5786820609213 0.08399880218640958 tensor(186.4566)\n",
      "-282.62302465971686 0.0 -282.62302465971686 0.03741876243752672 tensor(172.6518)\n",
      "-282.24374305783067 0.0 -282.24374305783067 0.05084161874060404 tensor(180.6271)\n",
      "-281.409349402846 0.0 -281.409349402846 0.13656446152717197 tensor(181.3924)\n",
      "-282.784865970826 0.0 -282.784865970826 0.0744670922018435 tensor(182.1504)\n",
      "-283.26606936989566 0.0 -283.26606936989566 0.02623195903615557 tensor(179.7745)\n",
      "-282.5064218255832 0.0 -282.5064218255832 0.05677787623545568 tensor(174.7246)\n",
      "-282.245081479515 0.0 -282.245081479515 0.12671190051680237 tensor(189.0983)\n",
      "-282.62423284798393 0.0 -282.62423284798393 0.042411842654495095 tensor(176.2400)\n",
      "-282.1892687908897 0.0 -282.1892687908897 0.0886350361750449 tensor(182.5670)\n",
      "-283.13641900257517 0.0 -283.13641900257517 0.05654391203810353 tensor(181.3715)\n",
      "-282.4141506779995 0.0 -282.4141506779995 0.03797720760149719 tensor(181.2802)\n",
      "-281.69943364204227 0.0 -281.69943364204227 0.02479114490873826 tensor(186.6312)\n",
      "-282.8145881174961 0.0 -282.8145881174961 0.12879306925862405 tensor(182.9701)\n",
      "-282.6576116343628 0.0 -282.6576116343628 0.026058811820070464 tensor(174.1428)\n",
      "-281.9045873704491 0.0 -281.9045873704491 0.07401757169788337 tensor(176.5488)\n",
      "-281.9241135564794 0.0 -281.9241135564794 0.021674948088754344 tensor(178.5651)\n",
      "-282.58506315946323 0.0 -282.58506315946323 0.054969876621468114 tensor(175.9771)\n",
      "-282.8221440534537 0.0 -282.8221440534537 0.060235092036641714 tensor(183.2793)\n",
      "-283.1575143737971 0.0 -283.1575143737971 0.02387033097882415 tensor(168.6776)\n",
      "-282.72163201644685 0.0 -282.72163201644685 0.06804583050383246 tensor(181.7649)\n",
      "-282.32408852684995 0.0 -282.32408852684995 0.06154253864237041 tensor(177.8500)\n",
      "-282.70621663953085 0.0 -282.70621663953085 0.028622312657531897 tensor(168.8674)\n",
      "-282.8094588805331 0.0 -282.8094588805331 0.018665688174398266 tensor(176.5408)\n",
      "-282.63723300502323 0.0 -282.63723300502323 0.10021790558655004 tensor(179.7700)\n",
      "-283.3579384252105 0.0 -283.3579384252105 0.05189148516343724 tensor(170.9027)\n",
      "-283.10038887227495 0.0 -283.10038887227495 0.038200552092651566 tensor(177.9523)\n",
      "-282.68798803012044 0.0 -282.68798803012044 0.025518272706880712 tensor(177.5988)\n",
      "-281.98884408961317 0.0 -281.98884408961317 0.02382872748704205 tensor(179.5276)\n",
      "-282.7261540436 0.0 -282.7261540436 0.04177959496051771 tensor(175.0303)\n",
      "-283.1636429933959 0.0 -283.1636429933959 0.0396354025333954 tensor(169.3717)\n",
      "-282.6732397282751 0.0 -282.6732397282751 0.033515291450720124 tensor(176.3352)\n",
      "-282.8378788255129 0.0 -282.8378788255129 0.04227902967625471 tensor(174.1817)\n",
      "-283.02466326601143 0.0 -283.02466326601143 0.09228048923094395 tensor(161.3621)\n",
      "-283.2038815349667 0.0 -283.2038815349667 0.026270597524305016 tensor(167.7969)\n",
      "-283.21567817960874 0.0 -283.21567817960874 0.09422648674796545 tensor(179.4490)\n",
      "-283.6466768042698 0.0 -283.6466768042698 0.07868024723971734 tensor(175.5804)\n",
      "-283.22758409731614 0.0 -283.22758409731614 0.033494321702104694 tensor(167.0371)\n",
      "-282.91624888111716 0.0 -282.91624888111716 0.09313566211703823 tensor(184.8681)\n",
      "-283.2002939378831 0.0 -283.2002939378831 0.04473349797437319 tensor(181.6628)\n",
      "-283.07145639155016 0.0 -283.07145639155016 0.025996375498481068 tensor(171.0386)\n",
      "-283.4605292200162 0.0 -283.4605292200162 0.09357857623588453 tensor(176.6584)\n",
      "-283.07973130084844 0.0 -283.07973130084844 0.09228574501682461 tensor(184.9057)\n",
      "-283.6691988893848 0.0 -283.6691988893848 0.10165913568647302 tensor(172.4988)\n",
      "-283.38250680359056 0.0 -283.38250680359056 0.09548665624980227 tensor(173.0412)\n",
      "-283.6224976444765 0.0 -283.6224976444765 0.049340566236146376 tensor(184.0006)\n",
      "-283.6883241597587 0.0 -283.6883241597587 0.06451535911110934 tensor(178.4664)\n",
      "-283.30554309250635 0.0 -283.30554309250635 0.09371114350093046 tensor(181.0470)\n",
      "-283.77877324089513 0.0 -283.77877324089513 0.04763465791691457 tensor(176.0067)\n",
      "-283.7292995741841 0.0 -283.7292995741841 0.04608567030490222 tensor(170.1164)\n",
      "-284.11832558227127 0.0 -284.11832558227127 0.1314894656401531 tensor(171.8823)\n",
      "-283.92601006269564 0.0 -283.92601006269564 0.07504494733284962 tensor(165.5140)\n",
      "-284.04429672370566 0.0 -284.04429672370566 0.07957767768700424 tensor(157.9695)\n",
      "-282.41326664947775 0.0 -282.41326664947775 0.03533001541850169 tensor(166.9896)\n",
      "-283.9473086067256 0.0 -283.9473086067256 0.041612507080581666 tensor(175.8104)\n",
      "-283.98824422526366 0.0 -283.98824422526366 0.12197026115576506 tensor(177.9753)\n",
      "-283.250210659402 0.0 -283.250210659402 0.15450115853407995 tensor(190.9328)\n",
      "-283.45409526763973 0.0 -283.45409526763973 0.038892732803720215 tensor(163.4863)\n",
      "-283.6671859395682 0.0 -283.6671859395682 0.06452112647698251 tensor(181.3958)\n",
      "-283.6006792273894 0.0 -283.6006792273894 0.07507946272279861 tensor(177.6001)\n",
      "-283.81768837274217 0.0 -283.81768837274217 0.0767204249036231 tensor(163.9469)\n",
      "-283.16032230770463 0.0 -283.16032230770463 0.22806601901468979 tensor(183.9247)\n",
      "-283.3553721456639 0.0 -283.3553721456639 0.04747435124053382 tensor(177.6712)\n",
      "-284.23683633458927 0.0 -284.23683633458927 0.04223485513527168 tensor(172.7541)\n",
      "-283.31529699030466 0.0 -283.31529699030466 0.020349941604795918 tensor(186.1169)\n",
      "-283.2976396079178 0.0 -283.2976396079178 0.10561375074356127 tensor(179.7029)\n",
      "-283.77652495614353 0.0 -283.77652495614353 0.041980134230480796 tensor(177.8353)\n",
      "-283.53156519225513 0.0 -283.53156519225513 0.01915918994343445 tensor(175.3042)\n",
      "-284.1459713848687 0.0 -284.1459713848687 0.11287402647562687 tensor(169.5770)\n",
      "-284.2772343704645 0.0 -284.2772343704645 0.08239528527094363 tensor(195.9518)\n",
      "-284.32362958720586 0.0 -284.32362958720586 0.06774449501601605 tensor(181.8286)\n",
      "-283.48804168627703 0.0 -283.48804168627703 0.01680813510681015 tensor(181.0120)\n",
      "-284.1828337252355 0.0 -284.1828337252355 0.08977455377326575 tensor(163.3059)\n",
      "-283.3726961468532 0.0 -283.3726961468532 0.050669622969637014 tensor(171.1889)\n",
      "-283.80368413697346 0.0 -283.80368413697346 0.16462952092142416 tensor(174.5620)\n",
      "-283.4678925330241 0.0 -283.4678925330241 0.07842751224422143 tensor(184.3947)\n",
      "-284.38566764365055 0.0 -284.38566764365055 0.04207836936256376 tensor(163.8079)\n",
      "-283.93555377382404 0.0 -283.93555377382404 0.052604668483319586 tensor(162.9276)\n",
      "-284.2664333580195 0.0 -284.2664333580195 0.08269842725797823 tensor(162.5307)\n",
      "-283.69774876908303 0.0 -283.69774876908303 0.017363853546943375 tensor(167.1454)\n",
      "-284.1901630781614 0.0 -284.1901630781614 0.030615924767735152 tensor(178.9905)\n",
      "-284.55804562929296 0.0 -284.55804562929296 0.12167276001003884 tensor(168.2535)\n",
      "-284.0306865174196 0.0 -284.0306865174196 0.042975307592059704 tensor(161.3664)\n",
      "-284.5294831701677 0.0 -284.5294831701677 0.04225331006726426 tensor(171.7617)\n",
      "-284.48133368928643 0.0 -284.48133368928643 0.12286111429813919 tensor(155.1719)\n",
      "-284.379209917746 0.0 -284.379209917746 0.08812165088801732 tensor(156.3804)\n",
      "-284.25456791622906 0.0 -284.25456791622906 0.11261597500795019 tensor(158.9209)\n",
      "-283.8833505045755 0.0 -283.8833505045755 0.05391973780140656 tensor(158.8158)\n",
      "-283.8821642426285 0.0 -283.8821642426285 0.06648566741675421 tensor(175.7047)\n",
      "-284.23590216501105 0.0 -284.23590216501105 0.06870746808040104 tensor(184.8741)\n",
      "-284.35495370003207 0.0 -284.35495370003207 0.10791041124252573 tensor(175.7066)\n",
      "-284.4353983257754 0.0 -284.4353983257754 0.06458345643161138 tensor(161.0063)\n",
      "-284.68327984098545 0.0 -284.68327984098545 0.10701042809858179 tensor(185.5954)\n",
      "-285.17907385083424 0.0 -285.17907385083424 0.15025555196629853 tensor(183.6048)\n",
      "-284.33315999233 0.0 -284.33315999233 0.04564478951006903 tensor(175.1316)\n",
      "-283.9217576487407 0.0 -283.9217576487407 0.1028619866198336 tensor(181.4775)\n",
      "-284.0511438526345 0.0 -284.0511438526345 0.06777241827415263 tensor(164.4810)\n",
      "-284.0037763735015 0.0 -284.0037763735015 0.05546382115991647 tensor(175.1865)\n",
      "== Era 2 | Epoch 0 metrics ==\n",
      "\tloss -283.352\n",
      "\tforce 0\n",
      "\tdkl -283.352\n",
      "\tlogp 77.9836\n",
      "\tlogq -205.368\n",
      "\tess 0.06757\n",
      "-283.8183165342452 0.0 -283.8183165342452 0.08550796483871059 tensor(185.1210)\n",
      "-284.0845064738834 0.0 -284.0845064738834 0.035594370191097804 tensor(162.8812)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-284.8429597529703 0.0 -284.8429597529703 0.1212049823963425 tensor(188.5751)\n",
      "-284.9351600879518 0.0 -284.9351600879518 0.04529845050025381 tensor(160.4054)\n",
      "-284.92479100690605 0.0 -284.92479100690605 0.10299279725705703 tensor(162.8252)\n",
      "-284.7006045154459 0.0 -284.7006045154459 0.0634903546981934 tensor(184.7761)\n",
      "-284.23417909309563 0.0 -284.23417909309563 0.06553069828929119 tensor(183.3095)\n",
      "-284.91079694828477 0.0 -284.91079694828477 0.1650090862175595 tensor(159.2117)\n",
      "-284.86244739779977 0.0 -284.86244739779977 0.07048635421890902 tensor(166.3495)\n",
      "-284.7051552926587 0.0 -284.7051552926587 0.05878212832837798 tensor(177.9648)\n",
      "-284.898315807862 0.0 -284.898315807862 0.09834594584974636 tensor(171.2399)\n",
      "-284.14618266483353 0.0 -284.14618266483353 0.06698763027745851 tensor(169.6701)\n",
      "-284.46044108063006 0.0 -284.46044108063006 0.16226879887856469 tensor(175.0261)\n",
      "-284.91939853223977 0.0 -284.91939853223977 0.06593788277972827 tensor(176.2942)\n",
      "-285.2429056183637 0.0 -285.2429056183637 0.09483144848361717 tensor(150.5288)\n",
      "-284.3797550449105 0.0 -284.3797550449105 0.08798214794078625 tensor(174.6016)\n",
      "-284.7374460296326 0.0 -284.7374460296326 0.061584360749441056 tensor(170.8500)\n",
      "-284.9990581342805 0.0 -284.9990581342805 0.020381544382407406 tensor(167.7000)\n",
      "-283.9556752244105 0.0 -283.9556752244105 0.20764106171112456 tensor(159.6041)\n",
      "-284.5045296167758 0.0 -284.5045296167758 0.12436120782862965 tensor(178.6969)\n",
      "-285.09625540825834 0.0 -285.09625540825834 0.03362413414129561 tensor(167.9578)\n",
      "-285.205299471118 0.0 -285.205299471118 0.1732128400628471 tensor(172.8116)\n",
      "-284.9243906153147 0.0 -284.9243906153147 0.10048238728376216 tensor(177.3898)\n",
      "-284.9495607744333 0.0 -284.9495607744333 0.0870245614748804 tensor(158.8126)\n",
      "-285.2665960225143 0.0 -285.2665960225143 0.12103597419312816 tensor(152.8699)\n",
      "-284.995503319764 0.0 -284.995503319764 0.12636495306844114 tensor(168.9785)\n",
      "-284.6669423970186 0.0 -284.6669423970186 0.10664989779317581 tensor(162.2056)\n",
      "-285.61600765981484 0.0 -285.61600765981484 0.12032230951817174 tensor(142.7315)\n",
      "-285.00946582584083 0.0 -285.00946582584083 0.10602224051953646 tensor(161.0350)\n",
      "-285.22737183396 0.0 -285.22737183396 0.1729974320656123 tensor(158.0107)\n",
      "-285.60102112159603 0.0 -285.60102112159603 0.12294012663334117 tensor(170.4435)\n",
      "-285.1601186949557 0.0 -285.1601186949557 0.08514847782614321 tensor(158.1214)\n",
      "-285.2601611349149 0.0 -285.2601611349149 0.09209528240221285 tensor(168.6522)\n",
      "-285.0365827906783 0.0 -285.0365827906783 0.05696663716836785 tensor(147.3888)\n",
      "-285.5607546649052 0.0 -285.5607546649052 0.14824627682587002 tensor(171.6546)\n",
      "-285.62363799361106 0.0 -285.62363799361106 0.12546555838014503 tensor(159.5576)\n",
      "-284.7777851644006 0.0 -284.7777851644006 0.11355701243530603 tensor(168.4727)\n",
      "-284.72146962167903 0.0 -284.72146962167903 0.1620607856144148 tensor(185.5985)\n",
      "-285.04080164595507 0.0 -285.04080164595507 0.1062933422578384 tensor(160.4979)\n",
      "-285.78262269291594 0.0 -285.78262269291594 0.14642367978836637 tensor(168.6562)\n",
      "-284.7716844348804 0.0 -284.7716844348804 0.10226282736542976 tensor(182.1831)\n",
      "-285.5845507036581 0.0 -285.5845507036581 0.11692889946510461 tensor(162.4812)\n",
      "-285.80455402975764 0.0 -285.80455402975764 0.2002491136553498 tensor(160.2561)\n",
      "-285.3573617596469 0.0 -285.3573617596469 0.05590334429466253 tensor(170.2584)\n",
      "-285.03441266765583 0.0 -285.03441266765583 0.10781398021532843 tensor(173.7003)\n",
      "-284.93389422310884 0.0 -284.93389422310884 0.1674751915622051 tensor(165.8991)\n",
      "-284.76965251706804 0.0 -284.76965251706804 0.13578296177880125 tensor(177.4759)\n",
      "-284.3133832033657 0.0 -284.3133832033657 0.16900448431234202 tensor(158.6171)\n",
      "-285.06078749774247 0.0 -285.06078749774247 0.17473828428045923 tensor(153.4380)\n",
      "-285.36300471560577 0.0 -285.36300471560577 0.21679493213788417 tensor(154.5089)\n",
      "-285.26929257213595 0.0 -285.26929257213595 0.11132238232162497 tensor(164.7523)\n",
      "-285.38326352695765 0.0 -285.38326352695765 0.12197866534449968 tensor(169.3595)\n",
      "-285.2212607033061 0.0 -285.2212607033061 0.2374422037471877 tensor(192.2061)\n",
      "-285.05626856830725 0.0 -285.05626856830725 0.03406112115061624 tensor(170.6466)\n",
      "-285.5132761965501 0.0 -285.5132761965501 0.062077905645537446 tensor(171.5786)\n",
      "-285.446890376355 0.0 -285.446890376355 0.03811709861580891 tensor(155.9304)\n",
      "-285.1968544182479 0.0 -285.1968544182479 0.2651208371147237 tensor(176.1905)\n",
      "-285.22230226114937 0.0 -285.22230226114937 0.0794794423386947 tensor(159.0332)\n",
      "-285.3645550623239 0.0 -285.3645550623239 0.03686850945516012 tensor(162.2936)\n",
      "-284.53820748582325 0.0 -284.53820748582325 0.1500727155564795 tensor(154.9844)\n",
      "-284.953733927188 0.0 -284.953733927188 0.061760870374122985 tensor(181.6507)\n",
      "-285.4635006521636 0.0 -285.4635006521636 0.06766142331067415 tensor(154.8483)\n",
      "-285.24260149653895 0.0 -285.24260149653895 0.05556518704437167 tensor(159.9532)\n",
      "-285.19313164247353 0.0 -285.19313164247353 0.14428837341039866 tensor(156.0767)\n",
      "-285.35975586423797 0.0 -285.35975586423797 0.13093438810291877 tensor(145.8284)\n",
      "-285.43654778073744 0.0 -285.43654778073744 0.12136455239169411 tensor(173.2184)\n",
      "-285.2258329553399 0.0 -285.2258329553399 0.05582965115752843 tensor(156.5488)\n",
      "-284.4968866244838 0.0 -284.4968866244838 0.10000862813509948 tensor(159.7116)\n",
      "-284.8352974626467 0.0 -284.8352974626467 0.05226831558050989 tensor(166.7049)\n",
      "-285.1537552953289 0.0 -285.1537552953289 0.09568618862715986 tensor(164.3301)\n",
      "-285.1961730739639 0.0 -285.1961730739639 0.15508859665485814 tensor(157.0258)\n",
      "-285.01564576911284 0.0 -285.01564576911284 0.03265113940689128 tensor(165.7581)\n",
      "-285.3936331005888 0.0 -285.3936331005888 0.028801710855086756 tensor(182.1191)\n",
      "-285.0119031708939 0.0 -285.0119031708939 0.06947951283600515 tensor(151.5380)\n",
      "-284.7892089148493 0.0 -284.7892089148493 0.18009535848093786 tensor(162.3971)\n",
      "-285.5835970651766 0.0 -285.5835970651766 0.04738323891654165 tensor(173.5435)\n",
      "-285.3375329240015 0.0 -285.3375329240015 0.12766321220420634 tensor(167.9516)\n",
      "-285.6419534984374 0.0 -285.6419534984374 0.13230036335735085 tensor(162.3136)\n",
      "-285.07782035066293 0.0 -285.07782035066293 0.07305637517513731 tensor(139.1589)\n",
      "-285.175230090806 0.0 -285.175230090806 0.1479177514005833 tensor(160.4749)\n",
      "-285.1107942526029 0.0 -285.1107942526029 0.1391296025148274 tensor(154.9077)\n",
      "-285.867989066529 0.0 -285.867989066529 0.1508320041443299 tensor(153.1793)\n",
      "-285.6857676965263 0.0 -285.6857676965263 0.060906762196792655 tensor(145.1331)\n",
      "-285.42094472345156 0.0 -285.42094472345156 0.17197262820631673 tensor(157.2244)\n",
      "-285.78401699313105 0.0 -285.78401699313105 0.24036736249509333 tensor(181.4816)\n",
      "-285.66295511518246 0.0 -285.66295511518246 0.10462101684086991 tensor(146.4757)\n",
      "-284.7700159252413 0.0 -284.7700159252413 0.13730987016274715 tensor(175.4094)\n",
      "-285.1781718282328 0.0 -285.1781718282328 0.19844363245801902 tensor(167.6308)\n",
      "-285.4614795017307 0.0 -285.4614795017307 0.030816583822477282 tensor(162.7926)\n",
      "-285.3904793984162 0.0 -285.3904793984162 0.1523352511602802 tensor(149.9114)\n",
      "-285.5253949235829 0.0 -285.5253949235829 0.2594111010588672 tensor(167.1751)\n",
      "-284.6596173665461 0.0 -284.6596173665461 0.07928647233434917 tensor(175.9412)\n",
      "-285.66889888362266 0.0 -285.66889888362266 0.10668605159765267 tensor(174.9553)\n",
      "-285.05808722798486 0.0 -285.05808722798486 0.06855100851327375 tensor(151.3595)\n",
      "-285.62310326199815 0.0 -285.62310326199815 0.05701819218331873 tensor(149.2559)\n",
      "-285.1831024478256 0.0 -285.1831024478256 0.0362293512344247 tensor(162.1726)\n",
      "-285.39643692678897 0.0 -285.39643692678897 0.13653406048652872 tensor(153.2261)\n",
      "-285.4967604446871 0.0 -285.4967604446871 0.16988103590350492 tensor(157.4488)\n",
      "-285.49030202197775 0.0 -285.49030202197775 0.17411185605328638 tensor(171.9079)\n",
      "-284.99097863477516 0.0 -284.99097863477516 0.1135350599981525 tensor(167.6669)\n",
      "== Era 3 | Epoch 0 metrics ==\n",
      "\tloss -285.1\n",
      "\tforce 0\n",
      "\tdkl -285.1\n",
      "\tlogp 82.214\n",
      "\tlogq -202.886\n",
      "\tess 0.111624\n",
      "-285.15904055308624 0.0 -285.15904055308624 0.05143829328675751 tensor(157.3436)\n",
      "-285.34080053003413 0.0 -285.34080053003413 0.04071071029141803 tensor(169.1474)\n",
      "-285.24055964769184 0.0 -285.24055964769184 0.11335424056902454 tensor(168.1496)\n",
      "-285.2282026393352 0.0 -285.2282026393352 0.05859126117723238 tensor(170.9444)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-284.9924276153818 0.0 -284.9924276153818 0.0682682104973811 tensor(160.3706)\n",
      "-285.47598577640906 0.0 -285.47598577640906 0.1306804690480359 tensor(164.7346)\n",
      "-285.774458633553 0.0 -285.774458633553 0.21663605512261588 tensor(181.0084)\n",
      "-285.30548104891386 0.0 -285.30548104891386 0.16002888497508885 tensor(155.8888)\n",
      "-285.36912382809015 0.0 -285.36912382809015 0.14315807526410207 tensor(150.5734)\n",
      "-284.9779429399015 0.0 -284.9779429399015 0.0994562994601455 tensor(170.0647)\n",
      "-285.701175592648 0.0 -285.701175592648 0.23117299012903894 tensor(173.1442)\n",
      "-284.8885695860637 0.0 -284.8885695860637 0.021625846217532194 tensor(162.5646)\n",
      "-285.3294141783652 0.0 -285.3294141783652 0.02891149803817181 tensor(154.7157)\n",
      "-285.58379607904914 0.0 -285.58379607904914 0.1065485742056109 tensor(175.4341)\n",
      "-284.86548068856814 0.0 -284.86548068856814 0.1513955935533572 tensor(159.7446)\n",
      "-285.3089959551804 0.0 -285.3089959551804 0.16908856438189449 tensor(151.7761)\n",
      "-285.1538291026305 0.0 -285.1538291026305 0.08568308498234842 tensor(149.5513)\n",
      "-285.27715912435474 0.0 -285.27715912435474 0.15475209634186082 tensor(171.7352)\n",
      "-285.21329228141974 0.0 -285.21329228141974 0.05396377842030514 tensor(152.1005)\n",
      "-285.5836381301209 0.0 -285.5836381301209 0.14740831982289365 tensor(166.8838)\n",
      "-285.1326851240139 0.0 -285.1326851240139 0.05652206627980775 tensor(176.7112)\n",
      "-285.3805068419881 0.0 -285.3805068419881 0.11842845260513239 tensor(162.1057)\n",
      "-285.88800393404506 0.0 -285.88800393404506 0.11360309058338179 tensor(163.9895)\n",
      "-285.68312666261636 0.0 -285.68312666261636 0.0408816966160682 tensor(146.1423)\n",
      "-285.64692792375865 0.0 -285.64692792375865 0.22011123932102988 tensor(159.4679)\n",
      "-285.70897807107644 0.0 -285.70897807107644 0.037173915925712925 tensor(161.4329)\n",
      "-286.02822537040265 0.0 -286.02822537040265 0.08431700018204165 tensor(156.9956)\n",
      "-285.6362065849818 0.0 -285.6362065849818 0.055185643598048874 tensor(162.8300)\n",
      "-285.2880858972024 0.0 -285.2880858972024 0.12346506584126478 tensor(168.5754)\n",
      "-285.2582744634553 0.0 -285.2582744634553 0.1420475382167344 tensor(160.7532)\n",
      "-285.3652659666214 0.0 -285.3652659666214 0.07788325186856537 tensor(177.2893)\n",
      "-285.1155084385894 0.0 -285.1155084385894 0.022238540177124025 tensor(184.1336)\n",
      "-284.61267090615166 0.0 -284.61267090615166 0.030495426694190926 tensor(172.3783)\n",
      "-285.0554367571059 0.0 -285.0554367571059 0.13081141699765303 tensor(187.3347)\n",
      "-285.1718624663433 0.0 -285.1718624663433 0.05741044861819794 tensor(154.4777)\n",
      "-285.45959201482935 0.0 -285.45959201482935 0.07477288226163574 tensor(181.9690)\n",
      "-285.4816658109778 0.0 -285.4816658109778 0.09876616352831581 tensor(164.8542)\n",
      "-285.035092790935 0.0 -285.035092790935 0.1459029082014395 tensor(180.0146)\n",
      "-285.3543689582776 0.0 -285.3543689582776 0.29183570939206627 tensor(184.8629)\n",
      "-284.8082682704886 0.0 -284.8082682704886 0.0884746550476599 tensor(175.4926)\n",
      "-286.11648715651245 0.0 -286.11648715651245 0.04444597153204568 tensor(165.4201)\n",
      "-285.56232205646074 0.0 -285.56232205646074 0.022837595360512202 tensor(177.2804)\n",
      "-285.09943058221586 0.0 -285.09943058221586 0.06345369305886316 tensor(178.7311)\n",
      "-285.19752111571574 0.0 -285.19752111571574 0.13601421519896023 tensor(158.0170)\n",
      "-285.3442747155426 0.0 -285.3442747155426 0.08757423628123508 tensor(167.9874)\n",
      "-285.7034942798958 0.0 -285.7034942798958 0.16958156885845072 tensor(176.3514)\n",
      "-285.7861115315609 0.0 -285.7861115315609 0.07216953081836126 tensor(160.0303)\n",
      "-285.52526838435796 0.0 -285.52526838435796 0.1086910084014319 tensor(159.7248)\n",
      "-285.6155792389335 0.0 -285.6155792389335 0.09277630526936234 tensor(156.7205)\n",
      "-285.5804188717133 0.0 -285.5804188717133 0.0797890229491694 tensor(163.4685)\n",
      "-285.6027121159416 0.0 -285.6027121159416 0.15790830422347524 tensor(188.3360)\n",
      "-285.4889257538149 0.0 -285.4889257538149 0.1272713159051605 tensor(167.2743)\n",
      "-285.2923423554786 0.0 -285.2923423554786 0.0819395890845722 tensor(167.5445)\n",
      "-285.80827199170517 0.0 -285.80827199170517 0.0671449232759008 tensor(180.1960)\n",
      "-285.8635437285133 0.0 -285.8635437285133 0.08316303944269829 tensor(147.3175)\n",
      "-285.3651626843981 0.0 -285.3651626843981 0.131126485379501 tensor(167.9416)\n",
      "-285.7630050521687 0.0 -285.7630050521687 0.0276090194457956 tensor(172.4885)\n",
      "-285.2303407714951 0.0 -285.2303407714951 0.18537279067209292 tensor(170.4919)\n",
      "-285.03102001874197 0.0 -285.03102001874197 0.09057083348979288 tensor(173.3224)\n",
      "-285.35966810449185 0.0 -285.35966810449185 0.1879037795076511 tensor(164.6944)\n",
      "-285.6909553405244 0.0 -285.6909553405244 0.1970358092759829 tensor(155.9840)\n",
      "-285.03937296629476 0.0 -285.03937296629476 0.04642953568968971 tensor(163.2519)\n",
      "-285.083447447936 0.0 -285.083447447936 0.06807718814302235 tensor(163.0399)\n",
      "-285.7346107610659 0.0 -285.7346107610659 0.1193513948622244 tensor(175.8399)\n",
      "-285.4774925910997 0.0 -285.4774925910997 0.09993134975783477 tensor(179.1905)\n",
      "-285.2457929199752 0.0 -285.2457929199752 0.09963997778823361 tensor(159.2324)\n",
      "-286.31480457218686 0.0 -286.31480457218686 0.079740593801366 tensor(146.1083)\n",
      "-285.8077242566086 0.0 -285.8077242566086 0.22463446707706128 tensor(157.5985)\n",
      "-285.7415075670735 0.0 -285.7415075670735 0.18735595712643366 tensor(166.4932)\n",
      "-285.04915413545973 0.0 -285.04915413545973 0.14572159095819778 tensor(170.0176)\n",
      "-285.3541620653989 0.0 -285.3541620653989 0.12020291496303892 tensor(151.3753)\n",
      "-285.203543768244 0.0 -285.203543768244 0.16255432014770643 tensor(158.5080)\n",
      "-285.3382975887639 0.0 -285.3382975887639 0.07760794038009126 tensor(178.7800)\n",
      "-285.81052489683964 0.0 -285.81052489683964 0.10790381193278285 tensor(164.5508)\n",
      "-285.7150682968843 0.0 -285.7150682968843 0.09648039117915078 tensor(158.3313)\n",
      "-285.4339367480991 0.0 -285.4339367480991 0.06882114194940388 tensor(172.4849)\n",
      "-285.10086785326195 0.0 -285.10086785326195 0.06525712224927979 tensor(175.4496)\n",
      "-285.2131919188088 0.0 -285.2131919188088 0.10811001754009643 tensor(173.1040)\n",
      "-285.5983230487276 0.0 -285.5983230487276 0.08933797554684098 tensor(171.4164)\n",
      "-285.2388290814688 0.0 -285.2388290814688 0.03762250672316672 tensor(151.4649)\n",
      "-285.9830341796005 0.0 -285.9830341796005 0.16645481743267246 tensor(164.2727)\n",
      "-285.0070938343046 0.0 -285.0070938343046 0.17102804313268585 tensor(159.7853)\n",
      "-285.27463263070774 0.0 -285.27463263070774 0.060286358693450996 tensor(171.1143)\n",
      "-284.46324081412877 0.0 -284.46324081412877 0.1263048854256564 tensor(170.3686)\n",
      "-285.3495222988977 0.0 -285.3495222988977 0.29808296126781303 tensor(155.3522)\n",
      "-285.7305427788441 0.0 -285.7305427788441 0.18744587848070782 tensor(163.6797)\n",
      "-285.65947270447975 0.0 -285.65947270447975 0.1576972140235944 tensor(155.6211)\n",
      "-286.028554711586 0.0 -286.028554711586 0.05109091781878805 tensor(160.2377)\n",
      "-285.17389644720225 0.0 -285.17389644720225 0.15090238174684809 tensor(135.9988)\n",
      "-285.89363528675256 0.0 -285.89363528675256 0.1647167173227034 tensor(150.6435)\n",
      "-285.48625331455287 0.0 -285.48625331455287 0.31529749270875207 tensor(172.0903)\n",
      "-284.98587430312716 0.0 -284.98587430312716 0.18899731020131888 tensor(167.9893)\n",
      "-285.35802207487535 0.0 -285.35802207487535 0.1277730912692437 tensor(176.9074)\n",
      "-285.92861693763865 0.0 -285.92861693763865 0.08507374110097186 tensor(168.8116)\n",
      "-285.52855598296367 0.0 -285.52855598296367 0.09429256899074667 tensor(167.5673)\n",
      "-286.1535598880031 0.0 -286.1535598880031 0.06420379110913461 tensor(182.6417)\n",
      "-285.3775649650079 0.0 -285.3775649650079 0.1507159015277831 tensor(170.8339)\n",
      "-285.2665526094239 0.0 -285.2665526094239 0.15746487774496573 tensor(169.6828)\n",
      "-285.6547899541396 0.0 -285.6547899541396 0.17023384884041562 tensor(179.5749)\n",
      "-285.6495392972774 0.0 -285.6495392972774 0.0924352806835497 tensor(171.8607)\n",
      "== Era 4 | Epoch 0 metrics ==\n",
      "\tloss -285.424\n",
      "\tforce 0\n",
      "\tdkl -285.424\n",
      "\tlogp 83.0325\n",
      "\tlogq -202.391\n",
      "\tess 0.114429\n",
      "-285.2832465342263 0.0 -285.2832465342263 0.17355649785339752 tensor(173.7748)\n",
      "-285.486685186094 0.0 -285.486685186094 0.14498867519130776 tensor(166.2574)\n",
      "-285.7609505987645 0.0 -285.7609505987645 0.10136686004789452 tensor(166.7881)\n",
      "-285.4193284954114 0.0 -285.4193284954114 0.04554612747971669 tensor(181.3098)\n",
      "-285.79999984615677 0.0 -285.79999984615677 0.16731116218244382 tensor(183.6537)\n",
      "-286.12418654344344 0.0 -286.12418654344344 0.05612124401507414 tensor(172.2896)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-284.88405082152804 0.0 -284.88405082152804 0.0440837282273959 tensor(179.2421)\n",
      "-285.7150312671116 0.0 -285.7150312671116 0.16567702480950963 tensor(159.0576)\n",
      "-285.03933336994277 0.0 -285.03933336994277 0.14370817615085807 tensor(171.1891)\n",
      "-285.8721464961258 0.0 -285.8721464961258 0.11958246018082601 tensor(168.3437)\n",
      "-285.8337436501543 0.0 -285.8337436501543 0.05933580034129706 tensor(147.9022)\n",
      "-285.56063784161165 0.0 -285.56063784161165 0.05754454112307764 tensor(170.3893)\n",
      "-285.91978820175734 0.0 -285.91978820175734 0.0691287882063723 tensor(161.4032)\n",
      "-285.51218808909346 0.0 -285.51218808909346 0.1042647469233061 tensor(169.6048)\n",
      "-286.0137515907934 0.0 -286.0137515907934 0.16950230707171174 tensor(170.5170)\n",
      "-285.6325431759516 0.0 -285.6325431759516 0.12297660716010761 tensor(171.7185)\n",
      "-286.22892481212875 0.0 -286.22892481212875 0.035725046026131003 tensor(159.0035)\n",
      "-285.403712218378 0.0 -285.403712218378 0.07808400725196686 tensor(160.8714)\n",
      "-285.44471471219066 0.0 -285.44471471219066 0.037198595444272224 tensor(142.9722)\n",
      "-285.8068214619793 0.0 -285.8068214619793 0.18281795019223054 tensor(182.2531)\n",
      "-285.79966864134974 0.0 -285.79966864134974 0.04089277219058984 tensor(168.8438)\n",
      "-285.6572853702153 0.0 -285.6572853702153 0.019061684097692155 tensor(166.9466)\n",
      "-286.0823405095015 0.0 -286.0823405095015 0.3102599055397559 tensor(159.1439)\n",
      "-285.6072876793552 0.0 -285.6072876793552 0.03243083698810078 tensor(164.6754)\n",
      "-285.7560398154518 0.0 -285.7560398154518 0.11272230902725056 tensor(156.1447)\n",
      "-285.7808099357536 0.0 -285.7808099357536 0.1152700878001921 tensor(154.8430)\n",
      "-285.49735976255295 0.0 -285.49735976255295 0.17187208654092045 tensor(156.5299)\n",
      "-286.2973035109436 0.0 -286.2973035109436 0.3073142459145494 tensor(151.7078)\n",
      "-286.12699919909045 0.0 -286.12699919909045 0.07812230640006707 tensor(150.4567)\n",
      "-285.9147898507962 0.0 -285.9147898507962 0.2819471320880121 tensor(159.6689)\n",
      "-285.987763093297 0.0 -285.987763093297 0.16335515004541842 tensor(169.0296)\n",
      "-286.1571339141358 0.0 -286.1571339141358 0.21719176283828381 tensor(177.3343)\n",
      "-286.14770249120375 0.0 -286.14770249120375 0.12436607049401324 tensor(179.3400)\n",
      "-285.50767360435566 0.0 -285.50767360435566 0.21222475543924826 tensor(160.9356)\n",
      "-285.9653049558712 0.0 -285.9653049558712 0.1599509397983044 tensor(166.5193)\n",
      "-285.85154145848605 0.0 -285.85154145848605 0.27650071570699863 tensor(158.4823)\n",
      "-285.6653660926542 0.0 -285.6653660926542 0.13377866408396494 tensor(163.2563)\n",
      "-285.5478927731907 0.0 -285.5478927731907 0.09617969023095536 tensor(168.4820)\n",
      "-285.4326044575289 0.0 -285.4326044575289 0.18195077374159388 tensor(164.2471)\n",
      "-285.7069193466032 0.0 -285.7069193466032 0.2965230646417421 tensor(177.2032)\n",
      "-285.7679320044508 0.0 -285.7679320044508 0.10994496864746618 tensor(163.3185)\n",
      "-285.8072431640843 0.0 -285.8072431640843 0.030098615381384534 tensor(165.0963)\n",
      "-286.23547740360175 0.0 -286.23547740360175 0.1619576617719826 tensor(171.1438)\n",
      "-285.6077334387405 0.0 -285.6077334387405 0.07319959680043298 tensor(153.6282)\n",
      "-285.5746036783718 0.0 -285.5746036783718 0.07206535274422399 tensor(182.9180)\n",
      "-286.1258441938186 0.0 -286.1258441938186 0.10332737865033563 tensor(165.9586)\n",
      "-286.0205910281122 0.0 -286.0205910281122 0.0380424322044389 tensor(183.6978)\n",
      "-285.74239197661154 0.0 -285.74239197661154 0.1978558245524527 tensor(172.9482)\n",
      "-286.0407415246531 0.0 -286.0407415246531 0.08370059002103869 tensor(173.0849)\n",
      "-285.7972321686511 0.0 -285.7972321686511 0.21753068625162875 tensor(171.3465)\n",
      "-286.17938982854577 0.0 -286.17938982854577 0.1254838900303427 tensor(170.0476)\n",
      "-285.5792768065012 0.0 -285.5792768065012 0.080586365466519 tensor(180.4705)\n",
      "-286.23324273736836 0.0 -286.23324273736836 0.02371633608385966 tensor(172.3485)\n",
      "-286.2409839675674 0.0 -286.2409839675674 0.0875489562320823 tensor(153.8813)\n",
      "-285.7385270815229 0.0 -285.7385270815229 0.22099836721745025 tensor(154.8424)\n",
      "-286.2239429796569 0.0 -286.2239429796569 0.1213434163074803 tensor(156.2519)\n",
      "-285.952632345374 0.0 -285.952632345374 0.1229884907868036 tensor(148.8329)\n",
      "-285.898384983049 0.0 -285.898384983049 0.10986585542636783 tensor(158.5296)\n",
      "-285.8666446670642 0.0 -285.8666446670642 0.05627607902712766 tensor(154.9408)\n",
      "-285.7965144182372 0.0 -285.7965144182372 0.113086367897646 tensor(143.7939)\n",
      "-285.98269395637953 0.0 -285.98269395637953 0.05881562125793563 tensor(153.8868)\n",
      "-285.6787457198297 0.0 -285.6787457198297 0.0753359780118171 tensor(176.3909)\n",
      "-285.95694064728457 0.0 -285.95694064728457 0.16140654500589535 tensor(173.3511)\n",
      "-286.28957867109386 0.0 -286.28957867109386 0.09885439382511901 tensor(166.5422)\n",
      "-286.173704630732 0.0 -286.173704630732 0.11012084193267327 tensor(165.3539)\n",
      "-285.55471375708896 0.0 -285.55471375708896 0.11440619108058181 tensor(172.6874)\n",
      "-285.72301901384964 0.0 -285.72301901384964 0.12787114594726454 tensor(172.1622)\n",
      "-285.6108757709493 0.0 -285.6108757709493 0.1628978758194632 tensor(170.9949)\n",
      "-285.8529451740568 0.0 -285.8529451740568 0.2567879737988472 tensor(188.1487)\n",
      "-285.7923676749139 0.0 -285.7923676749139 0.19857514130604878 tensor(191.0186)\n",
      "-285.46935742190135 0.0 -285.46935742190135 0.12513627423613718 tensor(171.2527)\n",
      "-285.85918994880365 0.0 -285.85918994880365 0.13842906069622882 tensor(167.8815)\n",
      "-286.24989776627814 0.0 -286.24989776627814 0.2550002755322943 tensor(157.0803)\n",
      "-286.3662758166919 0.0 -286.3662758166919 0.23661828532858528 tensor(158.5803)\n",
      "-286.23659971505174 0.0 -286.23659971505174 0.10205810717213533 tensor(148.0915)\n",
      "-285.7662106048665 0.0 -285.7662106048665 0.17116713745500928 tensor(168.3996)\n",
      "-285.62340126660547 0.0 -285.62340126660547 0.10893069674617596 tensor(160.0604)\n",
      "-286.13053864717006 0.0 -286.13053864717006 0.16126653326144186 tensor(150.4510)\n",
      "-286.55505791362054 0.0 -286.55505791362054 0.1426613137662324 tensor(164.2890)\n",
      "-285.864483647766 0.0 -285.864483647766 0.14808019704151815 tensor(188.7827)\n",
      "-285.9039128789756 0.0 -285.9039128789756 0.12215012468695419 tensor(153.0669)\n",
      "-286.39027258068904 0.0 -286.39027258068904 0.1733429952722795 tensor(144.3357)\n",
      "-285.34954624766715 0.0 -285.34954624766715 0.14204343075735013 tensor(157.6116)\n",
      "-286.1069980975493 0.0 -286.1069980975493 0.2435503405054145 tensor(175.6339)\n",
      "-286.07564703759635 0.0 -286.07564703759635 0.12329049712773019 tensor(191.2052)\n",
      "-286.0376191536199 0.0 -286.0376191536199 0.14441687346574533 tensor(162.7472)\n",
      "-286.0584231585421 0.0 -286.0584231585421 0.07477711597209132 tensor(165.1484)\n",
      "-285.58987178727386 0.0 -285.58987178727386 0.08068862712423702 tensor(178.1801)\n",
      "-285.6739758977627 0.0 -285.6739758977627 0.15835787749535607 tensor(177.4626)\n",
      "-286.1585876967681 0.0 -286.1585876967681 0.07203982895362511 tensor(165.9619)\n",
      "-285.9271291006064 0.0 -285.9271291006064 0.0869593171930747 tensor(171.5512)\n",
      "-285.39553788920125 0.0 -285.39553788920125 0.1437440603859971 tensor(177.2244)\n",
      "-285.61181226282775 0.0 -285.61181226282775 0.10700573777583058 tensor(199.4288)\n",
      "-285.90108309275104 0.0 -285.90108309275104 0.1945737791226345 tensor(186.9549)\n",
      "-286.01249591549634 0.0 -286.01249591549634 0.33740901631414016 tensor(221.1408)\n",
      "-286.4111093628675 0.0 -286.4111093628675 0.027496827771754495 tensor(163.1835)\n",
      "-285.9499197803397 0.0 -285.9499197803397 0.09362465969283924 tensor(208.7860)\n",
      "-285.98622364890923 0.0 -285.98622364890923 0.07903199549359721 tensor(189.3511)\n",
      "-285.79193459172063 0.0 -285.79193459172063 0.2080847721521145 tensor(195.5116)\n",
      "-286.44410868640983 0.0 -286.44410868640983 0.16072905404245025 tensor(200.3943)\n",
      "== Era 5 | Epoch 0 metrics ==\n",
      "\tloss -285.852\n",
      "\tforce 0\n",
      "\tdkl -285.852\n",
      "\tlogp 83.8965\n",
      "\tlogq -201.955\n",
      "\tess 0.132878\n",
      "-285.9269730756672 0.0 -285.9269730756672 0.07743474254448013 tensor(187.7026)\n",
      "-286.073536889033 0.0 -286.073536889033 0.07276721728396088 tensor(201.0817)\n",
      "-285.7230561040171 0.0 -285.7230561040171 0.09105855932955097 tensor(160.2491)\n",
      "-286.07869636076873 0.0 -286.07869636076873 0.260493853233392 tensor(159.9324)\n",
      "-286.0819678521914 0.0 -286.0819678521914 0.047204058042472866 tensor(173.9738)\n",
      "-285.8282131732831 0.0 -285.8282131732831 0.20674506031055717 tensor(169.2118)\n",
      "-286.14051410111256 0.0 -286.14051410111256 0.18933616609229303 tensor(191.1329)\n",
      "-285.82606012325095 0.0 -285.82606012325095 0.09014268640759197 tensor(155.3889)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.47472173797644 0.0 -286.47472173797644 0.09182258305495207 tensor(149.4296)\n",
      "-285.9607796128446 0.0 -285.9607796128446 0.18862357261061502 tensor(156.8301)\n",
      "-285.6111727568119 0.0 -285.6111727568119 0.14114451681140844 tensor(205.5014)\n",
      "-286.40606666537434 0.0 -286.40606666537434 0.23250984215594372 tensor(180.4642)\n",
      "-286.3391684910078 0.0 -286.3391684910078 0.027495911775428542 tensor(172.7053)\n",
      "-286.0323313692354 0.0 -286.0323313692354 0.05365137375771418 tensor(179.8557)\n",
      "-286.16294886419064 0.0 -286.16294886419064 0.19698324732441733 tensor(208.0853)\n",
      "-285.56547420220267 0.0 -285.56547420220267 0.2738823271308236 tensor(201.6251)\n",
      "-286.0119648392606 0.0 -286.0119648392606 0.13935801292991742 tensor(170.5158)\n",
      "-286.0334230540245 0.0 -286.0334230540245 0.17305758299458665 tensor(186.8160)\n",
      "-285.78114986768156 0.0 -285.78114986768156 0.22943843882789655 tensor(175.7230)\n",
      "-285.87816378429034 0.0 -285.87816378429034 0.18345726597562845 tensor(178.9020)\n",
      "-285.9998484833079 0.0 -285.9998484833079 0.07350468874126145 tensor(200.0263)\n",
      "-286.2970959876147 0.0 -286.2970959876147 0.1716409740261517 tensor(168.1735)\n",
      "-286.4188510743087 0.0 -286.4188510743087 0.0455699180545495 tensor(156.9470)\n",
      "-285.88496545778094 0.0 -285.88496545778094 0.17547052697313642 tensor(226.3874)\n",
      "-285.8973676691694 0.0 -285.8973676691694 0.15562580567980683 tensor(179.4946)\n",
      "-286.275827233217 0.0 -286.275827233217 0.24315457018606837 tensor(176.1551)\n",
      "-286.44147413126393 0.0 -286.44147413126393 0.22602749930715882 tensor(166.6905)\n",
      "-286.1836828451072 0.0 -286.1836828451072 0.18462068514073104 tensor(167.2001)\n",
      "-286.49857710526305 0.0 -286.49857710526305 0.23044104803443385 tensor(174.2109)\n",
      "-286.1345721030926 0.0 -286.1345721030926 0.1261960979605683 tensor(185.4180)\n",
      "-286.106460350769 0.0 -286.106460350769 0.19650151703431945 tensor(161.2367)\n",
      "-285.94783352869115 0.0 -285.94783352869115 0.052024253116966214 tensor(197.8324)\n",
      "-286.3883145271025 0.0 -286.3883145271025 0.133543658451298 tensor(165.3906)\n",
      "-285.7197465453923 0.0 -285.7197465453923 0.18735089949836012 tensor(194.3034)\n",
      "-286.7626121100396 0.0 -286.7626121100396 0.17912346011851799 tensor(185.3127)\n",
      "-285.9471703994359 0.0 -285.9471703994359 0.17736329210229496 tensor(178.9404)\n",
      "-285.5086639796632 0.0 -285.5086639796632 0.17906804696623485 tensor(193.4201)\n",
      "-285.9743204496889 0.0 -285.9743204496889 0.07898522952513058 tensor(172.8241)\n",
      "-286.1768647010531 0.0 -286.1768647010531 0.16353117256648325 tensor(200.0335)\n",
      "-286.2940761694783 0.0 -286.2940761694783 0.19975715025203614 tensor(153.9203)\n",
      "-286.3258569107479 0.0 -286.3258569107479 0.10752938262253171 tensor(151.9107)\n",
      "-286.2802299023072 0.0 -286.2802299023072 0.05239252768844284 tensor(199.3841)\n",
      "-285.9380291337713 0.0 -285.9380291337713 0.11519432551590257 tensor(173.1834)\n",
      "-286.40330878110484 0.0 -286.40330878110484 0.11909920402772994 tensor(166.9324)\n",
      "-285.8682142291786 0.0 -285.8682142291786 0.1407217501628978 tensor(210.6217)\n",
      "-286.0463483338008 0.0 -286.0463483338008 0.12519364657803345 tensor(177.0490)\n",
      "-286.41005947305484 0.0 -286.41005947305484 0.10964866684428469 tensor(198.7147)\n",
      "-286.686631355589 0.0 -286.686631355589 0.2128046832344439 tensor(200.0993)\n",
      "-286.57827330718567 0.0 -286.57827330718567 0.12098682795559756 tensor(198.6786)\n",
      "-286.54793198668995 0.0 -286.54793198668995 0.3293711957045394 tensor(169.4811)\n",
      "-286.0376849402205 0.0 -286.0376849402205 0.23723845355645423 tensor(163.3572)\n",
      "-285.7900717499614 0.0 -285.7900717499614 0.13601767876620594 tensor(191.2890)\n",
      "-285.9225805921167 0.0 -285.9225805921167 0.17397218663927222 tensor(156.7983)\n",
      "-286.43896906450703 0.0 -286.43896906450703 0.08093085598410191 tensor(204.7309)\n",
      "-286.02224059936236 0.0 -286.02224059936236 0.275125890642771 tensor(185.7845)\n",
      "-285.9484536068152 0.0 -285.9484536068152 0.12524245300511627 tensor(219.2202)\n",
      "-285.89763598912737 0.0 -285.89763598912737 0.18133968218864294 tensor(169.1925)\n",
      "-285.89886054916235 0.0 -285.89886054916235 0.19542839912536522 tensor(171.1294)\n",
      "-286.11718334676493 0.0 -286.11718334676493 0.06864118937339733 tensor(175.9759)\n",
      "-285.83324267964815 0.0 -285.83324267964815 0.1509450435218571 tensor(189.1355)\n",
      "-286.3449339270612 0.0 -286.3449339270612 0.11613496955379281 tensor(167.7236)\n",
      "-286.3105408116651 0.0 -286.3105408116651 0.1701787511181988 tensor(172.9549)\n",
      "-286.8231107718943 0.0 -286.8231107718943 0.12149842581009618 tensor(175.4319)\n",
      "-286.05377906543515 0.0 -286.05377906543515 0.19361297427968968 tensor(186.7280)\n",
      "-285.9371867793576 0.0 -285.9371867793576 0.16032043975387364 tensor(198.5424)\n",
      "-286.6560991769963 0.0 -286.6560991769963 0.15214523254593973 tensor(162.3521)\n",
      "-286.4361915606685 0.0 -286.4361915606685 0.0748931132015874 tensor(194.1266)\n",
      "-285.9319026527686 0.0 -285.9319026527686 0.22287865727067513 tensor(243.2538)\n",
      "-286.1849159733536 0.0 -286.1849159733536 0.1329528772038827 tensor(185.3209)\n",
      "-286.5022880848801 0.0 -286.5022880848801 0.12844238240490277 tensor(201.9712)\n",
      "-286.4733038652869 0.0 -286.4733038652869 0.22858619300971852 tensor(160.4416)\n",
      "-285.96089787099174 0.0 -285.96089787099174 0.020741578197932778 tensor(204.1339)\n",
      "-285.91028751056814 0.0 -285.91028751056814 0.2887127946053568 tensor(182.5422)\n",
      "-286.1691779042703 0.0 -286.1691779042703 0.10813833415081345 tensor(157.5101)\n",
      "-286.33169454599084 0.0 -286.33169454599084 0.20912828451832738 tensor(191.2170)\n",
      "-286.2500832281342 0.0 -286.2500832281342 0.10244863981189034 tensor(179.4618)\n",
      "-285.9981288313677 0.0 -285.9981288313677 0.2955425825271394 tensor(192.8463)\n",
      "-286.1519032927225 0.0 -286.1519032927225 0.1734020811593881 tensor(182.9496)\n",
      "-286.06405900703646 0.0 -286.06405900703646 0.1690887540345425 tensor(167.3373)\n",
      "-286.20868053498117 0.0 -286.20868053498117 0.16403488353388504 tensor(172.4005)\n",
      "-286.3789770291095 0.0 -286.3789770291095 0.22577775151444784 tensor(217.2875)\n",
      "-286.27760238231633 0.0 -286.27760238231633 0.14857190972352244 tensor(156.3502)\n",
      "-286.28107778851273 0.0 -286.28107778851273 0.07969743438854643 tensor(219.5226)\n",
      "-286.15972160773504 0.0 -286.15972160773504 0.0863837867423617 tensor(202.4019)\n",
      "-286.1815141122568 0.0 -286.1815141122568 0.24911062142458773 tensor(256.3227)\n",
      "-286.37294555434596 0.0 -286.37294555434596 0.11542562846914634 tensor(186.6598)\n",
      "-285.8577269649977 0.0 -285.8577269649977 0.11808721335499876 tensor(177.9641)\n",
      "-286.36412674181605 0.0 -286.36412674181605 0.21186877489919684 tensor(162.1115)\n",
      "-286.16760922527965 0.0 -286.16760922527965 0.1294638977221386 tensor(202.0411)\n",
      "-285.7866395416296 0.0 -285.7866395416296 0.2020120384996785 tensor(168.8601)\n",
      "-286.5763497229864 0.0 -286.5763497229864 0.19334923794020356 tensor(175.2926)\n",
      "-286.5920379633016 0.0 -286.5920379633016 0.15314791691056295 tensor(186.5408)\n",
      "-286.41350385915365 0.0 -286.41350385915365 0.18734952544528258 tensor(148.9207)\n",
      "-286.03504166580643 0.0 -286.03504166580643 0.047204193546171475 tensor(175.8423)\n",
      "-286.4310745583282 0.0 -286.4310745583282 0.1475830384352205 tensor(186.1925)\n",
      "-286.4921465879256 0.0 -286.4921465879256 0.05491832929364843 tensor(176.7136)\n",
      "-286.5031429407758 0.0 -286.5031429407758 0.18604164814943236 tensor(164.4512)\n",
      "-286.04808264444887 0.0 -286.04808264444887 0.13514314252365447 tensor(227.1226)\n",
      "-286.3677168030965 0.0 -286.3677168030965 0.1389161612257844 tensor(182.1543)\n",
      "-286.38865225202846 0.0 -286.38865225202846 0.04552689750573815 tensor(179.4720)\n",
      "== Era 6 | Epoch 0 metrics ==\n",
      "\tloss -286.162\n",
      "\tforce 0\n",
      "\tdkl -286.162\n",
      "\tlogp 84.5777\n",
      "\tlogq -201.584\n",
      "\tess 0.152924\n",
      "-285.88848364662056 0.0 -285.88848364662056 0.17151186399167886 tensor(169.8931)\n",
      "-286.3062217044876 0.0 -286.3062217044876 0.08856784979897091 tensor(163.9497)\n",
      "-286.20081384654407 0.0 -286.20081384654407 0.15630311255964596 tensor(180.0570)\n",
      "-286.41077712467813 0.0 -286.41077712467813 0.08986780187996192 tensor(189.8475)\n",
      "-286.36343815398527 0.0 -286.36343815398527 0.21463947363484492 tensor(219.7164)\n",
      "-286.1704164549801 0.0 -286.1704164549801 0.22735556877931268 tensor(188.8007)\n",
      "-286.3039990894738 0.0 -286.3039990894738 0.24788429740111229 tensor(194.6836)\n",
      "-286.5798524670364 0.0 -286.5798524670364 0.2943882636097958 tensor(179.6023)\n",
      "-286.1615173875049 0.0 -286.1615173875049 0.10571139412008478 tensor(170.1847)\n",
      "-286.37955766419657 0.0 -286.37955766419657 0.18264928152531684 tensor(187.9760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.3183407226188 0.0 -286.3183407226188 0.05497635291636582 tensor(168.3196)\n",
      "-286.39846727923185 0.0 -286.39846727923185 0.02999809625746632 tensor(183.9822)\n",
      "-285.71793775061946 0.0 -285.71793775061946 0.2697860454202388 tensor(240.4530)\n",
      "-286.89171004273675 0.0 -286.89171004273675 0.13042178985037003 tensor(190.7966)\n",
      "-286.5078881198041 0.0 -286.5078881198041 0.1564416181632313 tensor(168.1657)\n",
      "-286.3552168647048 0.0 -286.3552168647048 0.05647459326396601 tensor(155.8566)\n",
      "-286.2218199331704 0.0 -286.2218199331704 0.049171846473235054 tensor(191.9443)\n",
      "-286.1500915658622 0.0 -286.1500915658622 0.1631084134551966 tensor(196.8652)\n",
      "-286.1225216480007 0.0 -286.1225216480007 0.2755557042262862 tensor(266.8346)\n",
      "-286.5420371069774 0.0 -286.5420371069774 0.16808801799583012 tensor(164.7570)\n",
      "-286.1599318492364 0.0 -286.1599318492364 0.0773500092606213 tensor(169.0632)\n",
      "-286.18675701061915 0.0 -286.18675701061915 0.17755604816627615 tensor(172.2632)\n",
      "-286.0491820692249 0.0 -286.0491820692249 0.20841032480162966 tensor(222.6787)\n",
      "-286.3405517691829 0.0 -286.3405517691829 0.2501126575592038 tensor(217.1299)\n",
      "-286.2216588124596 0.0 -286.2216588124596 0.08257773009460395 tensor(184.2117)\n",
      "-286.22815953440124 0.0 -286.22815953440124 0.09277007159579902 tensor(172.8506)\n",
      "-286.52765567990315 0.0 -286.52765567990315 0.1539955580890513 tensor(186.5365)\n",
      "-286.3538404961278 0.0 -286.3538404961278 0.1393383291451838 tensor(174.5002)\n",
      "-285.9427083628158 0.0 -285.9427083628158 0.18538044008803944 tensor(255.7819)\n",
      "-285.9380829536023 0.0 -285.9380829536023 0.14675656151667452 tensor(190.6036)\n",
      "-286.1608730629618 0.0 -286.1608730629618 0.2136366855016252 tensor(205.1218)\n",
      "-286.32248770043225 0.0 -286.32248770043225 0.20696693416633094 tensor(196.4286)\n",
      "-286.47533975595354 0.0 -286.47533975595354 0.06172471340157687 tensor(179.1227)\n",
      "-286.28331470162254 0.0 -286.28331470162254 0.15820365422325572 tensor(173.2295)\n",
      "-286.12336325185015 0.0 -286.12336325185015 0.16751311269102948 tensor(221.9133)\n",
      "-286.23015490835746 0.0 -286.23015490835746 0.19826385105984062 tensor(195.2133)\n",
      "-286.7650289755818 0.0 -286.7650289755818 0.1742047866238682 tensor(172.5083)\n",
      "-286.1829472923183 0.0 -286.1829472923183 0.13155608294803295 tensor(177.6602)\n",
      "-286.48108939060063 0.0 -286.48108939060063 0.21365675698295167 tensor(203.5249)\n",
      "-286.2684594860378 0.0 -286.2684594860378 0.12493886002907952 tensor(198.4457)\n",
      "-286.1516671193629 0.0 -286.1516671193629 0.24014680353322898 tensor(167.5063)\n",
      "-286.59924338665434 0.0 -286.59924338665434 0.23881992655253334 tensor(147.6648)\n",
      "-286.5241067498698 0.0 -286.5241067498698 0.28369580156948065 tensor(166.4679)\n",
      "-286.3517010013528 0.0 -286.3517010013528 0.29028658943577895 tensor(152.7664)\n",
      "-286.18585890266405 0.0 -286.18585890266405 0.08503471735228114 tensor(164.8039)\n",
      "-286.2334371667018 0.0 -286.2334371667018 0.1463830472982109 tensor(173.5064)\n",
      "-286.28993360134285 0.0 -286.28993360134285 0.2548174495057682 tensor(158.4434)\n",
      "-286.1329162749427 0.0 -286.1329162749427 0.12125455271525606 tensor(206.9606)\n",
      "-285.81570096757343 0.0 -285.81570096757343 0.149684267364435 tensor(177.5099)\n",
      "-286.2812673909054 0.0 -286.2812673909054 0.3066716323495748 tensor(163.3626)\n",
      "-286.06488502445154 0.0 -286.06488502445154 0.1648826437486532 tensor(235.6260)\n",
      "-286.22013951177814 0.0 -286.22013951177814 0.2569258294450524 tensor(175.8113)\n",
      "-286.27635253155313 0.0 -286.27635253155313 0.13319883978238284 tensor(200.4622)\n",
      "-286.3126764511534 0.0 -286.3126764511534 0.15817305976559035 tensor(160.1755)\n",
      "-286.23047003485595 0.0 -286.23047003485595 0.13525923731284237 tensor(205.8702)\n",
      "-285.9189847577457 0.0 -285.9189847577457 0.1501581136258259 tensor(201.2947)\n",
      "-286.13032176206127 0.0 -286.13032176206127 0.051394807081880024 tensor(197.0888)\n",
      "-286.31641392792784 0.0 -286.31641392792784 0.10543691926967966 tensor(174.8871)\n",
      "-286.41771850593193 0.0 -286.41771850593193 0.14581461383915756 tensor(169.8071)\n",
      "-286.7062058911248 0.0 -286.7062058911248 0.09681998284380752 tensor(196.3993)\n",
      "-286.3139952468039 0.0 -286.3139952468039 0.2811816402721784 tensor(181.2745)\n",
      "-286.5208931582538 0.0 -286.5208931582538 0.23773565456384615 tensor(233.2383)\n",
      "-286.22745202483594 0.0 -286.22745202483594 0.2848530619199004 tensor(175.9272)\n",
      "-286.1277975226186 0.0 -286.1277975226186 0.16042946083808224 tensor(166.1004)\n",
      "-286.23212952877975 0.0 -286.23212952877975 0.11430831258971673 tensor(181.3724)\n",
      "-286.2775465374251 0.0 -286.2775465374251 0.2154405928301627 tensor(181.6596)\n",
      "-286.4772068612044 0.0 -286.4772068612044 0.12498034917329774 tensor(198.5702)\n",
      "-286.11725418816565 0.0 -286.11725418816565 0.19738268005775345 tensor(174.6112)\n",
      "-286.53834182658755 0.0 -286.53834182658755 0.2042610333538215 tensor(224.9297)\n",
      "-286.6797295633337 0.0 -286.6797295633337 0.2785620777010765 tensor(229.8993)\n",
      "-286.23064948090354 0.0 -286.23064948090354 0.08819881575459798 tensor(236.0395)\n",
      "-286.60458910316714 0.0 -286.60458910316714 0.1444435428394139 tensor(155.5953)\n",
      "-286.70517808992093 0.0 -286.70517808992093 0.1012244298660137 tensor(153.5136)\n",
      "-286.1576189108763 0.0 -286.1576189108763 0.2053554859371244 tensor(190.6017)\n",
      "-286.14689590784553 0.0 -286.14689590784553 0.1888949517166271 tensor(196.4373)\n",
      "-286.3497838773094 0.0 -286.3497838773094 0.24550236625643054 tensor(211.8103)\n",
      "-286.58480390920397 0.0 -286.58480390920397 0.12343638044060502 tensor(172.2860)\n",
      "-286.2981629398516 0.0 -286.2981629398516 0.1854154206813259 tensor(197.6305)\n",
      "-286.3872463526548 0.0 -286.3872463526548 0.16000879652840813 tensor(175.7027)\n",
      "-286.28351210268477 0.0 -286.28351210268477 0.17468218478173939 tensor(193.0381)\n",
      "-286.3484513458698 0.0 -286.3484513458698 0.2351577863429466 tensor(186.9432)\n",
      "-286.38484768813373 0.0 -286.38484768813373 0.13471054948552694 tensor(172.9414)\n",
      "-286.8269710102745 0.0 -286.8269710102745 0.16272820794628254 tensor(186.3077)\n",
      "-286.70724363663794 0.0 -286.70724363663794 0.2419472781402861 tensor(172.7954)\n",
      "-286.81959593235683 0.0 -286.81959593235683 0.23158458709617233 tensor(187.8718)\n",
      "-286.14095705594764 0.0 -286.14095705594764 0.2850545879110249 tensor(195.1869)\n",
      "-286.4772237455284 0.0 -286.4772237455284 0.16698504227114605 tensor(201.0715)\n",
      "-286.19720465236105 0.0 -286.19720465236105 0.27227866323372035 tensor(208.9414)\n",
      "-286.0883873463394 0.0 -286.0883873463394 0.20704352639812332 tensor(206.6017)\n",
      "-286.3096038487341 0.0 -286.3096038487341 0.24920823201009398 tensor(217.0941)\n",
      "-286.178745194583 0.0 -286.178745194583 0.19720113153790253 tensor(201.9070)\n",
      "-286.2161647088566 0.0 -286.2161647088566 0.1369729973140673 tensor(179.6852)\n",
      "-286.2402069655042 0.0 -286.2402069655042 0.20488225166928595 tensor(232.1807)\n",
      "-285.9543715980948 0.0 -285.9543715980948 0.21549699987870657 tensor(210.5951)\n",
      "-285.9469097513937 0.0 -285.9469097513937 0.28076450854019724 tensor(193.0921)\n",
      "-286.2153595306358 0.0 -286.2153595306358 0.14640669181536012 tensor(214.5837)\n",
      "-286.42690650406655 0.0 -286.42690650406655 0.21827006132515206 tensor(162.2106)\n",
      "-286.61692201178255 0.0 -286.61692201178255 0.23607465306818678 tensor(158.2261)\n",
      "-286.4464691761805 0.0 -286.4464691761805 0.3138009612079562 tensor(207.7781)\n",
      "-286.2936449150638 0.0 -286.2936449150638 0.10662090855526883 tensor(208.2532)\n",
      "== Era 7 | Epoch 0 metrics ==\n",
      "\tloss -286.305\n",
      "\tforce 0\n",
      "\tdkl -286.305\n",
      "\tlogp 84.8143\n",
      "\tlogq -201.491\n",
      "\tess 0.177722\n",
      "-286.537106609483 0.0 -286.537106609483 0.2045764158921396 tensor(172.2154)\n",
      "-286.2830302570115 0.0 -286.2830302570115 0.25122990058667155 tensor(186.8715)\n",
      "-286.5874245845697 0.0 -286.5874245845697 0.3609735166465771 tensor(179.9779)\n",
      "-286.5694881367972 0.0 -286.5694881367972 0.1421701962683292 tensor(258.2445)\n",
      "-286.42945543480926 0.0 -286.42945543480926 0.2561086305411012 tensor(181.0738)\n",
      "-286.27919964511926 0.0 -286.27919964511926 0.035103950008485464 tensor(172.1458)\n",
      "-286.72435613687344 0.0 -286.72435613687344 0.12465568241849873 tensor(141.6634)\n",
      "-286.10619317544825 0.0 -286.10619317544825 0.09582336258427168 tensor(175.1122)\n",
      "-286.73583978604165 0.0 -286.73583978604165 0.13413245221464395 tensor(195.9198)\n",
      "-286.4085815340585 0.0 -286.4085815340585 0.1572663287832948 tensor(172.9945)\n",
      "-286.5424723926923 0.0 -286.5424723926923 0.23336864534872764 tensor(141.1428)\n",
      "-286.67236012716506 0.0 -286.67236012716506 0.1892821976601139 tensor(170.3122)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.48745329945166 0.0 -286.48745329945166 0.3351923603298981 tensor(183.4778)\n",
      "-286.4086725866524 0.0 -286.4086725866524 0.2339367033684603 tensor(190.1558)\n",
      "-286.3786840831285 0.0 -286.3786840831285 0.2852631636108011 tensor(177.7794)\n",
      "-286.19242061668507 0.0 -286.19242061668507 0.2755282730440587 tensor(170.9211)\n",
      "-286.3353751015657 0.0 -286.3353751015657 0.20449066532426072 tensor(171.3001)\n",
      "-286.5412564001293 0.0 -286.5412564001293 0.0903277178347152 tensor(151.1315)\n",
      "-286.64954102488946 0.0 -286.64954102488946 0.20758501131154133 tensor(154.3481)\n",
      "-286.5632346647491 0.0 -286.5632346647491 0.13914443749305375 tensor(201.0176)\n",
      "-286.79489591194033 0.0 -286.79489591194033 0.09587419141806518 tensor(165.4573)\n",
      "-286.31831843890495 0.0 -286.31831843890495 0.1202599021096059 tensor(149.7972)\n",
      "-286.66820240355975 0.0 -286.66820240355975 0.39738996218866346 tensor(167.7489)\n",
      "-286.1537156245861 0.0 -286.1537156245861 0.15127741793434388 tensor(195.1199)\n",
      "-285.92559520353893 0.0 -285.92559520353893 0.07785357858052853 tensor(180.9818)\n",
      "-286.3917089262435 0.0 -286.3917089262435 0.1156634521902045 tensor(176.7775)\n",
      "-285.95147594852244 0.0 -285.95147594852244 0.1549863859723266 tensor(160.0281)\n",
      "-286.27830650169045 0.0 -286.27830650169045 0.2779550920343548 tensor(179.3751)\n",
      "-286.0834627607694 0.0 -286.0834627607694 0.13567891517290306 tensor(262.1139)\n",
      "-286.5591197417069 0.0 -286.5591197417069 0.09916376961900894 tensor(238.8068)\n",
      "-285.88438713163805 0.0 -285.88438713163805 0.2172310003618905 tensor(171.4188)\n",
      "-286.23757750580916 0.0 -286.23757750580916 0.12636870295635996 tensor(239.2531)\n",
      "-286.22965689352765 0.0 -286.22965689352765 0.14439596584451334 tensor(187.9144)\n",
      "-286.46772162942233 0.0 -286.46772162942233 0.06545344125175975 tensor(241.0847)\n",
      "-286.0453738402466 0.0 -286.0453738402466 0.0893976993138862 tensor(186.8965)\n",
      "-286.3633080881568 0.0 -286.3633080881568 0.13545833703915994 tensor(187.5647)\n",
      "-286.3178601213106 0.0 -286.3178601213106 0.1494584588670315 tensor(203.9076)\n",
      "-286.5622436907738 0.0 -286.5622436907738 0.2268993573703759 tensor(173.2388)\n",
      "-286.06210177326375 0.0 -286.06210177326375 0.049697752213733716 tensor(192.8865)\n",
      "-286.2759352852666 0.0 -286.2759352852666 0.09970099164302534 tensor(178.5710)\n",
      "-286.2663834165055 0.0 -286.2663834165055 0.16686930298925484 tensor(162.2576)\n",
      "-286.22875884881864 0.0 -286.22875884881864 0.15859479684324648 tensor(181.4624)\n",
      "-286.5465164425683 0.0 -286.5465164425683 0.3285257969468686 tensor(204.5234)\n",
      "-286.17534265198 0.0 -286.17534265198 0.16825738548967462 tensor(212.7306)\n",
      "-286.0260143879649 0.0 -286.0260143879649 0.15062439982115416 tensor(196.1057)\n",
      "-286.2474229363158 0.0 -286.2474229363158 0.2257922898747189 tensor(252.8785)\n",
      "-286.3857771503134 0.0 -286.3857771503134 0.22578064978531676 tensor(166.2465)\n",
      "-286.2752004848731 0.0 -286.2752004848731 0.184128136769657 tensor(199.2902)\n",
      "-286.4096616858444 0.0 -286.4096616858444 0.15376170130802477 tensor(203.0557)\n",
      "-286.41636400718335 0.0 -286.41636400718335 0.2154032031593501 tensor(175.7815)\n",
      "-286.6231112400669 0.0 -286.6231112400669 0.13786751242926842 tensor(196.4311)\n",
      "-286.3985377633369 0.0 -286.3985377633369 0.09055341607823876 tensor(229.6384)\n",
      "-286.4121610013273 0.0 -286.4121610013273 0.13177324544515162 tensor(177.3841)\n",
      "-286.93293492399175 0.0 -286.93293492399175 0.10658113150633455 tensor(192.2546)\n",
      "-286.27577933567954 0.0 -286.27577933567954 0.15076029136609947 tensor(193.5153)\n",
      "-286.3307202946676 0.0 -286.3307202946676 0.08246681709235112 tensor(202.7116)\n",
      "-286.3477591408632 0.0 -286.3477591408632 0.15831846959903054 tensor(186.5083)\n",
      "-285.9573410801579 0.0 -285.9573410801579 0.17453018042646104 tensor(202.1121)\n",
      "-286.36645193817105 0.0 -286.36645193817105 0.09920610268480158 tensor(206.0717)\n",
      "-286.2531254279654 0.0 -286.2531254279654 0.17101725192989778 tensor(200.9171)\n",
      "-286.4893043025398 0.0 -286.4893043025398 0.18298206967529834 tensor(173.5557)\n",
      "-286.48432551985707 0.0 -286.48432551985707 0.40501090608678914 tensor(208.5531)\n",
      "-286.7802808399049 0.0 -286.7802808399049 0.0865043672120166 tensor(186.0244)\n",
      "-286.38042376031433 0.0 -286.38042376031433 0.21713416528037147 tensor(159.8977)\n",
      "-286.2433341940989 0.0 -286.2433341940989 0.18573705392072865 tensor(223.4533)\n",
      "-286.10670218695896 0.0 -286.10670218695896 0.04757526006181424 tensor(266.2954)\n",
      "-286.758209989785 0.0 -286.758209989785 0.14518629817315415 tensor(188.6019)\n",
      "-286.3978656041913 0.0 -286.3978656041913 0.249320025165595 tensor(197.0984)\n",
      "-286.201003996222 0.0 -286.201003996222 0.07530395627827396 tensor(160.2644)\n",
      "-286.1885733659748 0.0 -286.1885733659748 0.18267113567539062 tensor(247.3306)\n",
      "-286.5059794488631 0.0 -286.5059794488631 0.08546430607202608 tensor(256.7517)\n",
      "-286.241702488563 0.0 -286.241702488563 0.1742180968849368 tensor(236.8806)\n",
      "-286.3700750800747 0.0 -286.3700750800747 0.13108528055538027 tensor(200.8761)\n",
      "-285.933159587954 0.0 -285.933159587954 0.2370999665764601 tensor(177.3350)\n",
      "-286.281190779926 0.0 -286.281190779926 0.09690040074564589 tensor(147.5069)\n",
      "-286.2292607495907 0.0 -286.2292607495907 0.20082752308399057 tensor(152.3096)\n",
      "-286.77099498341465 0.0 -286.77099498341465 0.18503636326633424 tensor(216.6326)\n",
      "-286.57211596783645 0.0 -286.57211596783645 0.20435832253651606 tensor(178.7252)\n",
      "-286.0005964188385 0.0 -286.0005964188385 0.20196211373035974 tensor(187.3306)\n",
      "-286.46777162445346 0.0 -286.46777162445346 0.10580653898676727 tensor(243.2407)\n",
      "-285.9831437203854 0.0 -285.9831437203854 0.1540256211572996 tensor(220.1818)\n",
      "-286.37042332258744 0.0 -286.37042332258744 0.2294059834370078 tensor(189.2191)\n",
      "-286.3636958450637 0.0 -286.3636958450637 0.1500375458982836 tensor(171.2667)\n",
      "-286.43527746197674 0.0 -286.43527746197674 0.24064750369456317 tensor(169.7926)\n",
      "-286.1557994940868 0.0 -286.1557994940868 0.1264405102052606 tensor(206.4287)\n",
      "-286.56792342199367 0.0 -286.56792342199367 0.10796746636035029 tensor(183.7054)\n",
      "-286.1408463808341 0.0 -286.1408463808341 0.06312718741308562 tensor(211.5781)\n",
      "-285.9978777318293 0.0 -285.9978777318293 0.13154776787562286 tensor(206.1086)\n",
      "-286.0264147412433 0.0 -286.0264147412433 0.09181041278112588 tensor(164.9366)\n",
      "-286.807221669686 0.0 -286.807221669686 0.2599079972176852 tensor(229.5582)\n",
      "-286.5154263018659 0.0 -286.5154263018659 0.31911926191982726 tensor(168.0134)\n",
      "-286.32345571926055 0.0 -286.32345571926055 0.16860926606593768 tensor(218.4447)\n",
      "-286.3367462871657 0.0 -286.3367462871657 0.19258861104730482 tensor(170.7523)\n",
      "-286.5275318832228 0.0 -286.5275318832228 0.07253686133148804 tensor(190.8077)\n",
      "-286.4986711875887 0.0 -286.4986711875887 0.16766783298138282 tensor(266.0972)\n",
      "-286.5905860238215 0.0 -286.5905860238215 0.39849426498707763 tensor(165.4466)\n",
      "-286.590031067059 0.0 -286.590031067059 0.15772748543614035 tensor(173.6528)\n",
      "-286.6259915456167 0.0 -286.6259915456167 0.19688689059389589 tensor(180.8315)\n",
      "-286.09411230012057 0.0 -286.09411230012057 0.13064603403154418 tensor(177.8318)\n",
      "-286.4925012570722 0.0 -286.4925012570722 0.11575384242978314 tensor(203.4766)\n",
      "== Era 8 | Epoch 0 metrics ==\n",
      "\tloss -286.367\n",
      "\tforce 0\n",
      "\tdkl -286.367\n",
      "\tlogp 84.8838\n",
      "\tlogq -201.483\n",
      "\tess 0.170423\n",
      "-287.02114331027894 0.0 -287.02114331027894 0.29389120007970404 tensor(259.6025)\n",
      "-286.70151535209544 0.0 -286.70151535209544 0.1901178481707551 tensor(228.0437)\n",
      "-286.4824090196987 0.0 -286.4824090196987 0.23335374910584938 tensor(170.5687)\n",
      "-286.4066472751639 0.0 -286.4066472751639 0.09921252909259021 tensor(203.3576)\n",
      "-286.5231270414266 0.0 -286.5231270414266 0.08603007711243431 tensor(201.1613)\n",
      "-286.6907622305255 0.0 -286.6907622305255 0.16095462839793206 tensor(180.5515)\n",
      "-286.3310040053582 0.0 -286.3310040053582 0.25166909002919513 tensor(194.1703)\n",
      "-286.4557094248755 0.0 -286.4557094248755 0.22909056871917685 tensor(235.4599)\n",
      "-286.20611641453405 0.0 -286.20611641453405 0.26289993124796074 tensor(199.2196)\n",
      "-286.8254304982573 0.0 -286.8254304982573 0.09694729171318361 tensor(187.2135)\n",
      "-286.30739273947955 0.0 -286.30739273947955 0.10942721171705225 tensor(198.9931)\n",
      "-286.2650432785358 0.0 -286.2650432785358 0.130099865457028 tensor(204.2908)\n",
      "-286.00213913091363 0.0 -286.00213913091363 0.17081027208372393 tensor(193.9949)\n",
      "-286.4420268982325 0.0 -286.4420268982325 0.09827825850719102 tensor(177.0615)\n",
      "-286.47831892261837 0.0 -286.47831892261837 0.17027048723240634 tensor(193.2899)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.8727808855105 0.0 -286.8727808855105 0.2119762225984894 tensor(198.1626)\n",
      "-286.4026814334459 0.0 -286.4026814334459 0.053351743906554165 tensor(174.8487)\n",
      "-285.7469882067933 0.0 -285.7469882067933 0.18192247011366758 tensor(173.1592)\n",
      "-286.41491595182043 0.0 -286.41491595182043 0.3231778264226082 tensor(235.9829)\n",
      "-286.05824123879245 0.0 -286.05824123879245 0.1212738108742854 tensor(178.4911)\n",
      "-286.06622801777286 0.0 -286.06622801777286 0.13319284648792587 tensor(254.3342)\n",
      "-285.8847073045669 0.0 -285.8847073045669 0.20306200277060413 tensor(186.1448)\n",
      "-286.58413832945365 0.0 -286.58413832945365 0.15970677779913178 tensor(197.4611)\n",
      "-286.220231684355 0.0 -286.220231684355 0.26816636434025265 tensor(163.8824)\n",
      "-286.2588822341328 0.0 -286.2588822341328 0.24439753779200485 tensor(196.8515)\n",
      "-286.1987582742004 0.0 -286.1987582742004 0.1692952245667373 tensor(156.9427)\n",
      "-286.36796379927716 0.0 -286.36796379927716 0.17812086778101455 tensor(197.4068)\n",
      "-286.47062444364667 0.0 -286.47062444364667 0.3024838169059279 tensor(205.6580)\n",
      "-286.73761363679625 0.0 -286.73761363679625 0.2736249260963918 tensor(175.0738)\n",
      "-286.5452942107376 0.0 -286.5452942107376 0.23068547510510537 tensor(200.1411)\n",
      "-286.6157079744836 0.0 -286.6157079744836 0.14124031719948146 tensor(205.7784)\n",
      "-286.6283071156665 0.0 -286.6283071156665 0.1336417328015271 tensor(201.0088)\n",
      "-286.3041781569754 0.0 -286.3041781569754 0.10615707664760278 tensor(216.1397)\n",
      "-286.53134748503237 0.0 -286.53134748503237 0.17369012956998464 tensor(227.1283)\n",
      "-286.2352646121754 0.0 -286.2352646121754 0.1030042208009781 tensor(190.0377)\n",
      "-286.43309130406783 0.0 -286.43309130406783 0.22195264077682098 tensor(185.0662)\n",
      "-286.532430514857 0.0 -286.532430514857 0.18209915689994569 tensor(199.0048)\n",
      "-286.0062781291125 0.0 -286.0062781291125 0.2869682327056358 tensor(164.7445)\n",
      "-286.23660993476517 0.0 -286.23660993476517 0.1890113923073028 tensor(211.7919)\n",
      "-286.1543015236242 0.0 -286.1543015236242 0.31405441346512714 tensor(207.3239)\n",
      "-286.7691044645841 0.0 -286.7691044645841 0.22235768320363455 tensor(171.7489)\n",
      "-286.69473227221863 0.0 -286.69473227221863 0.29724706238671933 tensor(184.6160)\n",
      "-286.6056640979235 0.0 -286.6056640979235 0.07825859687776822 tensor(224.7687)\n",
      "-287.06260978653745 0.0 -287.06260978653745 0.1942277897633165 tensor(148.9283)\n",
      "-286.51965937519446 0.0 -286.51965937519446 0.24118419561376736 tensor(199.6750)\n",
      "-286.71569779580443 0.0 -286.71569779580443 0.23718665594699623 tensor(193.8519)\n",
      "-286.31569720121297 0.0 -286.31569720121297 0.09241445722069157 tensor(208.6250)\n",
      "-286.15369159037135 0.0 -286.15369159037135 0.13633849803507955 tensor(222.2500)\n",
      "-286.1202561957839 0.0 -286.1202561957839 0.1662602484185038 tensor(160.2652)\n",
      "-286.38260133875326 0.0 -286.38260133875326 0.22806377720240162 tensor(212.7304)\n",
      "-286.5643231042887 0.0 -286.5643231042887 0.03577635865063682 tensor(213.6674)\n",
      "-286.54917333191236 0.0 -286.54917333191236 0.18624506260886745 tensor(235.1277)\n",
      "-286.3557967165754 0.0 -286.3557967165754 0.29808922694742435 tensor(216.9541)\n",
      "-286.40874706482623 0.0 -286.40874706482623 0.17086581866760736 tensor(200.1684)\n",
      "-286.33357798154066 0.0 -286.33357798154066 0.24240627931759098 tensor(173.9853)\n",
      "-286.2443289212955 0.0 -286.2443289212955 0.10384435950746716 tensor(198.7357)\n",
      "-286.3991307966071 0.0 -286.3991307966071 0.12585416069345376 tensor(186.5024)\n",
      "-286.595994214872 0.0 -286.595994214872 0.21754198788230306 tensor(255.8422)\n",
      "-286.3754411743394 0.0 -286.3754411743394 0.2600984823410715 tensor(202.6709)\n",
      "-286.3782236353094 0.0 -286.3782236353094 0.32300982662210564 tensor(213.6560)\n",
      "-286.2069273125203 0.0 -286.2069273125203 0.26051753442054265 tensor(229.6999)\n",
      "-286.2166682044773 0.0 -286.2166682044773 0.18426339198313496 tensor(237.3809)\n",
      "-286.58452546569663 0.0 -286.58452546569663 0.2229111347439823 tensor(191.4187)\n",
      "-286.49806907045433 0.0 -286.49806907045433 0.06955490789977652 tensor(204.6431)\n",
      "-286.56999740630954 0.0 -286.56999740630954 0.2372728273469765 tensor(194.1234)\n",
      "-286.61682876604186 0.0 -286.61682876604186 0.28385374456603346 tensor(269.0508)\n",
      "-286.7828997602544 0.0 -286.7828997602544 0.18404901770349427 tensor(197.5434)\n",
      "-286.73795714268357 0.0 -286.73795714268357 0.15024031414145847 tensor(187.0878)\n",
      "-286.10283324645707 0.0 -286.10283324645707 0.23211293729316307 tensor(179.4851)\n",
      "-286.68788271249457 0.0 -286.68788271249457 0.06334117472755382 tensor(189.1081)\n",
      "-286.0431345773327 0.0 -286.0431345773327 0.31628652807188307 tensor(195.9531)\n",
      "-286.5075632330975 0.0 -286.5075632330975 0.14178302720488187 tensor(180.9970)\n",
      "-286.780232020801 0.0 -286.780232020801 0.19890333119938947 tensor(184.4913)\n",
      "-286.20052337695347 0.0 -286.20052337695347 0.19140227384256708 tensor(165.3739)\n",
      "-286.33135252008054 0.0 -286.33135252008054 0.17959237844833967 tensor(216.0221)\n",
      "-286.7965058811743 0.0 -286.7965058811743 0.05556831342907595 tensor(193.4114)\n",
      "-286.5988600099132 0.0 -286.5988600099132 0.2524323212190165 tensor(181.8211)\n",
      "-286.85149379401355 0.0 -286.85149379401355 0.17524082675267433 tensor(181.9763)\n",
      "-286.2022824001368 0.0 -286.2022824001368 0.18282628228624365 tensor(192.9502)\n",
      "-286.11119323037053 0.0 -286.11119323037053 0.22506877580693246 tensor(229.0807)\n",
      "-285.9755150885368 0.0 -285.9755150885368 0.15418591272848392 tensor(191.5599)\n",
      "-286.2641506555593 0.0 -286.2641506555593 0.3112345253681362 tensor(180.2298)\n",
      "-286.57727028990143 0.0 -286.57727028990143 0.2078634006435638 tensor(170.6671)\n",
      "-286.4159981662654 0.0 -286.4159981662654 0.21131455588263373 tensor(180.5727)\n",
      "-286.6815450879337 0.0 -286.6815450879337 0.11940389673797652 tensor(199.3296)\n",
      "-286.37171698208215 0.0 -286.37171698208215 0.3500829551761694 tensor(191.9968)\n",
      "-286.4842229430802 0.0 -286.4842229430802 0.27137604667484494 tensor(190.4695)\n",
      "-286.73390491507155 0.0 -286.73390491507155 0.26063281635881796 tensor(221.4288)\n",
      "-286.4612519083893 0.0 -286.4612519083893 0.24315469385457197 tensor(163.6212)\n",
      "-286.3057414935224 0.0 -286.3057414935224 0.12333752441734154 tensor(157.9588)\n",
      "-286.41559799239235 0.0 -286.41559799239235 0.21320178361836442 tensor(226.1825)\n",
      "-286.8239368621939 0.0 -286.8239368621939 0.27490685397754044 tensor(218.3858)\n",
      "-286.54802844503934 0.0 -286.54802844503934 0.09974855418295518 tensor(211.5825)\n",
      "-286.4927038872029 0.0 -286.4927038872029 0.20310604934321383 tensor(187.4146)\n",
      "-286.87888084565327 0.0 -286.87888084565327 0.23110604039978547 tensor(185.9996)\n",
      "-286.70237974138047 0.0 -286.70237974138047 0.23735142327284123 tensor(184.4386)\n",
      "-286.82497217788705 0.0 -286.82497217788705 0.29094607159725183 tensor(209.1496)\n",
      "-286.8000026277854 0.0 -286.8000026277854 0.28634510088799453 tensor(183.9241)\n",
      "-286.6593953842028 0.0 -286.6593953842028 0.28605267837301174 tensor(211.3073)\n",
      "-286.6593273446785 0.0 -286.6593273446785 0.06442028887003338 tensor(190.9413)\n",
      "== Era 9 | Epoch 0 metrics ==\n",
      "\tloss -286.457\n",
      "\tforce 0\n",
      "\tdkl -286.457\n",
      "\tlogp 85.0582\n",
      "\tlogq -201.399\n",
      "\tess 0.195936\n",
      "-286.112641930622 0.0 -286.112641930622 0.24270165556334164 tensor(187.0288)\n",
      "-286.74307089156645 0.0 -286.74307089156645 0.30402016752058275 tensor(239.0813)\n",
      "-286.3627718974203 0.0 -286.3627718974203 0.1695272257458313 tensor(212.1271)\n",
      "-286.9138982646343 0.0 -286.9138982646343 0.17533220700705845 tensor(247.8542)\n",
      "-286.4914895868915 0.0 -286.4914895868915 0.3557558521456823 tensor(182.9216)\n",
      "-286.3907180699548 0.0 -286.3907180699548 0.2712848348205242 tensor(169.6150)\n",
      "-286.1998603645958 0.0 -286.1998603645958 0.1137191212840173 tensor(191.0588)\n",
      "-286.75755210850036 0.0 -286.75755210850036 0.2289782796090065 tensor(190.5990)\n",
      "-286.5260797397349 0.0 -286.5260797397349 0.11382421850455104 tensor(241.9871)\n",
      "-286.66681282544994 0.0 -286.66681282544994 0.1421950386876273 tensor(189.0954)\n",
      "-286.4969510568276 0.0 -286.4969510568276 0.37574699738101186 tensor(178.8558)\n",
      "-286.60785365200275 0.0 -286.60785365200275 0.16190419461915082 tensor(196.6475)\n",
      "-286.5858888731037 0.0 -286.5858888731037 0.09949906602033737 tensor(191.5583)\n",
      "-286.7746481498666 0.0 -286.7746481498666 0.3226847721551803 tensor(162.4335)\n",
      "-286.43136252425563 0.0 -286.43136252425563 0.271788667183745 tensor(236.5212)\n",
      "-286.79043410581176 0.0 -286.79043410581176 0.21694780755471837 tensor(194.8753)\n",
      "-286.7977897184018 0.0 -286.7977897184018 0.356860180889861 tensor(214.8998)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-286.6543886427441 0.0 -286.6543886427441 0.027139273083411825 tensor(187.2683)\n",
      "-287.11984830590984 0.0 -287.11984830590984 0.23946253513908966 tensor(180.7781)\n",
      "-286.44726839079055 0.0 -286.44726839079055 0.2990186078514791 tensor(198.1157)\n",
      "-286.71132282319854 0.0 -286.71132282319854 0.26285098549513436 tensor(166.8573)\n",
      "-286.96558113287847 0.0 -286.96558113287847 0.2241727284520199 tensor(194.2638)\n",
      "-286.04790435054997 0.0 -286.04790435054997 0.10465375528569884 tensor(189.9127)\n",
      "-286.8215774662575 0.0 -286.8215774662575 0.26091876294329636 tensor(244.6845)\n",
      "-286.1405829925794 0.0 -286.1405829925794 0.2026252107283514 tensor(181.0103)\n",
      "-286.83591925113876 0.0 -286.83591925113876 0.15957090316272263 tensor(175.1791)\n",
      "-286.55747095961726 0.0 -286.55747095961726 0.16052866625494644 tensor(192.5709)\n",
      "-286.71901436589553 0.0 -286.71901436589553 0.201083817478051 tensor(224.3452)\n",
      "-286.98951987543694 0.0 -286.98951987543694 0.24446415642835975 tensor(198.9069)\n",
      "-286.97806731676167 0.0 -286.97806731676167 0.10034091782211707 tensor(166.5438)\n",
      "-286.75921245253136 0.0 -286.75921245253136 0.22380504368641646 tensor(190.9207)\n",
      "-286.39011990742813 0.0 -286.39011990742813 0.08367137494225896 tensor(180.9092)\n",
      "-286.63701230095353 0.0 -286.63701230095353 0.18297864584853954 tensor(167.2133)\n",
      "-286.455725866168 0.0 -286.455725866168 0.15605382474112262 tensor(184.6280)\n",
      "-286.64271449059675 0.0 -286.64271449059675 0.1442328761795307 tensor(190.4907)\n",
      "-286.82313403668263 0.0 -286.82313403668263 0.14759240936980056 tensor(185.6281)\n",
      "-286.7464416827516 0.0 -286.7464416827516 0.18385908693548178 tensor(221.7098)\n",
      "-286.1089617397995 0.0 -286.1089617397995 0.15458231740333134 tensor(184.0134)\n",
      "-286.3156639438402 0.0 -286.3156639438402 0.2526808039956628 tensor(207.8897)\n",
      "-286.43724937145566 0.0 -286.43724937145566 0.3129791357090456 tensor(217.8973)\n",
      "-286.48407163527804 0.0 -286.48407163527804 0.15427585436001617 tensor(160.8249)\n",
      "-286.5620981890644 0.0 -286.5620981890644 0.3403242002635744 tensor(208.1708)\n",
      "-286.8202248546592 0.0 -286.8202248546592 0.2692293215104449 tensor(168.3706)\n",
      "-287.13226984901087 0.0 -287.13226984901087 0.10420709114034288 tensor(195.8292)\n",
      "-286.59436042783517 0.0 -286.59436042783517 0.14523115460192698 tensor(212.7448)\n",
      "-286.2569631653659 0.0 -286.2569631653659 0.1140400332683511 tensor(221.7353)\n",
      "-286.30683918429145 0.0 -286.30683918429145 0.17865947575768595 tensor(185.9634)\n",
      "-286.61026173375586 0.0 -286.61026173375586 0.2815045876019898 tensor(184.6091)\n",
      "-286.770784310232 0.0 -286.770784310232 0.17787040642335433 tensor(205.3067)\n",
      "-286.5048960607363 0.0 -286.5048960607363 0.23476334107871183 tensor(203.0381)\n",
      "-286.27132851194835 0.0 -286.27132851194835 0.1420589277891973 tensor(200.3075)\n",
      "-286.36109330041216 0.0 -286.36109330041216 0.11388774778354874 tensor(256.7741)\n",
      "-286.52018916299573 0.0 -286.52018916299573 0.1506289493088937 tensor(204.9312)\n",
      "-286.9373052163344 0.0 -286.9373052163344 0.19686417588977337 tensor(221.7229)\n",
      "-286.4033004619765 0.0 -286.4033004619765 0.11840204953581936 tensor(207.9474)\n",
      "-286.4787350398762 0.0 -286.4787350398762 0.29775529169169646 tensor(269.3246)\n",
      "-286.2721419615558 0.0 -286.2721419615558 0.1621173440619198 tensor(267.2565)\n",
      "-286.8384875001026 0.0 -286.8384875001026 0.12014513282889791 tensor(180.7704)\n",
      "-286.516719616636 0.0 -286.516719616636 0.15835486557685197 tensor(179.5114)\n",
      "-286.38594944407635 0.0 -286.38594944407635 0.20699702510942194 tensor(155.6015)\n",
      "-286.53378497142205 0.0 -286.53378497142205 0.31782299896536614 tensor(193.8807)\n",
      "-286.60662749010197 0.0 -286.60662749010197 0.21053794944543028 tensor(205.0236)\n",
      "-286.6386259276561 0.0 -286.6386259276561 0.1481257156786013 tensor(180.5681)\n",
      "-286.85489264481976 0.0 -286.85489264481976 0.24051393894989773 tensor(186.2450)\n",
      "-286.60415594840185 0.0 -286.60415594840185 0.15645862107103026 tensor(171.7445)\n",
      "-286.7194027994611 0.0 -286.7194027994611 0.13904783710683652 tensor(198.3938)\n",
      "-286.6071121100693 0.0 -286.6071121100693 0.11780665296343241 tensor(203.8747)\n",
      "-286.29881367901436 0.0 -286.29881367901436 0.07708229399726824 tensor(220.4339)\n",
      "-286.6492353326405 0.0 -286.6492353326405 0.11163380947920058 tensor(201.1875)\n",
      "-286.56109671288027 0.0 -286.56109671288027 0.08581933577760428 tensor(200.3530)\n",
      "-286.1372040789403 0.0 -286.1372040789403 0.12163474615300408 tensor(213.9558)\n",
      "-286.4963000926422 0.0 -286.4963000926422 0.19567866198572614 tensor(219.6232)\n",
      "-287.14441476070317 0.0 -287.14441476070317 0.23660190949132484 tensor(179.0976)\n",
      "-286.46386740251756 0.0 -286.46386740251756 0.3566870510425952 tensor(238.1107)\n",
      "-286.45551325690377 0.0 -286.45551325690377 0.21951277399064917 tensor(152.8040)\n",
      "-286.32141378516883 0.0 -286.32141378516883 0.3317424357676092 tensor(200.0473)\n",
      "-286.419118108549 0.0 -286.419118108549 0.258386908762144 tensor(224.7113)\n",
      "-286.34330561465924 0.0 -286.34330561465924 0.256746624322117 tensor(200.4225)\n",
      "-286.49638101685895 0.0 -286.49638101685895 0.13612757707808315 tensor(189.7574)\n",
      "-286.6931515308588 0.0 -286.6931515308588 0.2488909338327856 tensor(204.5078)\n",
      "-286.27556950708333 0.0 -286.27556950708333 0.3063846707751413 tensor(209.7473)\n",
      "-286.3554933530902 0.0 -286.3554933530902 0.15134227371779965 tensor(223.9476)\n",
      "-286.44044615305677 0.0 -286.44044615305677 0.09925114683812544 tensor(231.2934)\n",
      "-286.82453162250226 0.0 -286.82453162250226 0.2567516263902403 tensor(245.2987)\n",
      "-286.56610573097333 0.0 -286.56610573097333 0.12301388840167976 tensor(236.6066)\n",
      "-286.3003018051995 0.0 -286.3003018051995 0.14670908206229752 tensor(176.8570)\n",
      "-286.60968031993303 0.0 -286.60968031993303 0.14661689389477142 tensor(186.5360)\n",
      "-286.36498524084203 0.0 -286.36498524084203 0.17832994801346633 tensor(222.4740)\n",
      "-286.82901955750975 0.0 -286.82901955750975 0.148012225006639 tensor(200.9130)\n",
      "-286.3631964543341 0.0 -286.3631964543341 0.18045269034922395 tensor(262.2975)\n",
      "-286.76193332969615 0.0 -286.76193332969615 0.20424802333572945 tensor(243.4555)\n",
      "-286.5254669719391 0.0 -286.5254669719391 0.1287268988766372 tensor(240.4710)\n",
      "-286.2279928237775 0.0 -286.2279928237775 0.2475906077860816 tensor(196.8762)\n",
      "-286.917938324739 0.0 -286.917938324739 0.31677178469340206 tensor(179.0117)\n",
      "-286.93597384058205 0.0 -286.93597384058205 0.12138430088228223 tensor(226.9939)\n",
      "-286.59634704872724 0.0 -286.59634704872724 0.22898048215470032 tensor(221.4754)\n",
      "-286.6570655070627 0.0 -286.6570655070627 0.15560560465234638 tensor(222.0719)\n",
      "-286.46474533673444 0.0 -286.46474533673444 0.25234378916006034 tensor(220.6562)\n",
      "-286.7894748047123 0.0 -286.7894748047123 0.26493710703707507 tensor(175.3953)\n",
      "Accept rate: 0.2861328125\n",
      "Topological susceptibility = 1.23 +/- 0.12\n",
      "... vs HMC estimate = 1.23 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "pre_flow_model, flow_act = flow_train(param)\n",
    "flow_eval(pre_flow_model,flow_act)\n",
    "pre_flow = pre_flow_model['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.77397873000283 27.77397873000283 -324.7726341120924 0.03714393979584539 tensor(165.4058)\n",
      "== Era 0 | Epoch 0 metrics ==\n",
      "\tloss 27.774\n",
      "\tforce 27.774\n",
      "\tdkl -324.773\n",
      "\tlogp 85.8983\n",
      "\tlogq -238.874\n",
      "\tess 0.0371439\n",
      "26.91407619795939 26.91407619795939 -322.95765631459903 0.04061575398475373 tensor(162.8706)\n",
      "26.767884668397304 26.767884668397304 -325.36317072662706 0.015734281402194558 tensor(162.3905)\n",
      "26.24992180370059 26.24992180370059 -324.74301718258414 0.04104593314037602 tensor(160.8240)\n",
      "26.63525599015806 26.63525599015806 -322.7901953025006 0.04243541695345945 tensor(162.0254)\n",
      "26.81934919795798 26.81934919795798 -323.8843819176688 0.02651314548844088 tensor(162.5620)\n",
      "26.19574095421433 26.19574095421433 -320.73880448920755 0.03226041012604028 tensor(160.7309)\n",
      "25.77215270731929 25.77215270731929 -323.2999835264045 0.018805823847524303 tensor(159.3821)\n",
      "24.34105313985693 24.34105313985693 -324.60268076663067 0.01619048364981672 tensor(154.8887)\n",
      "24.221254247091423 24.221254247091423 -323.78034499799105 0.028328687940101866 tensor(154.5066)\n",
      "24.998290970095113 24.998290970095113 -323.8402704668776 0.11917688623470903 tensor(156.9476)\n",
      "24.68316758546746 24.68316758546746 -323.4717640149297 0.016611015777541066 tensor(155.9680)\n",
      "23.85250664523638 23.85250664523638 -322.86410167454835 0.03337886118627586 tensor(153.3032)\n",
      "24.2132226788814 24.2132226788814 -321.6846164372738 0.0591574338934635 tensor(154.4852)\n",
      "24.19675459332121 24.19675459332121 -322.7351382908911 0.019861191511886686 tensor(154.4501)\n",
      "24.11881517957023 24.11881517957023 -321.04548270028505 0.026391557950129582 tensor(154.1778)\n",
      "23.44419679274651 23.44419679274651 -322.094089547727 0.04636228522953589 tensor(151.9999)\n",
      "22.70681700693231 22.70681700693231 -321.8789717976249 0.023116116072205227 tensor(149.5911)\n",
      "23.834323801098957 23.834323801098957 -320.05284720094863 0.01592283521274097 tensor(153.2751)\n",
      "22.68897263639386 22.68897263639386 -320.8153627504719 0.055378345404769186 tensor(149.5372)\n",
      "22.69116318062099 22.69116318062099 -320.3662735735104 0.05328884196997588 tensor(149.5596)\n",
      "22.400900617337392 22.400900617337392 -320.7632780141041 0.017201046718115103 tensor(148.6244)\n",
      "21.895426704748065 21.895426704748065 -320.3435213151172 0.018111700139671377 tensor(146.8825)\n",
      "22.098140703745866 22.098140703745866 -321.9327415056108 0.041484656625272065 tensor(147.5763)\n",
      "21.591519783050817 21.591519783050817 -320.0767021491595 0.0336765883338787 tensor(145.8922)\n",
      "22.642806468685645 22.642806468685645 -319.9263402517643 0.024614196579608814 tensor(149.4039)\n",
      "21.080467026983413 21.080467026983413 -321.1192989383766 0.042868659220131784 tensor(144.1443)\n",
      "21.7323490102761 21.7323490102761 -318.7505880771927 0.023297049483780762 tensor(146.3834)\n",
      "21.188417334930364 21.188417334930364 -320.0719111025115 0.015721163197379213 tensor(144.5142)\n",
      "20.937790266868934 20.937790266868934 -319.20959353412593 0.01712692722358962 tensor(143.6550)\n",
      "20.7935625391463 20.7935625391463 -319.59057336899497 0.07485707942209512 tensor(143.1801)\n",
      "20.8663873740573 20.8663873740573 -318.4540963188948 0.050094305925712346 tensor(143.4316)\n",
      "20.46934805499365 20.46934805499365 -318.26025274845733 0.05614658059600332 tensor(142.0709)\n",
      "20.46504245401271 20.46504245401271 -318.76934351666 0.05843499529823279 tensor(142.0241)\n",
      "20.310774207667382 20.310774207667382 -318.23285055502237 0.06575137344703498 tensor(141.4971)\n",
      "19.31921416530863 19.31921416530863 -318.64591632769657 0.016424764853303908 tensor(137.9653)\n",
      "19.813594233473406 19.813594233473406 -317.4292394169543 0.05577265917823558 tensor(139.8038)\n",
      "19.32488587891904 19.32488587891904 -317.8381985707416 0.07478198366322832 tensor(138.0158)\n",
      "20.034190325649906 20.034190325649906 -316.91373639530707 0.031781059076404466 tensor(140.5406)\n",
      "18.83900840537935 18.83900840537935 -317.3943819403782 0.021342241500923762 tensor(136.2694)\n",
      "18.956325620226256 18.956325620226256 -318.2592099769126 0.03219613396779034 tensor(136.7010)\n",
      "18.611747900016272 18.611747900016272 -317.9230606048835 0.019950129052971763 tensor(135.4593)\n",
      "19.208222967557056 19.208222967557056 -316.5608814499707 0.08637591763094192 tensor(137.5753)\n",
      "18.874563549932375 18.874563549932375 -316.7954607820206 0.03911388431563453 tensor(136.3970)\n",
      "18.326458299147053 18.326458299147053 -318.006230863151 0.016277234697529133 tensor(134.3690)\n",
      "17.92379095371081 17.92379095371081 -318.2763987119621 0.020873815607735456 tensor(132.8757)\n",
      "18.02036060979313 18.02036060979313 -317.08611535887684 0.03325051481328449 tensor(133.2426)\n",
      "17.27557743949025 17.27557743949025 -317.0643004853449 0.062222517969918976 tensor(130.4557)\n",
      "17.842042531094027 17.842042531094027 -316.7441018711092 0.03266077889344118 tensor(132.5848)\n",
      "17.445917559129448 17.445917559129448 -316.0851738899132 0.02084983437634843 tensor(131.0937)\n",
      "17.58120414036685 17.58120414036685 -316.16022347256677 0.022724984690893072 tensor(131.6069)\n",
      "17.66468734738689 17.66468734738689 -316.51729207067285 0.01915933208952897 tensor(131.9081)\n",
      "16.720761485174105 16.720761485174105 -316.45810267069197 0.01833174624300603 tensor(128.3316)\n",
      "16.879780740604414 16.879780740604414 -316.2756505060988 0.020601186014212826 tensor(128.9529)\n",
      "17.092740702218165 17.092740702218165 -314.9587219384505 0.01573138864182489 tensor(129.7662)\n",
      "16.997062237872665 16.997062237872665 -315.0092477801451 0.03929763036479296 tensor(129.3846)\n",
      "16.77325404936775 16.77325404936775 -314.6864686349597 0.04836613582426319 tensor(128.5101)\n",
      "16.406529513135684 16.406529513135684 -315.33481299805953 0.03521242915409219 tensor(127.1174)\n",
      "16.369176558777458 16.369176558777458 -314.9198447576889 0.03285627897828036 tensor(126.9372)\n",
      "16.507301355298495 16.507301355298495 -314.7661865586903 0.0862566360188317 tensor(127.4757)\n",
      "16.158335930590493 16.158335930590493 -314.43805497661384 0.02465363990407861 tensor(126.1125)\n",
      "16.93231343368777 16.93231343368777 -314.32256543033594 0.03453163043820632 tensor(129.1124)\n",
      "16.141132560831377 16.141132560831377 -313.20830964308885 0.018085928650386943 tensor(126.0563)\n",
      "15.618588885942811 15.618588885942811 -313.79630956449745 0.015918443179760475 tensor(124.0052)\n",
      "15.971275863443486 15.971275863443486 -312.834788171007 0.019715004306773393 tensor(125.3914)\n",
      "15.992565578366772 15.992565578366772 -313.11158371906913 0.01594318238619075 tensor(125.4451)\n",
      "14.964014600791888 14.964014600791888 -313.6677100160614 0.022176159307730956 tensor(121.3318)\n",
      "15.750774531879037 15.750774531879037 -311.71036891970795 0.030745943134505477 tensor(124.5059)\n",
      "15.083344933336203 15.083344933336203 -313.3463487934959 0.016276425722217946 tensor(121.8229)\n",
      "15.220726121100087 15.220726121100087 -312.65961362579486 0.01979057335821653 tensor(122.3762)\n",
      "14.54159754175651 14.54159754175651 -313.8240587217725 0.040898223114060724 tensor(119.6405)\n",
      "15.013916184011673 15.013916184011673 -312.5066899991483 0.016252241511934794 tensor(121.5553)\n",
      "14.449251596337955 14.449251596337955 -312.3532137779842 0.05558157446050955 tensor(119.2398)\n",
      "14.592520218600148 14.592520218600148 -311.2200520512669 0.03174744970672056 tensor(119.8461)\n",
      "14.127900477699463 14.127900477699463 -312.87383723137106 0.036650787650826605 tensor(117.8872)\n",
      "14.4680033934206 14.4680033934206 -311.2889395447599 0.12141622570008734 tensor(119.3120)\n",
      "13.969540374292377 13.969540374292377 -311.5972493046795 0.024936299112597392 tensor(117.2301)\n",
      "13.381459308560158 13.381459308560158 -312.09522936731025 0.035592760564946924 tensor(114.6937)\n",
      "14.042746592009637 14.042746592009637 -310.69124009098937 0.05388130007794939 tensor(117.5780)\n",
      "14.001188668887693 14.001188668887693 -311.0107704352859 0.020702439123767007 tensor(117.3477)\n",
      "13.518939438760386 13.518939438760386 -311.48455329645356 0.018521163183897082 tensor(115.2754)\n",
      "13.58916931726144 13.58916931726144 -310.6444450967677 0.018376175658206217 tensor(115.5768)\n",
      "14.116998718918971 14.116998718918971 -309.49751673305116 0.01647429279250367 tensor(117.8379)\n",
      "13.018209326703245 13.018209326703245 -310.41151894173385 0.030218913994930104 tensor(113.1162)\n",
      "12.688211971550638 12.688211971550638 -311.56248684204 0.05388818873571639 tensor(111.6182)\n",
      "13.403532792991232 13.403532792991232 -310.15664316357567 0.029148079564780906 tensor(114.7477)\n",
      "12.958580832126168 12.958580832126168 -310.0015163743378 0.02084168248313515 tensor(112.8863)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.009517298151831 13.009517298151831 -309.56884817605516 0.02295520505408384 tensor(113.0542)\n",
      "13.144325807431873 13.144325807431873 -309.32251728352537 0.020842333623546448 tensor(113.6733)\n",
      "13.035029344437012 13.035029344437012 -309.4694201366011 0.0775134300486318 tensor(113.1695)\n",
      "12.53797674384126 12.53797674384126 -308.5255957202083 0.026206231087198852 tensor(111.0059)\n",
      "12.458744035060564 12.458744035060564 -307.71903256805024 0.01680695848751508 tensor(110.6865)\n",
      "12.828874297272916 12.828874297272916 -308.2911372681497 0.023990594704324866 tensor(112.2857)\n",
      "12.154067392536254 12.154067392536254 -309.25290861185056 0.03259338328569028 tensor(109.2751)\n",
      "12.497425346803494 12.497425346803494 -306.4734808546465 0.05326524846558484 tensor(110.8241)\n",
      "12.121203929423121 12.121203929423121 -308.2776705269762 0.03326609600935348 tensor(109.0797)\n",
      "12.089815614075984 12.089815614075984 -308.0969273621632 0.017238037130384545 tensor(108.9841)\n",
      "10.806682009773917 10.806682009773917 -309.2003603377648 0.02935355639542111 tensor(102.9864)\n",
      "12.121168992381369 12.121168992381369 -306.96915533941115 0.032980518956706915 tensor(109.1108)\n",
      "11.56220180749991 11.56220180749991 -307.9154701375584 0.043969932371767044 tensor(106.5267)\n",
      "13.00996933428535 13.00996933428535 -305.2524506663042 0.0389075938059974 tensor(113.1177)\n",
      "== Era 1 | Epoch 0 metrics ==\n",
      "\tloss 18.0972\n",
      "\tforce 18.0972\n",
      "\tdkl -315.853\n",
      "\tlogp 85.823\n",
      "\tlogq -230.03\n",
      "\tess 0.0348523\n",
      "12.03905720135592 12.03905720135592 -306.76734441883474 0.05351453092942067 tensor(108.7484)\n",
      "11.738098984866705 11.738098984866705 -306.3705253752671 0.053884169206254134 tensor(107.3939)\n",
      "11.387734523897768 11.387734523897768 -307.322592647217 0.027598761063898417 tensor(105.6932)\n",
      "11.135953754219694 11.135953754219694 -307.11827316444953 0.018862957974555093 tensor(104.5223)\n",
      "11.400411808212 11.400411808212 -305.75289436162336 0.026419825482914685 tensor(105.8278)\n",
      "11.667277192157758 11.667277192157758 -306.44787232447516 0.03879877476881715 tensor(107.0528)\n",
      "11.643951551417333 11.643951551417333 -304.8717696838885 0.0982040921538993 tensor(106.9005)\n",
      "10.846485366654647 10.846485366654647 -306.5412500499996 0.02177587434329768 tensor(103.1650)\n",
      "10.673037696946409 10.673037696946409 -307.03124985869835 0.07272021295032595 tensor(102.2882)\n",
      "11.025078458536829 11.025078458536829 -306.0940059944006 0.028436434468414675 tensor(103.9615)\n",
      "10.493698353033679 10.493698353033679 -305.5660946672814 0.024726738323691887 tensor(101.4432)\n",
      "10.417809049202013 10.417809049202013 -306.0217907384614 0.02528084870856702 tensor(101.0074)\n",
      "10.963002946400524 10.963002946400524 -304.7585226838426 0.01723674414588961 tensor(103.7189)\n",
      "10.932551988385447 10.932551988385447 -305.16181906341376 0.04235553882020536 tensor(103.5650)\n",
      "11.187583402718518 11.187583402718518 -303.975962809766 0.0506973705034615 tensor(104.7722)\n",
      "10.834080800660224 10.834080800660224 -304.2585924564883 0.02217706575938887 tensor(103.1396)\n",
      "12.113244060393969 12.113244060393969 -303.2308745533545 0.01942740787664968 tensor(109.0426)\n",
      "10.742832781852194 10.742832781852194 -303.49029859185976 0.04470927553242714 tensor(102.6719)\n",
      "11.603948373607011 11.603948373607011 -302.4811039864306 0.058012834889423374 tensor(106.6962)\n",
      "10.689257370999178 10.689257370999178 -303.5258875853613 0.057259407840460824 tensor(102.3451)\n",
      "10.995895739323434 10.995895739323434 -304.46550779346325 0.03901266688295913 tensor(103.8353)\n",
      "10.01086309298097 10.01086309298097 -304.7734912404411 0.07397146713013666 tensor(99.0120)\n",
      "9.935206887257129 9.935206887257129 -304.2922341978492 0.03395355768991701 tensor(98.6209)\n",
      "10.900427057618156 10.900427057618156 -303.42161237226867 0.06727516784104755 tensor(103.3700)\n",
      "11.23478455902087 11.23478455902087 -303.28661229615204 0.10615313382989366 tensor(104.9287)\n",
      "10.993491176845946 10.993491176845946 -303.1433559366559 0.03471053112421256 tensor(103.7869)\n",
      "10.650858412572418 10.650858412572418 -302.679623750376 0.017016085929121558 tensor(102.1124)\n",
      "11.244193600140775 11.244193600140775 -301.9095455881454 0.03201509559927584 tensor(105.0354)\n",
      "10.349269554732745 10.349269554732745 -302.8293889377638 0.01574660840513242 tensor(100.7126)\n",
      "11.110351439650083 11.110351439650083 -303.3850681492253 0.054568185750547955 tensor(104.3841)\n",
      "10.83164273302606 10.83164273302606 -302.28668160509676 0.02373922702151579 tensor(102.9443)\n",
      "10.414786980345074 10.414786980345074 -302.9262599461647 0.03951752614360702 tensor(100.9727)\n",
      "10.928189048261693 10.928189048261693 -301.4009113112796 0.024009062827828435 tensor(103.4820)\n",
      "11.35191652789264 11.35191652789264 -300.90658634584975 0.021044450711492926 tensor(105.5269)\n",
      "11.288810537163922 11.288810537163922 -301.7675174357333 0.07274251015831953 tensor(105.1653)\n",
      "9.952063385353776 9.952063385353776 -302.90077455363974 0.016711482575309137 tensor(98.6414)\n",
      "10.650152604619525 10.650152604619525 -301.5522333146695 0.05941465765789126 tensor(102.0647)\n",
      "10.808444077947145 10.808444077947145 -301.41947538103796 0.023555558912930787 tensor(102.8474)\n",
      "11.551372970987158 11.551372970987158 -301.2245399693845 0.03971166048056604 tensor(106.4158)\n",
      "11.118785494117681 11.118785494117681 -301.4480549608419 0.015984270321675258 tensor(104.2657)\n",
      "10.405670244796914 10.405670244796914 -301.94184382926517 0.07137693228681961 tensor(100.8538)\n",
      "9.743103258722298 9.743103258722298 -303.0315769372648 0.04958568248207256 tensor(97.4957)\n",
      "10.345789246320331 10.345789246320331 -300.9964936335964 0.0270717392383841 tensor(100.4585)\n",
      "10.79673738955424 10.79673738955424 -300.8523011121473 0.04029537662962296 tensor(102.7273)\n",
      "10.811620878454494 10.811620878454494 -301.0179516564788 0.01940803289803945 tensor(102.6918)\n",
      "10.649404868515118 10.649404868515118 -300.5884055279989 0.03525143991844036 tensor(102.0583)\n",
      "11.464718339679731 11.464718339679731 -301.04217188430067 0.03631455543255818 tensor(105.7510)\n",
      "10.992977770900499 10.992977770900499 -300.4604876455786 0.01716252208349047 tensor(103.7148)\n",
      "10.719272753587768 10.719272753587768 -301.3080007500896 0.03623620005732018 tensor(102.2172)\n",
      "11.909893471905438 11.909893471905438 -300.1915679096428 0.02969829882242041 tensor(107.8729)\n",
      "10.627870672821894 10.627870672821894 -301.8739182927494 0.015973045999443655 tensor(101.6666)\n",
      "11.564579747205329 11.564579747205329 -300.518073399149 0.016692371076769498 tensor(106.3771)\n",
      "11.215075374543288 11.215075374543288 -301.40161477157517 0.02453337722212861 tensor(104.6259)\n",
      "9.911146592742783 9.911146592742783 -302.4871445674288 0.07789186634708407 tensor(98.1888)\n",
      "11.374472099534938 11.374472099534938 -300.96991820153175 0.017460650103251273 tensor(105.2396)\n",
      "11.684452738150478 11.684452738150478 -300.0440385817813 0.029631481564286244 tensor(106.6626)\n",
      "11.673611773299388 11.673611773299388 -301.53677388588176 0.09489767758930923 tensor(106.6058)\n",
      "12.06462666257945 12.06462666257945 -298.94676734194314 0.022688356375738603 tensor(108.5887)\n",
      "13.061295359404854 13.061295359404854 -301.0345792795205 0.07288556179245076 tensor(112.6481)\n",
      "12.373621515267248 12.373621515267248 -299.90475301973896 0.07655258922993272 tensor(109.6349)\n",
      "12.314184415701812 12.314184415701812 -300.3462952154903 0.026861778810469295 tensor(109.5483)\n",
      "13.201067118996923 13.201067118996923 -301.1826724747799 0.04880934845152379 tensor(113.2177)\n",
      "12.431429582432253 12.431429582432253 -300.7305861846978 0.1017970673591011 tensor(109.9431)\n",
      "11.911166858781304 11.911166858781304 -301.4425859312207 0.052405290040404076 tensor(107.7160)\n",
      "12.130025741750337 12.130025741750337 -300.97433458337184 0.05448157096140768 tensor(108.4617)\n",
      "13.02172959150805 13.02172959150805 -300.6038615573549 0.03298178619367992 tensor(112.4988)\n",
      "13.19920659237058 13.19920659237058 -300.6950423485514 0.03063123395707275 tensor(113.0082)\n",
      "13.033619904548965 13.033619904548965 -301.159431023721 0.02419944669581476 tensor(112.3388)\n",
      "12.286670249350387 12.286670249350387 -301.458925734542 0.02723800679514185 tensor(108.6965)\n",
      "13.517463931058526 13.517463931058526 -300.98980526338715 0.08216740520780297 tensor(114.6169)\n",
      "14.633597684548777 14.633597684548777 -301.19961402858496 0.031910521341541785 tensor(118.8750)\n",
      "13.562298405089535 13.562298405089535 -301.09884424872814 0.023238716049632863 tensor(114.5466)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.1950742795009 17.1950742795009 -300.3809682395894 0.018798142279514943 tensor(128.8142)\n",
      "16.586543326954015 16.586543326954015 -301.09909198766985 0.03644359916797689 tensor(126.7845)\n",
      "14.966017056882498 14.966017056882498 -301.97647155671586 0.0354412521795978 tensor(120.1424)\n",
      "16.20105645907035 16.20105645907035 -301.04257765612573 0.01651509306785345 tensor(124.9642)\n",
      "15.913252370453009 15.913252370453009 -302.0116778646428 0.039363673419194355 tensor(124.1844)\n",
      "18.02482124113124 18.02482124113124 -301.4853181661258 0.016110428166420773 tensor(131.8740)\n",
      "16.333901354846862 16.333901354846862 -302.8924691465151 0.03169177237015928 tensor(125.2017)\n",
      "17.26626051809003 17.26626051809003 -301.26428201288934 0.02507109899157521 tensor(128.6958)\n",
      "16.03562904976514 16.03562904976514 -302.9059297992959 0.08735869540297513 tensor(124.1890)\n",
      "15.95982375499482 15.95982375499482 -302.36641187346163 0.07673066490139471 tensor(123.6649)\n",
      "18.906658143866064 18.906658143866064 -302.1328158426803 0.03314728199754047 tensor(134.9051)\n",
      "17.216494238098118 17.216494238098118 -301.7742555458885 0.020300937388247283 tensor(128.3227)\n",
      "19.106416329192832 19.106416329192832 -301.8233234238103 0.06043601008467636 tensor(135.3293)\n",
      "17.710924441022037 17.710924441022037 -302.34652591232935 0.017965459552112716 tensor(130.3775)\n",
      "18.901136683914988 18.901136683914988 -302.6501490643891 0.054361574696677455 tensor(133.9208)\n",
      "18.07452416424786 18.07452416424786 -302.38663220428884 0.024671638545922255 tensor(131.2913)\n",
      "21.868027825822747 21.868027825822747 -303.76959801243356 0.02777856987839701 tensor(143.9940)\n",
      "19.939136285400707 19.939136285400707 -303.78091083237484 0.05600586420195519 tensor(137.5632)\n",
      "20.717741783249743 20.717741783249743 -303.8652019680116 0.029395963563614142 tensor(140.7743)\n",
      "19.566804896772876 19.566804896772876 -303.1360411743327 0.025343442047924054 tensor(136.8026)\n",
      "20.598630783625687 20.598630783625687 -303.927921939487 0.025535761755209444 tensor(139.7508)\n",
      "22.993640784141302 22.993640784141302 -302.89273994994693 0.025058411723263008 tensor(147.8319)\n",
      "20.840563848109344 20.840563848109344 -303.22902645052 0.03196409965470534 tensor(140.7947)\n",
      "22.21823592330837 22.21823592330837 -304.7301711145956 0.04214428666995248 tensor(145.6018)\n",
      "23.432605500070423 23.432605500070423 -304.78152901152873 0.025440832866282372 tensor(148.6075)\n",
      "23.162885143982013 23.162885143982013 -305.37558642672303 0.01713367625270949 tensor(148.3969)\n",
      "25.625441168904327 25.625441168904327 -304.47327866598357 0.040150728083706975 tensor(155.8122)\n",
      "25.687376080113637 25.687376080113637 -304.84735279896597 0.05905158245545044 tensor(155.3785)\n",
      "== Era 2 | Epoch 0 metrics ==\n",
      "\tloss 13.5954\n",
      "\tforce 13.5954\n",
      "\tdkl -302.702\n",
      "\tlogp 85.9118\n",
      "\tlogq -216.79\n",
      "\tess 0.0396069\n",
      "25.74488423465281 25.74488423465281 -304.55275308133554 0.056897389277794516 tensor(156.0886)\n",
      "24.69269499880835 24.69269499880835 -306.20612853485216 0.03382793919886848 tensor(152.2785)\n",
      "26.020143832022082 26.020143832022082 -305.1306455311716 0.06051428784101445 tensor(155.8108)\n",
      "26.049949776072527 26.049949776072527 -304.50580977845823 0.04050263921151531 tensor(156.4979)\n",
      "24.963569424582936 24.963569424582936 -304.7699233865378 0.03411587202141911 tensor(153.8705)\n",
      "27.02463016940088 27.02463016940088 -306.4443508678983 0.046839256672528994 tensor(158.1111)\n",
      "28.871980067956965 28.871980067956965 -305.13639134107314 0.018658594716803232 tensor(163.9860)\n",
      "26.016560012861774 26.016560012861774 -305.45248590564864 0.02407817546753185 tensor(156.1366)\n",
      "31.368406303241795 31.368406303241795 -305.4333084199942 0.032122448873031645 tensor(171.1148)\n",
      "29.751738158318883 29.751738158318883 -306.32666548889205 0.01764674306713675 tensor(167.1781)\n",
      "29.339223100671393 29.339223100671393 -306.28372719393155 0.07123048918434947 tensor(165.5490)\n",
      "28.749848388728562 28.749848388728562 -306.4534357346599 0.040461606868473624 tensor(164.2196)\n",
      "31.242729707761743 31.242729707761743 -306.7485509329364 0.09189155515265314 tensor(170.4685)\n",
      "33.67858456878559 33.67858456878559 -306.6791364313908 0.020168636617558963 tensor(177.9101)\n",
      "32.93616143195021 32.93616143195021 -307.58532828235 0.033339707749819265 tensor(175.0320)\n",
      "31.223845087275908 31.223845087275908 -307.4143943099084 0.030906272295724995 tensor(170.7197)\n",
      "31.49535765948469 31.49535765948469 -308.05043512137684 0.032762823847711835 tensor(170.2060)\n",
      "32.62532153034868 32.62532153034868 -309.17312840427024 0.07356586944199127 tensor(174.2227)\n",
      "33.59577281985968 33.59577281985968 -307.6768762236237 0.017548385957774672 tensor(174.8806)\n",
      "35.66405078048032 35.66405078048032 -307.2490279566462 0.0217519894790683 tensor(182.0681)\n",
      "34.018114959354975 34.018114959354975 -307.83489948511925 0.018846316512485185 tensor(177.7235)\n",
      "33.17175812693012 33.17175812693012 -307.3870888368245 0.024547966365766893 tensor(175.8104)\n",
      "33.64569734776032 33.64569734776032 -308.4885898023325 0.01577113903456045 tensor(176.3430)\n",
      "35.58554686409389 35.58554686409389 -308.92549210082785 0.02344096688299565 tensor(181.5498)\n",
      "32.435512083947195 32.435512083947195 -310.09095889911356 0.026720473667757497 tensor(172.9223)\n",
      "33.21318569871 33.21318569871 -307.95177157245803 0.016816426318222177 tensor(174.7399)\n",
      "34.429787154017475 34.429787154017475 -308.6631854308142 0.01936897962917015 tensor(178.8552)\n",
      "34.27927877106283 34.27927877106283 -309.83660129713445 0.03461108568641881 tensor(178.2021)\n",
      "35.59722707142403 35.59722707142403 -309.25043014950063 0.016808031070647527 tensor(181.5350)\n",
      "36.82994326957831 36.82994326957831 -308.04275412129675 0.03376929173810602 tensor(185.4237)\n",
      "36.88258336112781 36.88258336112781 -310.3854082203916 0.08075717996178189 tensor(185.8105)\n",
      "32.71329767306326 32.71329767306326 -309.24581157728016 0.020401481198016994 tensor(175.1546)\n",
      "35.47132791262745 35.47132791262745 -308.9218676324165 0.016188824532601672 tensor(181.6325)\n",
      "33.30310711389321 33.30310711389321 -309.82222035108776 0.14891214722020604 tensor(175.8846)\n",
      "37.09269776076689 37.09269776076689 -309.1468413183566 0.019026414188193022 tensor(185.9443)\n",
      "32.46478438908907 32.46478438908907 -309.3078674083762 0.029866920680980395 tensor(174.3059)\n",
      "34.395725475255745 34.395725475255745 -308.5172175241942 0.050744971875961775 tensor(179.9505)\n",
      "36.0828347747533 36.0828347747533 -310.0752066046238 0.05630042558327211 tensor(183.1434)\n",
      "36.233183801384875 36.233183801384875 -310.25791437458287 0.016146567164544386 tensor(183.2046)\n",
      "35.88713308421758 35.88713308421758 -310.476753988292 0.015814293436625382 tensor(183.2307)\n",
      "37.015407631616846 37.015407631616846 -307.9259879660101 0.023324899084851473 tensor(186.7504)\n",
      "38.90343363699841 38.90343363699841 -310.31106253026496 0.02063035664406783 tensor(190.1871)\n",
      "35.40687934343195 35.40687934343195 -310.9753830130155 0.037917989858461336 tensor(181.4311)\n",
      "35.36440569272015 35.36440569272015 -310.78848356556193 0.04001653811815649 tensor(180.9066)\n",
      "35.535392813229755 35.535392813229755 -309.7322231248568 0.06598016265561292 tensor(182.2113)\n",
      "34.18423050332478 34.18423050332478 -309.7659077670671 0.06558981423681898 tensor(178.1317)\n",
      "34.06513003964264 34.06513003964264 -309.9501958171301 0.02999353526631345 tensor(177.6166)\n",
      "38.56173702009095 38.56173702009095 -309.2309293017289 0.02973897002423517 tensor(189.6855)\n",
      "34.99472884725741 34.99472884725741 -310.70493439210696 0.023897543763172775 tensor(181.8746)\n",
      "35.44501004389193 35.44501004389193 -309.67729478169406 0.029848656833646143 tensor(180.5617)\n",
      "36.87269007025311 36.87269007025311 -310.30607347002075 0.05942316092583456 tensor(184.7257)\n",
      "34.71292762255731 34.71292762255731 -310.8169068780089 0.056004120813474924 tensor(180.3435)\n",
      "36.92970172895457 36.92970172895457 -310.4001235441327 0.01701944246708681 tensor(187.0438)\n",
      "34.16080256388629 34.16080256388629 -309.2171044146771 0.01571074760872759 tensor(178.4512)\n",
      "33.41605634603125 33.41605634603125 -309.45044045974043 0.023617836540150292 tensor(177.6121)\n",
      "34.04400573673921 34.04400573673921 -308.6080412479311 0.05516767873768177 tensor(178.4271)\n",
      "31.67324372877308 31.67324372877308 -309.27528457141693 0.020034856439349782 tensor(173.1238)\n",
      "33.12111311253765 33.12111311253765 -309.53328777499536 0.022678130267970945 tensor(176.2044)\n",
      "35.89123287682344 35.89123287682344 -309.4892863567011 0.041611653563819934 tensor(182.8912)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.35429699620677 35.35429699620677 -309.44301014785674 0.0243454032887555 tensor(182.2585)\n",
      "38.863100078561736 38.863100078561736 -309.4482762827648 0.043294395329799014 tensor(191.3257)\n",
      "37.21088919406989 37.21088919406989 -310.04823623395305 0.017376955480751313 tensor(186.8121)\n",
      "31.79659083495742 31.79659083495742 -308.16741739219106 0.01683312082929542 tensor(172.8128)\n",
      "36.6395714488692 36.6395714488692 -308.61567090146536 0.06606079056073691 tensor(183.3813)\n",
      "31.81777167971699 31.81777167971699 -309.4214985995179 0.01729362995133938 tensor(172.2053)\n",
      "35.108514327720776 35.108514327720776 -309.57791530253974 0.03585271883948045 tensor(180.0924)\n",
      "34.46002990477125 34.46002990477125 -310.15044766897154 0.038331615698732405 tensor(178.7407)\n",
      "32.34470350292456 32.34470350292456 -309.5443231926607 0.03439944299601824 tensor(173.3701)\n",
      "36.300631776551015 36.300631776551015 -308.80787133763357 0.01571988714123884 tensor(183.8771)\n",
      "37.44997248627826 37.44997248627826 -308.86459734469264 0.015735891664895082 tensor(185.4236)\n",
      "36.7874559783922 36.7874559783922 -309.5037670869039 0.028485758886863943 tensor(182.5820)\n",
      "33.566903429344244 33.566903429344244 -311.31580266829826 0.016016541753312855 tensor(176.5346)\n",
      "36.577720122708364 36.577720122708364 -308.8574071594651 0.01825680947124422 tensor(183.7902)\n",
      "36.80049426755076 36.80049426755076 -308.72433650243136 0.03515261598915382 tensor(183.7686)\n",
      "34.67591669365123 34.67591669365123 -308.56437837437045 0.02717000154043482 tensor(178.2405)\n",
      "37.20774700883825 37.20774700883825 -309.78169948925625 0.016278450197280882 tensor(184.1652)\n",
      "37.26821974648032 37.26821974648032 -310.70228177140984 0.0282345625834607 tensor(181.9729)\n",
      "37.59138858946961 37.59138858946961 -308.5201085175876 0.07868727862720407 tensor(185.5265)\n",
      "36.506156581277466 36.506156581277466 -308.8952056974834 0.01563799811151874 tensor(182.8305)\n",
      "32.556286937772676 32.556286937772676 -310.245610181597 0.04421681089779755 tensor(174.1115)\n",
      "36.09915832814932 36.09915832814932 -309.3617201153825 0.03840184880019356 tensor(179.5289)\n",
      "34.878622448000726 34.878622448000726 -308.86071751886874 0.024242214711205117 tensor(179.3312)\n",
      "33.65467869687167 33.65467869687167 -310.3672139575749 0.038201607994763104 tensor(175.8932)\n",
      "32.796374079623014 32.796374079623014 -309.9842526634302 0.03600778626504937 tensor(173.2213)\n",
      "31.994080407428378 31.994080407428378 -309.0261484856415 0.016213136418329197 tensor(172.5428)\n",
      "34.43590429956144 34.43590429956144 -309.033505446839 0.066597555597123 tensor(177.5252)\n",
      "33.46159846864101 33.46159846864101 -309.53141626739546 0.030401719532672067 tensor(175.5644)\n",
      "36.78459026856849 36.78459026856849 -308.42655129599797 0.017412119135036513 tensor(182.6340)\n",
      "34.78027222994189 34.78027222994189 -309.36377158067677 0.03264255670179271 tensor(178.6227)\n",
      "34.78517726771247 34.78517726771247 -308.4218249782642 0.01985087322802506 tensor(179.1387)\n",
      "33.1543726341247 33.1543726341247 -310.1835916253036 0.015935765827221043 tensor(172.8440)\n",
      "35.04981099930919 35.04981099930919 -307.94815290592055 0.018114641725133954 tensor(179.3976)\n",
      "31.149520064544777 31.149520064544777 -308.7045656107042 0.03263761335224617 tensor(169.5198)\n",
      "28.824204974147282 28.824204974147282 -310.43880002758533 0.015695184396514045 tensor(163.7624)\n",
      "30.47412566408457 30.47412566408457 -307.793635990962 0.01585785912616902 tensor(169.0237)\n",
      "35.06399165127156 35.06399165127156 -309.3973811670546 0.03821270991436701 tensor(179.0112)\n",
      "32.970292619029 32.970292619029 -308.23384401735615 0.017921718392700323 tensor(173.3095)\n",
      "32.903527243853134 32.903527243853134 -308.554193784581 0.02129348349224281 tensor(173.8644)\n",
      "33.07836347429882 33.07836347429882 -310.0462905048146 0.01681051826094453 tensor(172.2150)\n",
      "36.18334496364957 36.18334496364957 -308.82565313584996 0.01815502859280103 tensor(182.4300)\n",
      "== Era 3 | Epoch 0 metrics ==\n",
      "\tloss 33.7449\n",
      "\tforce 33.7449\n",
      "\tdkl -308.758\n",
      "\tlogp 85.9002\n",
      "\tlogq -222.857\n",
      "\tess 0.0332588\n",
      "29.065534318044005 29.065534318044005 -307.6763129895004 0.02426472532409704 tensor(164.3827)\n",
      "32.280147869806434 32.280147869806434 -310.9254541344524 0.04243226922633768 tensor(171.5245)\n",
      "32.372156087516 32.372156087516 -309.3848206316869 0.042993193257500714 tensor(172.2325)\n",
      "34.42675792854573 34.42675792854573 -309.1183735642558 0.020848115190376323 tensor(177.6837)\n",
      "32.308565870874865 32.308565870874865 -309.675350368733 0.032209060945674724 tensor(172.9941)\n",
      "33.14452735451054 33.14452735451054 -308.71719134411126 0.016943826397277234 tensor(173.0821)\n",
      "34.75569509570344 34.75569509570344 -311.67462581061324 0.02189920032225456 tensor(178.3901)\n",
      "33.17663790088634 33.17663790088634 -310.25924873046114 0.03783071698796665 tensor(173.5466)\n",
      "34.22679647249673 34.22679647249673 -309.8538984682283 0.051281053138718016 tensor(176.7092)\n",
      "33.8779692059334 33.8779692059334 -309.296154527426 0.019514415630231874 tensor(175.9632)\n",
      "34.12142687450443 34.12142687450443 -310.0700727698789 0.08190555200869296 tensor(174.7396)\n",
      "33.645836325801504 33.645836325801504 -310.16248743275776 0.015640876888556487 tensor(175.3897)\n",
      "36.25976334557999 36.25976334557999 -309.73452518998306 0.06759796393977165 tensor(181.4576)\n",
      "31.668567703700376 31.668567703700376 -310.38619504591213 0.03338226133969922 tensor(170.7612)\n",
      "35.57779532862157 35.57779532862157 -309.8565590884079 0.02034861231787867 tensor(180.4240)\n",
      "35.852584039614335 35.852584039614335 -310.43658850768634 0.021593452527612456 tensor(180.0467)\n",
      "31.09765520327341 31.09765520327341 -309.4009895508997 0.03928429092039858 tensor(169.9030)\n",
      "38.01228665262399 38.01228665262399 -310.66038596593046 0.018405241856716194 tensor(184.7765)\n",
      "34.59982579740668 34.59982579740668 -310.20282012242933 0.016551762196317998 tensor(178.7583)\n",
      "37.434465637717786 37.434465637717786 -310.79440117734134 0.05165160939202711 tensor(183.5084)\n",
      "35.04568727319281 35.04568727319281 -311.01735401098813 0.01695388324054276 tensor(178.0329)\n",
      "35.140218566653694 35.140218566653694 -311.1934335330575 0.03432218195990146 tensor(180.2976)\n",
      "33.22299333243327 33.22299333243327 -311.859261098501 0.015636528593400832 tensor(174.0977)\n",
      "35.38382515233212 35.38382515233212 -311.2543100428482 0.022123995644532445 tensor(178.1083)\n",
      "35.405700854068115 35.405700854068115 -310.7638955814592 0.016954789615179617 tensor(179.6452)\n",
      "34.86258734692675 34.86258734692675 -310.7683173094996 0.022837377013306938 tensor(178.4801)\n",
      "37.934105858626076 37.934105858626076 -310.55486292109657 0.015670376671806423 tensor(185.6429)\n",
      "34.14154316404894 34.14154316404894 -312.37283879954714 0.03558295987828584 tensor(177.0925)\n",
      "33.94071930999063 33.94071930999063 -313.2703735178605 0.017751740517040537 tensor(175.4520)\n",
      "33.097308379014 33.097308379014 -309.6930115383923 0.031329434706204445 tensor(175.0103)\n",
      "36.88770135611905 36.88770135611905 -312.56117579411836 0.01775638370012403 tensor(182.4072)\n",
      "37.25369267171099 37.25369267171099 -313.2581647752079 0.0185647319654553 tensor(180.0756)\n",
      "40.74585469699861 40.74585469699861 -312.79769233073995 0.02151527478906885 tensor(186.9273)\n",
      "41.10306421944396 41.10306421944396 -312.01279288391527 0.022518709169540786 tensor(189.8655)\n",
      "37.34937355126233 37.34937355126233 -315.0997807611662 0.021345843276002804 tensor(181.2336)\n",
      "37.85451840318631 37.85451840318631 -310.4115553984448 0.018926153262371185 tensor(183.3448)\n",
      "37.26248161002743 37.26248161002743 -313.4309412626089 0.06412476985037086 tensor(181.4357)\n",
      "40.10391283596563 40.10391283596563 -314.45823204575345 0.018482905196543865 tensor(187.0971)\n",
      "39.798188097773725 39.798188097773725 -312.59083358887017 0.01988197527569372 tensor(187.0553)\n",
      "42.89561939153318 42.89561939153318 -312.81049469933464 0.01796076403736907 tensor(188.4656)\n",
      "39.2955653109845 39.2955653109845 -312.7212208656296 0.04092991632593874 tensor(188.1509)\n",
      "42.443020159837694 42.443020159837694 -315.0684681653797 0.018429778661197833 tensor(190.2741)\n",
      "45.29919068020986 45.29919068020986 -313.5533150602216 0.023288244118550093 tensor(199.7109)\n",
      "45.27951322755269 45.27951322755269 -312.25595080763827 0.03554928812606767 tensor(196.8621)\n",
      "43.39459775679161 43.39459775679161 -314.8599160363579 0.030440002766698816 tensor(192.2562)\n",
      "46.59388807341989 46.59388807341989 -313.5047221463136 0.04835694785349774 tensor(197.0749)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0503749247797 45.0503749247797 -315.2507622547365 0.051520419576561234 tensor(197.8630)\n",
      "44.48686161912643 44.48686161912643 -313.3129579933605 0.03517826725861532 tensor(195.9832)\n",
      "41.39164805193615 41.39164805193615 -313.4585500331968 0.03712566751817073 tensor(187.8514)\n",
      "43.12674010588215 43.12674010588215 -314.1976178385104 0.01695097952399715 tensor(192.6038)\n",
      "41.089460299644536 41.089460299644536 -315.84910682253934 0.025425626763451364 tensor(193.3237)\n",
      "42.90785973805504 42.90785973805504 -314.42229813320694 0.05627110783066065 tensor(197.1323)\n",
      "47.346610005043594 47.346610005043594 -315.5797255298402 0.024900452146717694 tensor(199.6550)\n",
      "43.27006133696745 43.27006133696745 -317.3404148080214 0.03341599882890113 tensor(194.3889)\n",
      "52.93393678286721 52.93393678286721 -316.8484975028126 0.03360927946728099 tensor(207.4920)\n",
      "47.768320750398246 47.768320750398246 -317.30574006998086 0.03230070831985299 tensor(203.3396)\n",
      "45.669868230247765 45.669868230247765 -316.05832950059465 0.018221541862925968 tensor(200.9146)\n",
      "51.09501940267049 51.09501940267049 -315.2313499570006 0.015667908740272272 tensor(209.8029)\n",
      "52.22992453284649 52.22992453284649 -316.4140461999607 0.03334407188315293 tensor(207.4875)\n",
      "48.47510423718611 48.47510423718611 -317.53713952082376 0.017047003101815075 tensor(209.0911)\n",
      "48.72508779553612 48.72508779553612 -317.9352523706677 0.044806930181332555 tensor(208.3271)\n",
      "47.85644090736137 47.85644090736137 -316.45769357814333 0.03366248614443903 tensor(211.5399)\n",
      "53.260956543387046 53.260956543387046 -318.6153306789797 0.021211307312910748 tensor(216.4080)\n",
      "54.37085626697931 54.37085626697931 -317.20600325051583 0.01587036925370526 tensor(215.9983)\n",
      "45.71550597808204 45.71550597808204 -317.6924488539365 0.01588143667891794 tensor(201.1273)\n",
      "49.502387624276906 49.502387624276906 -317.850524758585 0.015643872033719676 tensor(203.2773)\n",
      "47.65513605259585 47.65513605259585 -317.87114202854207 0.01601060311420047 tensor(206.0353)\n",
      "44.73593029582732 44.73593029582732 -318.41764615054865 0.01849989776272078 tensor(203.4995)\n",
      "48.26247232540274 48.26247232540274 -317.83276538096754 0.04614382079864953 tensor(208.8228)\n",
      "49.018915685475385 49.018915685475385 -317.627444425946 0.07677146817224943 tensor(208.4550)\n",
      "42.39045101269412 42.39045101269412 -316.51693014102364 0.020352806144313226 tensor(198.0464)\n",
      "45.532613295373274 45.532613295373274 -314.9264785170111 0.02604665113128851 tensor(203.8775)\n",
      "45.63609177123891 45.63609177123891 -316.38971672059677 0.06607879906028248 tensor(203.0899)\n",
      "45.406569548220695 45.406569548220695 -316.7624920084088 0.01562765434636414 tensor(201.3613)\n",
      "41.53711397802059 41.53711397802059 -318.91679020747006 0.04429141098392525 tensor(195.2202)\n",
      "44.94626861053225 44.94626861053225 -315.55080314999526 0.0648253533075358 tensor(203.7897)\n",
      "41.280008918580826 41.280008918580826 -316.8579979180397 0.045755632816634514 tensor(199.2670)\n",
      "44.04949247968524 44.04949247968524 -317.3883434284525 0.0338035458987689 tensor(202.1726)\n",
      "38.47624401389674 38.47624401389674 -317.47577495496677 0.04338431406037328 tensor(190.8698)\n",
      "39.190560502355495 39.190560502355495 -315.54094796306805 0.018649254241102933 tensor(189.4827)\n",
      "40.22402221688371 40.22402221688371 -315.5432789876373 0.015767167506232582 tensor(192.5917)\n",
      "37.957687120912816 37.957687120912816 -315.6100711648937 0.025824010596465042 tensor(190.3595)\n",
      "36.89547404552702 36.89547404552702 -315.40929477227115 0.06253912638732918 tensor(186.6137)\n",
      "35.240443914738485 35.240443914738485 -314.6266908116504 0.08942747794558865 tensor(181.8423)\n",
      "39.73664391957045 39.73664391957045 -314.50642915223335 0.10344563964119347 tensor(191.2573)\n",
      "37.664429871792294 37.664429871792294 -313.84668033397963 0.018485638464664594 tensor(188.2103)\n",
      "34.76218511286375 34.76218511286375 -314.0302631248803 0.016056645318274845 tensor(181.1719)\n",
      "36.992522615213524 36.992522615213524 -314.9616203821282 0.046808022237992 tensor(185.6303)\n",
      "35.52185769143955 35.52185769143955 -313.1751622709324 0.01565557351219844 tensor(183.5357)\n",
      "33.551032876573444 33.551032876573444 -313.1029067472046 0.024974948499723214 tensor(179.6526)\n",
      "35.03384808663638 35.03384808663638 -314.02071812670283 0.020594266370266692 tensor(181.7148)\n",
      "36.13440463994478 36.13440463994478 -313.67882142367256 0.02265901464500243 tensor(184.4413)\n",
      "31.09779035499809 31.09779035499809 -313.5422072449853 0.08083378382267382 tensor(172.7492)\n",
      "32.77927562967452 32.77927562967452 -313.75648140510975 0.02727577028944609 tensor(176.1769)\n",
      "32.87315149045614 32.87315149045614 -313.91094800081623 0.04562204845368756 tensor(176.0530)\n",
      "30.352142929678593 30.352142929678593 -312.93252475666725 0.018959918692922885 tensor(170.2438)\n",
      "30.79709438571506 30.79709438571506 -312.9626681168212 0.033813385122029346 tensor(172.5453)\n",
      "30.924610374081755 30.924610374081755 -311.9225596889448 0.015648945765310056 tensor(171.6367)\n",
      "29.230561331640146 29.230561331640146 -313.29105929508637 0.015972857566826346 tensor(167.1545)\n",
      "29.633265087981354 29.633265087981354 -312.72851541686737 0.028432876817631555 tensor(167.5263)\n",
      "== Era 4 | Epoch 0 metrics ==\n",
      "\tloss 39.3143\n",
      "\tforce 39.3143\n",
      "\tdkl -313.626\n",
      "\tlogp 85.7126\n",
      "\tlogq -227.914\n",
      "\tess 0.0318691\n",
      "30.914257649868883 30.914257649868883 -313.48744074300936 0.0932189817413123 tensor(170.7287)\n",
      "32.4106106163765 32.4106106163765 -312.0033411115836 0.01713646437339262 tensor(176.6914)\n",
      "29.272590587845173 29.272590587845173 -311.322496019134 0.018857625496463432 tensor(167.9914)\n",
      "31.669073606571843 31.669073606571843 -312.7890343737415 0.049182505511777094 tensor(174.6490)\n",
      "28.634292022343676 28.634292022343676 -311.6580177232561 0.015833963336479143 tensor(166.1871)\n",
      "26.482014351842466 26.482014351842466 -312.2489429052001 0.02701671617050771 tensor(160.6013)\n",
      "28.355315476935193 28.355315476935193 -312.5688986747069 0.032407842674925094 tensor(163.6200)\n",
      "27.594862414367473 27.594862414367473 -310.5900108236649 0.05132334128080498 tensor(163.3167)\n",
      "27.646013090249298 27.646013090249298 -310.7479124569671 0.01594322333695813 tensor(162.6863)\n",
      "28.79600411748659 28.79600411748659 -310.5012249495287 0.026152669518932962 tensor(166.2489)\n",
      "25.345078063284266 25.345078063284266 -311.1679275318102 0.015950886526692316 tensor(156.4574)\n",
      "30.62911449763053 30.62911449763053 -310.48877815967836 0.01631375471984371 tensor(171.6314)\n",
      "25.878457374349658 25.878457374349658 -310.37352086412494 0.05327873334399495 tensor(158.3326)\n",
      "25.65019623621468 25.65019623621468 -310.82696273282505 0.024026251889946837 tensor(157.4916)\n",
      "27.85724187362832 27.85724187362832 -310.99734130042407 0.03347095096233655 tensor(162.9839)\n",
      "26.13662321710047 26.13662321710047 -311.87450927948123 0.03646321621575294 tensor(158.6782)\n",
      "25.504544064982152 25.504544064982152 -311.67861763444296 0.04777958738878633 tensor(157.2594)\n",
      "29.030405970334122 29.030405970334122 -309.4835699796041 0.06844073550867286 tensor(167.4112)\n",
      "27.006794804429777 27.006794804429777 -311.21827103363535 0.0369163438181073 tensor(161.8262)\n",
      "27.664719408130622 27.664719408130622 -309.8270555247772 0.030216119872760766 tensor(163.1243)\n",
      "26.326550521646634 26.326550521646634 -306.9331343119281 0.017749072368322676 tensor(159.6187)\n",
      "25.902608498339752 25.902608498339752 -309.83252313623603 0.016231700555859863 tensor(159.0738)\n",
      "26.22135433318902 26.22135433318902 -310.24696475860304 0.03220309738505768 tensor(159.3503)\n",
      "25.93812434670237 25.93812434670237 -310.1829616227617 0.01818725189699741 tensor(158.9396)\n",
      "28.03068711743568 28.03068711743568 -310.49904715376346 0.0246730748500076 tensor(164.6433)\n",
      "28.985801375861506 28.985801375861506 -310.280451277482 0.035491779630484006 tensor(166.5768)\n",
      "26.29901561849808 26.29901561849808 -311.6665491554452 0.01722913250352975 tensor(159.5063)\n",
      "28.933430363631203 28.933430363631203 -310.6460438995857 0.058013927020358236 tensor(167.4700)\n",
      "25.311585019867913 25.311585019867913 -309.8764852454978 0.024722422675385845 tensor(156.6744)\n",
      "27.034941233245963 27.034941233245963 -310.9665807109378 0.016911080744086142 tensor(160.5728)\n",
      "27.880869314681995 27.880869314681995 -310.1080932135237 0.016038517194907304 tensor(163.4560)\n",
      "28.6950097797524 28.6950097797524 -309.7837710376856 0.016896979588001782 tensor(166.7216)\n",
      "27.42836904824134 27.42836904824134 -311.43411998234654 0.057279626734367865 tensor(163.2032)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.665706219857036 28.665706219857036 -310.7225036254682 0.01616279978166587 tensor(166.3245)\n",
      "28.807414044628743 28.807414044628743 -310.0172954560383 0.018465405212787705 tensor(169.0318)\n",
      "27.738665609914108 27.738665609914108 -311.45603862417204 0.054659857930243486 tensor(163.4161)\n",
      "30.826510014182347 30.826510014182347 -311.52465239370935 0.020131368071415405 tensor(172.3857)\n",
      "28.619654902453735 28.619654902453735 -311.74545093718905 0.016937443572485673 tensor(166.5080)\n",
      "28.689098849514288 28.689098849514288 -311.38031249925433 0.03027369128116943 tensor(166.7232)\n",
      "29.024080298414884 29.024080298414884 -310.2851840886251 0.02310738257491598 tensor(168.2898)\n",
      "29.788112519105063 29.788112519105063 -311.2054602321869 0.022887066548563133 tensor(170.2704)\n",
      "32.979183148661 32.979183148661 -311.9624475876771 0.02337092320016644 tensor(177.6737)\n",
      "29.39557202586504 29.39557202586504 -309.8032782208809 0.019687483380012454 tensor(168.9984)\n",
      "29.3943589586803 29.3943589586803 -312.827794099047 0.017581012736503334 tensor(167.2065)\n",
      "31.122054285532524 31.122054285532524 -310.8528561917625 0.018257835634518493 tensor(172.5982)\n",
      "34.76460629683599 34.76460629683599 -311.40984202519564 0.015631928874629844 tensor(182.1126)\n",
      "33.33145976554524 33.33145976554524 -311.9571275681464 0.020803315848532625 tensor(179.9247)\n",
      "29.164629530375773 29.164629530375773 -310.7293161068311 0.038619379410907796 tensor(168.2111)\n",
      "31.003854458804284 31.003854458804284 -311.66711177236914 0.025084651419349707 tensor(173.0062)\n",
      "33.952976186568954 33.952976186568954 -312.6381715067738 0.01639166677746447 tensor(177.6437)\n",
      "36.089375479454745 36.089375479454745 -311.0697266280396 0.04012397175662485 tensor(183.2642)\n",
      "34.33472118496005 34.33472118496005 -312.8411336834474 0.016847781664338042 tensor(174.6681)\n",
      "32.61832058045991 32.61832058045991 -310.41292127713353 0.02118282427138822 tensor(175.0286)\n",
      "36.36101381888671 36.36101381888671 -312.99346792696826 0.02686587750683996 tensor(181.9672)\n",
      "38.12236841146625 38.12236841146625 -313.6844177584993 0.06776022029957225 tensor(185.8400)\n",
      "33.978668604582786 33.978668604582786 -314.06686938474826 0.030662634488370054 tensor(176.5019)\n",
      "35.15452383125757 35.15452383125757 -314.184661493725 0.031057149819923267 tensor(180.3959)\n",
      "33.408863283829135 33.408863283829135 -314.66485303382905 0.06461890553954723 tensor(175.2512)\n",
      "37.57865714009947 37.57865714009947 -312.21661630642143 0.036715777160751806 tensor(185.3844)\n",
      "37.771371985647036 37.771371985647036 -313.3288046119203 0.06251592480763572 tensor(183.6108)\n",
      "36.56846312520212 36.56846312520212 -313.9664308940593 0.016675137347232832 tensor(181.4820)\n",
      "40.45780030627953 40.45780030627953 -313.41704648219724 0.026708249879846022 tensor(193.0825)\n",
      "42.39759082665657 42.39759082665657 -313.6203506386896 0.0178366916734479 tensor(192.5991)\n",
      "41.458104767430314 41.458104767430314 -314.6153502724872 0.021498831300597546 tensor(194.1178)\n",
      "41.12686839138331 41.12686839138331 -315.04544842041116 0.01572332658145265 tensor(194.3448)\n",
      "44.27811617527956 44.27811617527956 -315.3780684449131 0.028058625730940923 tensor(199.3376)\n",
      "44.16039407727099 44.16039407727099 -315.80757003987986 0.016219904696843583 tensor(192.5889)\n",
      "41.729969299533046 41.729969299533046 -313.8381535024908 0.03863769080957627 tensor(194.4727)\n",
      "42.961143993435556 42.961143993435556 -315.71874192861566 0.016587103141741395 tensor(195.1927)\n",
      "41.06920765755538 41.06920765755538 -314.55584639630644 0.015635033770780543 tensor(183.7254)\n",
      "41.528605336795195 41.528605336795195 -316.3786362683265 0.019087860321997205 tensor(186.6077)\n",
      "44.3704299264108 44.3704299264108 -316.49416672286225 0.04622278080008867 tensor(189.6031)\n",
      "50.67846100594315 50.67846100594315 -314.682522695946 0.027251054811879828 tensor(192.3773)\n",
      "48.0189811504378 48.0189811504378 -317.2151673724899 0.09526451173786381 tensor(195.2760)\n",
      "50.25116110683959 50.25116110683959 -315.8669783142666 0.036577537372251945 tensor(198.5700)\n",
      "52.001905538568124 52.001905538568124 -314.85685814182426 0.03127658364604933 tensor(197.7483)\n",
      "45.0514592842509 45.0514592842509 -316.7850606396637 0.023011700766926005 tensor(191.0863)\n",
      "53.021650192351 53.021650192351 -315.88428939110395 0.018753597805404764 tensor(196.0229)\n",
      "52.85048837466501 52.85048837466501 -314.9902701516061 0.023559220785697874 tensor(202.7001)\n",
      "50.31400558934565 50.31400558934565 -316.63192004336906 0.016262800502357743 tensor(196.9732)\n",
      "50.66744315681419 50.66744315681419 -314.95900232158806 0.016000144294132247 tensor(189.3726)\n",
      "47.31666921323715 47.31666921323715 -316.0195730072696 0.02104814056479157 tensor(198.5361)\n",
      "48.76496816763269 48.76496816763269 -314.8481717107884 0.020962581974963167 tensor(199.3606)\n",
      "41.8717020331917 41.8717020331917 -315.19625436908404 0.030387791647310192 tensor(196.5938)\n",
      "55.49729733503529 55.49729733503529 -315.4012442132106 0.020197512962151387 tensor(215.9533)\n",
      "52.20293604415919 52.20293604415919 -316.09922915057535 0.016514067792308497 tensor(205.9821)\n",
      "52.70411980924625 52.70411980924625 -315.64989485639717 0.018354989669337723 tensor(209.8719)\n",
      "60.51274993478573 60.51274993478573 -315.62680006785376 0.035455177318061235 tensor(224.2922)\n",
      "50.99924997171662 50.99924997171662 -315.0226167925897 0.029343433710398496 tensor(212.0353)\n",
      "60.40759041041744 60.40759041041744 -315.98224040086984 0.015926126737883302 tensor(208.6623)\n",
      "61.77351413087034 61.77351413087034 -315.19193090689646 0.04359507723397288 tensor(222.6968)\n",
      "54.62702621863484 54.62702621863484 -314.501831131043 0.018879487041686162 tensor(238.2080)\n",
      "67.4229033988564 67.4229033988564 -317.56373869534013 0.03208083069993309 tensor(238.0642)\n",
      "75.9752862008294 75.9752862008294 -316.7065129054147 0.02864762135904988 tensor(240.3040)\n",
      "68.14624909779478 68.14624909779478 -316.37259053058943 0.0459340412305942 tensor(239.9219)\n",
      "63.11521550964435 63.11521550964435 -316.7689578043302 0.043182389207922646 tensor(245.1738)\n",
      "78.30784779587333 78.30784779587333 -316.3999591693794 0.01775036855306004 tensor(252.9023)\n",
      "80.15222604036843 80.15222604036843 -314.5841254498638 0.021199730222742304 tensor(262.4354)\n",
      "80.87209854352264 80.87209854352264 -317.5331450785955 0.03587434740462841 tensor(266.3748)\n",
      "72.39768240104769 72.39768240104769 -316.1541184931725 0.057681727548742484 tensor(256.0668)\n",
      "== Era 5 | Epoch 0 metrics ==\n",
      "\tloss 39.1618\n",
      "\tforce 39.1618\n",
      "\tdkl -313.023\n",
      "\tlogp 85.8108\n",
      "\tlogq -227.212\n",
      "\tess 0.0297783\n",
      "71.52818467860114 71.52818467860114 -315.5595858096707 0.02827547134670244 tensor(275.3381)\n",
      "79.06312733654947 79.06312733654947 -318.03443561539154 0.036464777809164045 tensor(263.4044)\n",
      "87.13175924501458 87.13175924501458 -317.35065181399807 0.07579083182336593 tensor(255.0615)\n",
      "77.19815755774432 77.19815755774432 -316.5164465381348 0.028850062052887065 tensor(268.9156)\n",
      "71.48400905356459 71.48400905356459 -317.7938834321685 0.028099524483297757 tensor(253.2315)\n",
      "91.300817451859 91.300817451859 -317.33178347639495 0.029838203588826988 tensor(279.8632)\n",
      "96.2719193587473 96.2719193587473 -319.0222546357107 0.02326096696740754 tensor(289.5711)\n",
      "73.51697244823929 73.51697244823929 -318.49910825899485 0.021899578306541774 tensor(276.4213)\n",
      "86.64561595415566 86.64561595415566 -317.26678669116956 0.09222550672223183 tensor(281.9001)\n",
      "87.00443165732098 87.00443165732098 -319.5186537901465 0.032190433954361226 tensor(288.8200)\n",
      "92.92428337787953 92.92428337787953 -319.76265779665437 0.024513231322071165 tensor(291.3528)\n",
      "66.54382442774916 66.54382442774916 -321.08109781282934 0.027847403328955928 tensor(266.3097)\n",
      "67.9458402008049 67.9458402008049 -321.5336054202812 0.048601560306154847 tensor(266.5968)\n",
      "91.25482624851269 91.25482624851269 -320.8357118153694 0.015953720311877584 tensor(278.7412)\n",
      "83.40215671943105 83.40215671943105 -321.7311634526334 0.015973831376049477 tensor(276.5021)\n",
      "96.40562312222924 96.40562312222924 -320.3333807700018 0.03868867609655341 tensor(280.3161)\n",
      "86.87322788349141 86.87322788349141 -320.96184940616644 0.04385491122826771 tensor(262.2994)\n",
      "93.06794253919301 93.06794253919301 -321.9745887020294 0.044940064627311475 tensor(273.3075)\n",
      "80.95703259366583 80.95703259366583 -320.45032959293553 0.0250904455521662 tensor(249.7452)\n",
      "91.541937594543 91.541937594543 -320.78985040623195 0.019261374103957847 tensor(255.4431)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.63370145848394 80.63370145848394 -321.7941037193 0.08383641438267128 tensor(257.4823)\n",
      "93.92926239966253 93.92926239966253 -319.9509026116176 0.032339620359379435 tensor(257.3936)\n",
      "86.87167978159343 86.87167978159343 -320.97831850583844 0.03705830383363055 tensor(241.9349)\n",
      "71.69264790439364 71.69264790439364 -321.6852656308044 0.01630415082118613 tensor(246.9860)\n",
      "70.32155824389375 70.32155824389375 -320.0616075782882 0.01661250852837919 tensor(235.5833)\n",
      "74.0201816891283 74.0201816891283 -321.69650642360114 0.0443225174536213 tensor(241.6833)\n",
      "73.44863018614755 73.44863018614755 -318.9778896026628 0.04542662808671604 tensor(244.5254)\n",
      "75.18949280149442 75.18949280149442 -319.21320336154315 0.03184169959659128 tensor(250.2024)\n",
      "79.97491922107112 79.97491922107112 -321.3646861176413 0.018434647396538106 tensor(249.6901)\n",
      "85.46661567605835 85.46661567605835 -319.223448820679 0.027911253721062266 tensor(259.7973)\n",
      "79.34782271636779 79.34782271636779 -320.1823346962834 0.017749103369652235 tensor(244.4675)\n",
      "78.82528343432398 78.82528343432398 -321.53304003010476 0.0504991389847657 tensor(238.4050)\n",
      "80.32416239188476 80.32416239188476 -319.15000856354857 0.016406072497163002 tensor(248.2582)\n",
      "74.98606883135483 74.98606883135483 -317.2844414288553 0.027733116861275386 tensor(245.0733)\n",
      "77.38851817517148 77.38851817517148 -319.6656992380342 0.035507249674424715 tensor(246.3769)\n",
      "72.9983544784318 72.9983544784318 -318.73719238514565 0.03876497062172026 tensor(245.0814)\n",
      "84.56612982628518 84.56612982628518 -320.4080106565876 0.025387537606937335 tensor(257.1014)\n",
      "77.14305868899918 77.14305868899918 -321.0308164681095 0.028600519506191628 tensor(243.4395)\n",
      "70.9792033501095 70.9792033501095 -318.95939327929966 0.029903372422268457 tensor(243.2556)\n",
      "65.7379204960819 65.7379204960819 -320.1852908457481 0.016962898630019457 tensor(235.7771)\n",
      "81.27991919335632 81.27991919335632 -320.2915291080378 0.015909114853003854 tensor(250.8848)\n",
      "94.0065116278668 94.0065116278668 -319.7976543727108 0.06071217842165827 tensor(260.4968)\n",
      "93.7919186233771 93.7919186233771 -319.6665007749467 0.02930100669986642 tensor(275.9377)\n",
      "96.7888090968774 96.7888090968774 -320.1925552027535 0.0159207884643605 tensor(273.3710)\n",
      "110.980243300752 110.980243300752 -321.17209280991443 0.04170538111549482 tensor(278.8209)\n",
      "97.30221783678452 97.30221783678452 -320.40745129419304 0.037005393497914686 tensor(275.8412)\n",
      "114.83777152317239 114.83777152317239 -320.1436911579317 0.04501505657079788 tensor(276.3908)\n",
      "109.26920716227539 109.26920716227539 -320.0507588388077 0.024147149442431463 tensor(288.1735)\n",
      "109.12212120207782 109.12212120207782 -321.64256696659515 0.0619207054389993 tensor(275.5975)\n",
      "109.94945347605511 109.94945347605511 -319.9076522734395 0.022416415916599094 tensor(300.5091)\n",
      "109.67328328988556 109.67328328988556 -322.23115976928807 0.05433569101723573 tensor(298.2594)\n",
      "113.70796469930345 113.70796469930345 -319.83071291118057 0.01851559162275094 tensor(296.0001)\n",
      "118.25871502555292 118.25871502555292 -320.6192003925056 0.017877490753023115 tensor(312.5278)\n",
      "83.74057674994451 83.74057674994451 -320.7009720858114 0.016209301460454323 tensor(328.6786)\n",
      "113.87097576610225 113.87097576610225 -320.76769323669885 0.03215474256709429 tensor(330.1714)\n",
      "120.99966131269527 120.99966131269527 -321.0079069334414 0.06934555934386916 tensor(347.6492)\n",
      "107.97202642378103 107.97202642378103 -321.9109760492272 0.05270124810296325 tensor(379.6631)\n",
      "142.9767385804686 142.9767385804686 -321.66617749052574 0.017461830393772842 tensor(402.0169)\n",
      "116.89156762517456 116.89156762517456 -322.01023571989634 0.032156004814266455 tensor(419.3967)\n",
      "132.33054939996666 132.33054939996666 -322.17103700706645 0.039926971690640876 tensor(469.0968)\n",
      "118.46808111310436 118.46808111310436 -323.22474618630315 0.019140180942842193 tensor(522.5076)\n",
      "137.96422663009523 137.96422663009523 -322.67586629588936 0.015808531965915543 tensor(526.4820)\n",
      "156.47309635139223 156.47309635139223 -321.83446593904523 0.03718097474673359 tensor(568.8795)\n",
      "158.32297289120098 158.32297289120098 -324.55303625041444 0.016417502220101274 tensor(604.1912)\n",
      "204.0017688115324 204.0017688115324 -326.4910428372191 0.017550777694418766 tensor(654.7933)\n",
      "194.2553099666228 194.2553099666228 -325.4863816601887 0.04526901982059628 tensor(719.3383)\n",
      "196.61783940807712 196.61783940807712 -326.56258586010205 0.018406021120424092 tensor(819.2260)\n",
      "206.20886859943536 206.20886859943536 -326.6436738461462 0.027785883669426244 tensor(806.4161)\n",
      "236.932971425948 236.932971425948 -327.86836925676494 0.022282622082253532 tensor(897.8660)\n",
      "297.65811630337123 297.65811630337123 -328.25484562866245 0.02058481756689131 tensor(921.3543)\n",
      "265.0274670231656 265.0274670231656 -327.1477991319632 0.02307851991558045 tensor(949.0699)\n",
      "267.15446709438385 267.15446709438385 -328.8923676535967 0.028389972036541335 tensor(939.8956)\n",
      "238.45832611128566 238.45832611128566 -328.1427273975901 0.041778516834892886 tensor(934.4645)\n",
      "245.86553059206477 245.86553059206477 -330.476367885098 0.050387099558482924 tensor(1015.7059)\n",
      "312.25409003970435 312.25409003970435 -329.2191194270862 0.06259298775530778 tensor(911.6781)\n",
      "310.80036251034915 310.80036251034915 -330.6126435720201 0.015631440948017824 tensor(927.9518)\n",
      "252.87335476765 252.87335476765 -329.3945361315741 0.03478424819917025 tensor(934.2931)\n",
      "320.60529939214354 320.60529939214354 -329.80668045093904 0.01787427840999951 tensor(804.6239)\n",
      "270.660817061228 270.660817061228 -330.27674610171005 0.0156590284705532 tensor(774.4409)\n",
      "279.09423087804095 279.09423087804095 -329.4001676020276 0.036617591593550526 tensor(663.7902)\n",
      "222.79913390644808 222.79913390644808 -330.42719272968793 0.02890615752569366 tensor(554.0643)\n",
      "286.7309641152306 286.7309641152306 -330.44896875344705 0.051511938338056236 tensor(587.0403)\n",
      "217.51670519760347 217.51670519760347 -329.24330238810546 0.02361322668910254 tensor(509.1858)\n",
      "245.45398180447455 245.45398180447455 -327.9121256552078 0.016731266723059645 tensor(542.8510)\n",
      "215.27716047989912 215.27716047989912 -329.9599121318526 0.015626753264706725 tensor(515.2613)\n",
      "223.62088788889574 223.62088788889574 -327.79836878215764 0.02137480835959945 tensor(502.3544)\n",
      "223.2296158332344 223.2296158332344 -327.22380452155585 0.016096370566543432 tensor(491.6882)\n",
      "252.64142081281219 252.64142081281219 -328.10859350449505 0.04247911425702876 tensor(520.2295)\n",
      "236.71106184577178 236.71106184577178 -328.6854730935437 0.04228913876821955 tensor(492.0154)\n",
      "242.05874181916215 242.05874181916215 -325.9916305772234 0.021582155435595357 tensor(495.2015)\n",
      "188.99375802886794 188.99375802886794 -326.9376880478561 0.05493688116670936 tensor(437.6237)\n",
      "212.0382468528386 212.0382468528386 -327.00208182204034 0.01861858698181125 tensor(450.9151)\n",
      "200.8789955041498 200.8789955041498 -326.7240473777748 0.03363538079989794 tensor(438.1463)\n",
      "202.7321217621753 202.7321217621753 -325.4985391458489 0.0608800653187356 tensor(430.7564)\n",
      "189.4815861996338 189.4815861996338 -323.63878684056306 0.04832126453123077 tensor(430.9417)\n",
      "179.98843565469275 179.98843565469275 -325.5920766793894 0.021585793344210378 tensor(412.7657)\n",
      "173.5255106285193 173.5255106285193 -327.1134849850944 0.015627722494865676 tensor(413.2358)\n",
      "155.35132350954987 155.35132350954987 -324.9114705183201 0.01735742616703473 tensor(387.3092)\n",
      "145.31809593455867 145.31809593455867 -324.14321251219536 0.03132000348216579 tensor(380.4683)\n",
      "181.797795503181 181.797795503181 -325.2810509416687 0.025692839551279677 tensor(423.5296)\n",
      "== Era 6 | Epoch 0 metrics ==\n",
      "\tloss 142.695\n",
      "\tforce 142.695\n",
      "\tdkl -322.942\n",
      "\tlogp 85.7794\n",
      "\tlogq -237.163\n",
      "\tess 0.0322337\n",
      "172.24428913484897 172.24428913484897 -325.9907722411767 0.016089425895462084 tensor(407.7282)\n",
      "157.60111836041906 157.60111836041906 -324.56230762394 0.024765708460265757 tensor(392.8844)\n",
      "158.2955107736896 158.2955107736896 -324.9327227932239 0.020469149091662926 tensor(390.8538)\n",
      "132.15926492535166 132.15926492535166 -323.5285186382679 0.05010005643520635 tensor(362.8852)\n",
      "172.73055476005788 172.73055476005788 -323.21962540532115 0.01643205014589744 tensor(403.7092)\n",
      "151.8757053158261 151.8757053158261 -324.8236358673447 0.01571099894259562 tensor(377.2991)\n",
      "154.40597582693087 154.40597582693087 -325.18173647427693 0.018807597222319204 tensor(393.0513)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181.65608768570743 181.65608768570743 -323.47354436727284 0.045019551157424426 tensor(408.0710)\n",
      "155.12556107958767 155.12556107958767 -322.78427137797996 0.06257573112442112 tensor(408.0915)\n",
      "155.70709944210273 155.70709944210273 -322.19702026029216 0.04203302553759664 tensor(386.7660)\n",
      "154.2939438878576 154.2939438878576 -324.0813765313353 0.025152359792144658 tensor(389.1889)\n",
      "130.0926802616391 130.0926802616391 -321.81524742004854 0.018315291004942832 tensor(355.8395)\n",
      "136.7728301757141 136.7728301757141 -323.3256254430799 0.0198683622398773 tensor(384.4378)\n",
      "135.1534894513842 135.1534894513842 -322.886484779454 0.028554687286129705 tensor(372.9541)\n",
      "140.6655586488424 140.6655586488424 -322.35172329532105 0.035174959984422015 tensor(360.1203)\n",
      "141.79888153106856 141.79888153106856 -323.08621018318865 0.027008585033358692 tensor(376.5234)\n",
      "153.88782916348052 153.88782916348052 -323.11633541314416 0.017297137531767523 tensor(391.0686)\n",
      "135.27238321189066 135.27238321189066 -322.219090871224 0.021710336956230702 tensor(375.5348)\n",
      "153.8820119492011 153.8820119492011 -321.0338107754888 0.01619617248088211 tensor(383.2311)\n",
      "118.5979144351396 118.5979144351396 -321.56168600163323 0.07043926304943977 tensor(346.7783)\n",
      "140.69898753228182 140.69898753228182 -323.04133840305406 0.07498769682218746 tensor(367.0847)\n",
      "141.25407157462803 141.25407157462803 -321.8517728802508 0.019363900253174 tensor(381.4303)\n",
      "119.82317029356994 119.82317029356994 -323.4050818627903 0.03921673205440336 tensor(346.9544)\n",
      "117.2359257373095 117.2359257373095 -320.7891106323065 0.02121676858429118 tensor(342.9483)\n",
      "110.46995025686573 110.46995025686573 -323.72324339369425 0.01791043340161971 tensor(331.2718)\n",
      "133.3974621445637 133.3974621445637 -321.36443052021195 0.07746226718396408 tensor(376.0310)\n",
      "102.72468070241457 102.72468070241457 -322.7031683576422 0.03291111198009897 tensor(311.3927)\n",
      "117.90140884218577 117.90140884218577 -323.9428911978649 0.01840032558698144 tensor(351.7062)\n",
      "120.95462679061247 120.95462679061247 -321.1873254221949 0.06010439986908064 tensor(341.0702)\n",
      "109.80147986821544 109.80147986821544 -321.23511075151737 0.036514341649741426 tensor(323.9370)\n",
      "100.86723226529381 100.86723226529381 -320.53224980019615 0.025484142960581786 tensor(320.4161)\n",
      "116.0474655398271 116.0474655398271 -319.9406853904755 0.019710392301175807 tensor(329.9865)\n",
      "101.76429946707054 101.76429946707054 -319.530925115536 0.035302172917329996 tensor(313.7004)\n",
      "89.65746690173444 89.65746690173444 -321.0855729598402 0.02041558331439293 tensor(299.7296)\n",
      "108.34619259724838 108.34619259724838 -321.8979382703037 0.018305527754800585 tensor(328.3981)\n",
      "103.591947292147 103.591947292147 -320.28038160172014 0.02253127616206686 tensor(322.8324)\n",
      "109.76383363360058 109.76383363360058 -318.5941666686617 0.039448958605931506 tensor(325.2318)\n",
      "102.95158414940478 102.95158414940478 -319.9090931256452 0.05064627967482357 tensor(309.8857)\n",
      "95.45654936620402 95.45654936620402 -321.6696290685418 0.036405219569489 tensor(304.4696)\n",
      "87.50703043306582 87.50703043306582 -318.41104289686865 0.040418009623088426 tensor(293.8828)\n",
      "89.6092930069435 89.6092930069435 -319.34739156807177 0.030111207738629037 tensor(301.4031)\n",
      "88.71260586038612 88.71260586038612 -319.3587637730663 0.04592397529183568 tensor(297.4088)\n",
      "91.14109395280435 91.14109395280435 -320.7102053294682 0.035323307610512125 tensor(300.5492)\n",
      "95.13984998761067 95.13984998761067 -319.87822780451154 0.020751997185898274 tensor(304.9324)\n",
      "88.3665690482912 88.3665690482912 -319.17306662452233 0.02909726205067413 tensor(296.8282)\n",
      "84.04723090414161 84.04723090414161 -320.02883585858257 0.025043138636588302 tensor(286.0430)\n",
      "78.93681005981068 78.93681005981068 -319.43500306616113 0.017151407805315332 tensor(277.8349)\n",
      "98.16913044456508 98.16913044456508 -318.34395859188334 0.08551838940156418 tensor(312.8440)\n",
      "88.75918547964332 88.75918547964332 -319.6047130289898 0.01685161977976197 tensor(294.4990)\n",
      "89.29127907143669 89.29127907143669 -319.2895412390457 0.0454607812399573 tensor(293.7043)\n",
      "79.83574328741165 79.83574328741165 -319.4720633216036 0.027208243800417073 tensor(282.4841)\n",
      "92.95164949905 92.95164949905 -319.21179405803446 0.058629289830551545 tensor(301.0413)\n",
      "88.61943341084046 88.61943341084046 -319.7535852268654 0.02975691088367677 tensor(294.7657)\n",
      "78.33026768136934 78.33026768136934 -319.1054921760531 0.01828330170820174 tensor(278.2176)\n",
      "82.40596657429856 82.40596657429856 -320.32165091655526 0.021047917102754797 tensor(283.6654)\n",
      "78.35112731439668 78.35112731439668 -319.3052968499196 0.016677897970528044 tensor(278.1463)\n",
      "78.51945439540928 78.51945439540928 -319.0754136679167 0.044287416571026826 tensor(271.8117)\n",
      "76.35132443534785 76.35132443534785 -319.2871065017647 0.028853026399306602 tensor(274.8579)\n",
      "83.25823958051056 83.25823958051056 -319.684186436244 0.04436293150053535 tensor(282.4003)\n",
      "97.4143366880836 97.4143366880836 -319.15666209760957 0.0543332586095769 tensor(304.4149)\n",
      "77.05629898418304 77.05629898418304 -319.1266749484913 0.03911890401542207 tensor(277.2751)\n",
      "80.58982253298512 80.58982253298512 -320.247294727605 0.027615012558354222 tensor(280.8132)\n",
      "81.10131068323345 81.10131068323345 -319.310049399777 0.01891572397176192 tensor(282.3510)\n",
      "82.78022468734672 82.78022468734672 -318.3122223924464 0.06280311446561795 tensor(287.4571)\n",
      "79.2538802153878 79.2538802153878 -318.4074752782393 0.015760958460559957 tensor(278.9775)\n",
      "71.12003320561703 71.12003320561703 -319.9848862461283 0.016497360433243503 tensor(264.7721)\n",
      "79.42583539068944 79.42583539068944 -318.53363418126776 0.01665531257138327 tensor(279.2079)\n",
      "70.86083062754064 70.86083062754064 -318.5692484343814 0.04135095802900409 tensor(264.0536)\n",
      "79.58184609802484 79.58184609802484 -318.26697590228247 0.01613591348613566 tensor(279.4813)\n",
      "74.10434458148701 74.10434458148701 -317.6189945541127 0.022320478195835824 tensor(268.9024)\n",
      "76.28311046109246 76.28311046109246 -319.0961025680173 0.018506980377650806 tensor(275.1379)\n",
      "66.15264929608685 66.15264929608685 -319.5078538121361 0.048489778034415995 tensor(255.1080)\n",
      "82.16613504324503 82.16613504324503 -318.81031457560846 0.04801593452984978 tensor(287.6806)\n",
      "74.57662612383434 74.57662612383434 -318.3543812254682 0.019880293417485668 tensor(271.9939)\n",
      "73.4203854190438 73.4203854190438 -318.8033792794602 0.04881385048888495 tensor(268.1840)\n",
      "71.04856891667902 71.04856891667902 -318.8144601188035 0.046126173132340124 tensor(263.0744)\n",
      "74.84427827701654 74.84427827701654 -319.0965615467238 0.05233827935106228 tensor(272.3607)\n",
      "72.91436462805555 72.91436462805555 -317.9021557983141 0.03255596199767069 tensor(266.9168)\n",
      "72.5119515425652 72.5119515425652 -318.55476646922483 0.030685770730558407 tensor(267.4720)\n",
      "78.14123069770466 78.14123069770466 -318.1210492666848 0.041899946259164156 tensor(274.8328)\n",
      "77.65033749967787 77.65033749967787 -320.1554035541377 0.027322292489807776 tensor(275.3566)\n",
      "64.33300634956537 64.33300634956537 -317.662288005954 0.016209993348430412 tensor(253.8090)\n",
      "73.5446896422258 73.5446896422258 -319.26263486860427 0.06786178945154185 tensor(268.1216)\n",
      "62.927495756913785 62.927495756913785 -319.95754036382 0.04419868784220185 tensor(249.8730)\n",
      "78.076565979418 78.076565979418 -320.0684593430142 0.01573499400723569 tensor(277.8786)\n",
      "70.09977593692665 70.09977593692665 -317.2787523022921 0.04170971362828009 tensor(262.2778)\n",
      "74.52675341401451 74.52675341401451 -318.7188687629707 0.035358114190588354 tensor(269.6694)\n",
      "73.95254736060737 73.95254736060737 -318.21113179793423 0.023911192501877218 tensor(270.2666)\n",
      "69.02508822452344 69.02508822452344 -317.51758428590165 0.01609435356319138 tensor(257.2744)\n",
      "78.34909023051921 78.34909023051921 -319.37956886873957 0.033542029250885876 tensor(279.0809)\n",
      "69.48326717639846 69.48326717639846 -318.0946200829951 0.017066062605730997 tensor(262.8435)\n",
      "67.38389385583612 67.38389385583612 -318.5894967685015 0.05764054501530916 tensor(259.4764)\n",
      "71.54488291495873 71.54488291495873 -317.12165714693106 0.04387180475338994 tensor(266.1294)\n",
      "73.26578229503035 73.26578229503035 -319.7569282753177 0.037353935167450364 tensor(268.7491)\n",
      "75.72756616567246 75.72756616567246 -319.3293052452072 0.036441332102859644 tensor(273.0006)\n",
      "72.1730372538339 72.1730372538339 -317.7306913940187 0.03994521364672625 tensor(267.5873)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.4273730494417 79.4273730494417 -318.7759146044166 0.019853609200635405 tensor(280.2026)\n",
      "71.0194834346879 71.0194834346879 -318.66786138077623 0.016423150801170853 tensor(264.2678)\n",
      "68.89047978827622 68.89047978827622 -319.26151999400406 0.04181828671497601 tensor(260.9306)\n",
      "74.27185951222205 74.27185951222205 -317.4243042673273 0.027928298531312908 tensor(271.2451)\n",
      "== Era 7 | Epoch 0 metrics ==\n",
      "\tloss 99.1425\n",
      "\tforce 99.1425\n",
      "\tdkl -320.292\n",
      "\tlogp 85.9464\n",
      "\tlogq -234.346\n",
      "\tess 0.0331792\n",
      "76.70587507555432 76.70587507555432 -318.05710098431655 0.01667322302795106 tensor(275.5978)\n",
      "78.11218690104243 78.11218690104243 -317.66766468801984 0.018697585256455172 tensor(277.9992)\n",
      "73.72820878453487 73.72820878453487 -318.6173740349351 0.07366837406687728 tensor(269.7089)\n",
      "73.95378617606819 73.95378617606819 -320.4279857212785 0.07055327758134822 tensor(269.5216)\n",
      "69.4738971367191 69.4738971367191 -317.90371647725505 0.030587208108588587 tensor(262.0267)\n",
      "66.16230736777696 66.16230736777696 -316.93619347518444 0.04735304917862832 tensor(255.8641)\n",
      "67.71746606842257 67.71746606842257 -318.0592176032438 0.03576702702958666 tensor(259.2689)\n",
      "79.29393820310979 79.29393820310979 -317.2661530071983 0.05276909053777124 tensor(280.1862)\n",
      "71.9700592293772 71.9700592293772 -319.2417325447517 0.03428337058434008 tensor(266.5395)\n",
      "66.45667793422193 66.45667793422193 -316.6481531274746 0.024757479514639143 tensor(255.8459)\n",
      "65.45721050540212 65.45721050540212 -319.21123145140143 0.0952041282369602 tensor(254.8795)\n",
      "67.22213894964662 67.22213894964662 -317.4244785601118 0.05700267163147502 tensor(257.9888)\n",
      "74.55860786478193 74.55860786478193 -317.89665937646896 0.016288731195089026 tensor(271.3856)\n",
      "67.44566819762619 67.44566819762619 -316.8716355600514 0.02903216984490637 tensor(258.0305)\n",
      "68.90876422092214 68.90876422092214 -317.34197250707655 0.015685833252952253 tensor(261.2842)\n",
      "70.65818163350188 70.65818163350188 -318.2866945168388 0.04006922414112029 tensor(264.1306)\n",
      "72.08782853115392 72.08782853115392 -317.3633430810114 0.016759014925815482 tensor(267.0370)\n",
      "64.7888907975368 64.7888907975368 -319.11395753400274 0.07497109901426964 tensor(253.3970)\n",
      "60.86035698416565 60.86035698416565 -317.78922693308243 0.048681647542296584 tensor(245.7551)\n",
      "67.82615874525784 67.82615874525784 -317.5146577227523 0.024511665946240307 tensor(259.0351)\n",
      "64.03887672617661 64.03887672617661 -317.2877808853879 0.04182624476714376 tensor(251.2166)\n",
      "69.77579959473354 69.77579959473354 -317.19527632200135 0.04054157254059008 tensor(261.9700)\n",
      "69.29529836309517 69.29529836309517 -317.02249630712754 0.02202769620435819 tensor(259.0367)\n",
      "69.0686311933429 69.0686311933429 -315.59454406452653 0.04087871150872851 tensor(261.1180)\n",
      "83.7102935039523 83.7102935039523 -316.2703194115948 0.02650413499946719 tensor(284.2728)\n",
      "67.72946223660051 67.72946223660051 -317.17537391523985 0.03085449351006228 tensor(258.1380)\n",
      "58.882019113036385 58.882019113036385 -318.2146193791786 0.04514066270127116 tensor(242.4708)\n",
      "68.15283128862903 68.15283128862903 -318.71210034365356 0.01827523816291133 tensor(259.3879)\n",
      "65.82095075780826 65.82095075780826 -317.6418641366004 0.0854633513879709 tensor(256.8128)\n",
      "66.37624565133939 66.37624565133939 -317.78907972384184 0.016666136261906783 tensor(256.1187)\n",
      "74.65193744260016 74.65193744260016 -317.21046090376217 0.016437312695506627 tensor(271.9278)\n",
      "70.50068993203774 70.50068993203774 -316.8490523145857 0.044190108634118035 tensor(262.2614)\n",
      "70.26544339875387 70.26544339875387 -315.90233955246015 0.016957249081629825 tensor(265.4973)\n",
      "74.35153174150537 74.35153174150537 -317.48803426618883 0.021390663750145117 tensor(271.1848)\n",
      "69.95759715761051 69.95759715761051 -318.3838297468068 0.07137829570000113 tensor(264.1729)\n",
      "69.32129159229775 69.32129159229775 -318.51612937108666 0.020144165785544628 tensor(259.0703)\n",
      "70.86225305431248 70.86225305431248 -317.94076810693423 0.047758220309551964 tensor(261.0633)\n",
      "71.70149211674627 71.70149211674627 -318.27946265469086 0.03757807127254157 tensor(263.1445)\n",
      "67.76220100431385 67.76220100431385 -318.2559202356189 0.04552991239987591 tensor(255.7169)\n",
      "66.47865625485161 66.47865625485161 -317.63860763148216 0.04803067276326682 tensor(256.8119)\n",
      "72.53501587941476 72.53501587941476 -317.59409213765093 0.032655217387699484 tensor(265.4455)\n",
      "76.10786702803033 76.10786702803033 -318.22929076466784 0.05176545667449262 tensor(272.6476)\n",
      "64.52748318706661 64.52748318706661 -317.088194552003 0.03963730680959821 tensor(251.9716)\n",
      "69.90055045997724 69.90055045997724 -316.49070796480646 0.03238068165784515 tensor(263.5331)\n",
      "71.912153675528 71.912153675528 -316.48484370394175 0.036761626300298895 tensor(260.1746)\n",
      "70.2723110697339 70.2723110697339 -317.40633859457904 0.030886877989131492 tensor(263.5977)\n",
      "61.71769044958595 61.71769044958595 -318.29571166472925 0.015752671052348656 tensor(245.8001)\n",
      "68.60875596216661 68.60875596216661 -316.0042646227429 0.030308503753961217 tensor(258.5264)\n",
      "69.02060453231897 69.02060453231897 -317.7993960909931 0.06364720090128839 tensor(258.3974)\n",
      "73.72288332351842 73.72288332351842 -318.8315299018104 0.0834347673152018 tensor(262.3476)\n",
      "65.243805749215 65.243805749215 -316.61782937530415 0.016649457003255964 tensor(255.9756)\n",
      "61.50051514182087 61.50051514182087 -317.25579209317266 0.01746896696283914 tensor(246.3065)\n",
      "77.66792342920589 77.66792342920589 -318.7001008654523 0.05820749523131768 tensor(274.8081)\n",
      "71.17323185841401 71.17323185841401 -316.85842474760085 0.019754243798072287 tensor(263.2927)\n",
      "68.96618739834616 68.96618739834616 -316.45854029540027 0.015643783726429678 tensor(260.5486)\n",
      "69.75144746622993 69.75144746622993 -316.9210460375413 0.025440023808662 tensor(257.1296)\n",
      "74.95433399652475 74.95433399652475 -317.8476922774508 0.030161793135200062 tensor(264.5122)\n",
      "68.36722921119964 68.36722921119964 -317.17452342066196 0.01735751529774626 tensor(259.3094)\n",
      "70.21959886408273 70.21959886408273 -317.11040111956976 0.017550162640356595 tensor(257.3862)\n",
      "68.4061774122262 68.4061774122262 -317.0718438160436 0.019098157303255026 tensor(260.4522)\n",
      "73.5775370774043 73.5775370774043 -316.1134999771922 0.05542342123201085 tensor(265.2130)\n",
      "70.2302817885392 70.2302817885392 -317.51788391868774 0.041272900382937766 tensor(252.0072)\n",
      "63.93107499166574 63.93107499166574 -316.43051443879983 0.016654198676458017 tensor(252.5757)\n",
      "68.2258247049982 68.2258247049982 -318.0446859580907 0.046291699642082886 tensor(252.4500)\n",
      "71.3507216029896 71.3507216029896 -316.9220386412047 0.041109169196242676 tensor(262.5970)\n",
      "69.12506197405035 69.12506197405035 -318.2754388289168 0.018166787361789644 tensor(257.1651)\n",
      "71.65290251668044 71.65290251668044 -317.60313059051146 0.01626718844018093 tensor(268.2045)\n",
      "79.12333537981837 79.12333537981837 -318.8724986465534 0.03282346450937788 tensor(268.0755)\n",
      "69.22813518190989 69.22813518190989 -317.1949961700584 0.020808845587495815 tensor(256.1072)\n",
      "70.44308435798827 70.44308435798827 -316.4746847455027 0.02547050244326861 tensor(259.6154)\n",
      "76.0312069931229 76.0312069931229 -319.64510503315256 0.02960630236424474 tensor(276.2959)\n",
      "71.35411237682388 71.35411237682388 -317.21259715700444 0.018423658124923307 tensor(265.3966)\n",
      "74.15769009307935 74.15769009307935 -317.67302901596054 0.023209659311266406 tensor(275.1670)\n",
      "75.91974348965036 75.91974348965036 -318.99059890629366 0.027170919841892082 tensor(272.9843)\n",
      "73.5449653868053 73.5449653868053 -320.318179906685 0.022917707809792843 tensor(267.3835)\n",
      "76.88487712628638 76.88487712628638 -317.356169151381 0.015794223075033465 tensor(269.5455)\n",
      "76.72579849823143 76.72579849823143 -318.5610986290729 0.018452523060672885 tensor(278.6352)\n",
      "69.53632478548883 69.53632478548883 -318.84146732336535 0.03743984015919078 tensor(259.8872)\n",
      "68.10872720707916 68.10872720707916 -320.0453905592841 0.024577210532220294 tensor(250.8794)\n",
      "72.6696531933941 72.6696531933941 -317.4174418792644 0.08321433317349532 tensor(272.0477)\n",
      "75.22591592230022 75.22591592230022 -319.3129860453914 0.022438862063004092 tensor(271.1671)\n",
      "77.36857656727037 77.36857656727037 -317.7043132989211 0.019133728136341416 tensor(282.1570)\n",
      "80.92800810697238 80.92800810697238 -318.73966616151694 0.022192797477187765 tensor(278.1115)\n",
      "70.91695228966809 70.91695228966809 -318.4614691052211 0.04561877305518568 tensor(263.7733)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.74288480358658 82.74288480358658 -317.2621327873443 0.01622506634547729 tensor(277.2914)\n",
      "85.99712333859195 85.99712333859195 -318.6204254508401 0.05380546533297986 tensor(287.7774)\n",
      "76.80904345915064 76.80904345915064 -318.2623810209533 0.05065862122462366 tensor(273.8736)\n",
      "74.1363738046789 74.1363738046789 -319.6510503410915 0.01577946850353168 tensor(279.6327)\n",
      "97.52560455945566 97.52560455945566 -317.34839986656965 0.02002376881935342 tensor(301.7239)\n",
      "88.96878198141486 88.96878198141486 -317.714147514894 0.017438766551435576 tensor(298.7170)\n",
      "76.86626464391331 76.86626464391331 -319.5871053315606 0.01745455281142562 tensor(273.0981)\n",
      "74.48266370798734 74.48266370798734 -318.35380740854316 0.03521906030082006 tensor(265.4572)\n",
      "75.19791365641704 75.19791365641704 -318.3088258606043 0.04763871451653718 tensor(267.1702)\n",
      "66.34998948782567 66.34998948782567 -318.3620008048792 0.04038686444101792 tensor(258.6650)\n",
      "71.4511849554269 71.4511849554269 -318.69978020464083 0.05816223576693072 tensor(260.9016)\n",
      "74.19045134072094 74.19045134072094 -318.76716781067273 0.06295326394465717 tensor(274.0932)\n",
      "77.2929398281935 77.2929398281935 -319.13860779880923 0.016001708740622293 tensor(274.4433)\n",
      "78.1548157550884 78.1548157550884 -318.0801719211387 0.030316111670324577 tensor(280.1881)\n",
      "76.01230724532591 76.01230724532591 -319.45979943402443 0.022654299021104253 tensor(264.5118)\n",
      "78.24408766957961 78.24408766957961 -319.77773750486574 0.01563388760153343 tensor(276.9514)\n",
      "== Era 8 | Epoch 0 metrics ==\n",
      "\tloss 71.8735\n",
      "\tforce 71.8735\n",
      "\tdkl -317.864\n",
      "\tlogp 85.7954\n",
      "\tlogq -232.068\n",
      "\tess 0.0346028\n",
      "81.1319475486737 81.1319475486737 -318.5681879752851 0.03629555331745768 tensor(283.4693)\n",
      "79.3776248670409 79.3776248670409 -317.89567872525765 0.019622513157170993 tensor(270.8270)\n",
      "81.3352467206663 81.3352467206663 -317.95514317567904 0.016835114564072516 tensor(280.8543)\n",
      "72.6663731910319 72.6663731910319 -317.89497042463984 0.03907175308583358 tensor(266.5266)\n",
      "78.39024814839038 78.39024814839038 -318.07956456648583 0.0604746335031803 tensor(276.8734)\n",
      "80.8136741487502 80.8136741487502 -318.0177626899575 0.015726333869229156 tensor(274.2850)\n",
      "78.44886529428524 78.44886529428524 -317.15736438578585 0.045557809169912346 tensor(286.2564)\n",
      "95.71523661298593 95.71523661298593 -317.97505325738945 0.03643752831224694 tensor(294.7322)\n",
      "90.46919348366835 90.46919348366835 -318.03100525104566 0.042342853853915084 tensor(289.9866)\n",
      "86.53872701334471 86.53872701334471 -317.8751732474975 0.015670266350392953 tensor(277.6593)\n",
      "80.1608872764851 80.1608872764851 -319.69516103617417 0.043274066319490795 tensor(281.3522)\n",
      "79.00300040341587 79.00300040341587 -318.699437887849 0.025515690972489388 tensor(281.2943)\n",
      "75.69813611176977 75.69813611176977 -319.42383788103774 0.037145756603026756 tensor(283.0823)\n",
      "92.76239374755946 92.76239374755946 -318.9565611402027 0.02540209028496638 tensor(298.4622)\n",
      "83.4550514028589 83.4550514028589 -320.08006140851285 0.04287092110615473 tensor(288.4213)\n",
      "94.79426723547185 94.79426723547185 -319.87923463655613 0.06501405601023738 tensor(302.6688)\n",
      "83.14534008090179 83.14534008090179 -319.01555890129123 0.01630701445249034 tensor(295.4910)\n",
      "83.82343135612042 83.82343135612042 -319.6039680434993 0.01652836106982364 tensor(301.6123)\n",
      "96.72975209747217 96.72975209747217 -319.0277402394448 0.019012054159713198 tensor(305.3583)\n",
      "92.80421358347739 92.80421358347739 -319.00748427792223 0.015664751170402783 tensor(289.4967)\n",
      "95.02215751850599 95.02215751850599 -321.75692082364424 0.03283120096442401 tensor(308.7152)\n",
      "93.98405530163629 93.98405530163629 -320.4545404151916 0.015663277148061046 tensor(312.5716)\n",
      "104.08936909667906 104.08936909667906 -321.2601125576026 0.01635375348925651 tensor(299.7106)\n",
      "95.03411251633582 95.03411251633582 -320.75548903566107 0.021959623300080562 tensor(299.9610)\n",
      "98.8904164162008 98.8904164162008 -321.096688804677 0.01881055653810301 tensor(303.6043)\n",
      "100.90004909754529 100.90004909754529 -321.3846923355381 0.016251911009689236 tensor(320.6070)\n",
      "98.93149488190109 98.93149488190109 -322.0986852259455 0.031130992041626563 tensor(313.2129)\n",
      "115.62559249537979 115.62559249537979 -322.93509814138497 0.05089751620386783 tensor(329.0511)\n",
      "105.56062026188025 105.56062026188025 -321.83271915212583 0.01844018296942943 tensor(328.9027)\n",
      "115.14257752261227 115.14257752261227 -323.3687192534144 0.02888726335173867 tensor(319.3156)\n",
      "105.66477841865789 105.66477841865789 -325.2297234876357 0.028034136041374537 tensor(323.0100)\n",
      "111.40008252471874 111.40008252471874 -323.99642792918223 0.0318436706633178 tensor(319.7942)\n",
      "109.35328063988547 109.35328063988547 -324.90055701164005 0.017460493038606743 tensor(331.2911)\n",
      "109.43785225226226 109.43785225226226 -324.90514170938815 0.02954121759078761 tensor(327.8950)\n",
      "124.31755564893624 124.31755564893624 -324.74747823605395 0.02016905287888364 tensor(336.4115)\n",
      "120.43581316630804 120.43581316630804 -326.5513475927784 0.024834595629316898 tensor(342.6534)\n",
      "127.95710220419205 127.95710220419205 -328.1750829193985 0.03298196908392529 tensor(338.0772)\n",
      "119.90613775854145 119.90613775854145 -327.92854429324603 0.033380392168508195 tensor(322.5823)\n",
      "132.49887718508916 132.49887718508916 -327.3641733701772 0.023665729663499644 tensor(338.3278)\n",
      "135.23832655880034 135.23832655880034 -325.91644600816045 0.017073647087073332 tensor(362.1607)\n",
      "148.16857023524506 148.16857023524506 -328.4600635748783 0.017068539113721023 tensor(378.7976)\n",
      "142.21384287354985 142.21384287354985 -328.49343878110193 0.02338236354998399 tensor(360.4171)\n",
      "136.50269178428363 136.50269178428363 -330.39773749035885 0.016365289121288085 tensor(394.3086)\n",
      "139.82239183456068 139.82239183456068 -331.07319947628486 0.03432090833826562 tensor(380.0763)\n",
      "163.74746075014136 163.74746075014136 -329.8508011189515 0.031468876117200485 tensor(417.8991)\n",
      "171.99888708464835 171.99888708464835 -331.5773233357636 0.06784216878510793 tensor(418.0624)\n",
      "159.0346676012883 159.0346676012883 -331.29723528598265 0.038133404777620554 tensor(419.5717)\n",
      "193.82258958662865 193.82258958662865 -332.6635442091791 0.01584680239985366 tensor(438.5730)\n",
      "210.09524492734815 210.09524492734815 -332.0301170044276 0.017065007919916456 tensor(486.6075)\n",
      "248.6065534535465 248.6065534535465 -335.6809883107407 0.015631134951533183 tensor(522.6287)\n",
      "224.75604487297431 224.75604487297431 -333.470514933434 0.015866153256570287 tensor(534.5839)\n",
      "242.04510674590304 242.04510674590304 -337.10523907006086 0.017028333510201665 tensor(599.3769)\n",
      "285.77296250492 285.77296250492 -338.03856037758317 0.017320663362572052 tensor(638.1031)\n",
      "343.5272474652014 343.5272474652014 -338.02222703606725 0.040605770113796756 tensor(723.0727)\n",
      "320.7788905704865 320.7788905704865 -338.2610209810125 0.031094385647302266 tensor(782.9668)\n",
      "390.650349131926 390.650349131926 -339.78470419853505 0.03499087151283857 tensor(877.4488)\n",
      "497.3083469055936 497.3083469055936 -340.9303022599491 0.031238969697201056 tensor(955.8586)\n",
      "537.6301704778778 537.6301704778778 -344.32210833967997 0.018215398866655522 tensor(1049.2323)\n",
      "737.8642402095495 737.8642402095495 -344.2636078103412 0.01766003125891673 tensor(1174.3341)\n",
      "850.7183758869841 850.7183758869841 -348.332342729083 0.02263606314126135 tensor(1363.8961)\n",
      "792.2758549650084 792.2758549650084 -348.3642283993892 0.016352359384025742 tensor(1464.1921)\n",
      "946.1370628248094 946.1370628248094 -351.72226207032475 0.016731974506756793 tensor(1465.4848)\n",
      "929.6891996716922 929.6891996716922 -351.0731822155814 0.022183567815904647 tensor(1477.8237)\n",
      "858.9215956118337 858.9215956118337 -349.93632249553497 0.017735647382474178 tensor(1496.1183)\n",
      "840.7160417387928 840.7160417387928 -348.88328323141997 0.015629954760562278 tensor(1478.7292)\n",
      "780.6040292270986 780.6040292270986 -347.5979238198324 0.03603840417911036 tensor(1444.4732)\n",
      "690.8315080169899 690.8315080169899 -345.7729575167966 0.015631866462215836 tensor(1425.3866)\n",
      "683.8757080544462 683.8757080544462 -344.89721031131086 0.04622667186128508 tensor(1359.1150)\n",
      "813.0109033725115 813.0109033725115 -344.81731282685774 0.031236006557654378 tensor(1414.2862)\n",
      "694.9755887820446 694.9755887820446 -341.1051274318933 0.015628626591174317 tensor(1409.0637)\n",
      "607.9841308966254 607.9841308966254 -343.27737412600493 0.015628704479696477 tensor(1408.2557)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626.7233868574317 626.7233868574317 -337.36729207625706 0.019293629860757076 tensor(1412.7034)\n",
      "535.446528799626 535.446528799626 -337.91369129802183 0.038495076068937734 tensor(1231.3895)\n",
      "489.71455337312864 489.71455337312864 -335.6095387313769 0.021939974128057385 tensor(1237.6834)\n",
      "426.150472470369 426.150472470369 -334.0369309341992 0.015724482293290314 tensor(1090.7742)\n",
      "476.75774474507864 476.75774474507864 -333.5088935160295 0.015942482204443963 tensor(1058.9312)\n",
      "498.2129368254296 498.2129368254296 -334.11756547358436 0.029732072415502797 tensor(1118.3511)\n",
      "387.17725557713584 387.17725557713584 -329.3743623879847 0.015626432470939734 tensor(967.1091)\n",
      "386.96467865257284 386.96467865257284 -331.1445942459946 0.01778524344830195 tensor(940.8708)\n",
      "382.5078208701152 382.5078208701152 -328.9895116918243 0.04039735317903083 tensor(906.9559)\n",
      "374.6321528398615 374.6321528398615 -328.26740397922913 0.019492240990197154 tensor(928.9940)\n",
      "312.3595396743618 312.3595396743618 -327.06104198210676 0.04922218559905572 tensor(859.9154)\n",
      "375.1712697920516 375.1712697920516 -327.53986005583226 0.04044718005930781 tensor(1006.4942)\n",
      "340.9935828592472 340.9935828592472 -327.39545510226594 0.0242968590320556 tensor(897.4264)\n",
      "319.83442762113646 319.83442762113646 -327.1178265996033 0.028261383102214693 tensor(966.0086)\n",
      "331.38117022458255 331.38117022458255 -323.83833238823354 0.015674834801795625 tensor(840.6439)\n",
      "332.51651024583134 332.51651024583134 -326.6455927319052 0.016134906227683363 tensor(817.8423)\n",
      "317.16290592109283 317.16290592109283 -325.0988875519201 0.021911056710211367 tensor(777.2099)\n",
      "307.6080314717255 307.6080314717255 -324.058419137768 0.0185193239648092 tensor(770.8090)\n",
      "386.61358392343504 386.61358392343504 -323.59976648844486 0.03384087850217895 tensor(761.6226)\n",
      "308.69833147388334 308.69833147388334 -325.80373603968013 0.023130174333784267 tensor(822.7422)\n",
      "348.1369092589937 348.1369092589937 -322.1957040224179 0.01783846534757274 tensor(868.3333)\n",
      "339.6752294187741 339.6752294187741 -324.18414051330774 0.02361145923603574 tensor(732.5491)\n",
      "287.23268445069243 287.23268445069243 -324.03335775146803 0.016921390299222443 tensor(687.5776)\n",
      "301.46739568953956 301.46739568953956 -321.10115379129184 0.01873794094194082 tensor(697.6321)\n",
      "343.84242397688575 343.84242397688575 -321.78733110486667 0.024520572634866514 tensor(705.1773)\n",
      "333.28191626190267 333.28191626190267 -320.51021572832053 0.041134574060010615 tensor(671.6162)\n",
      "368.58001066610694 368.58001066610694 -322.64264499743354 0.03222931895781305 tensor(779.1281)\n",
      "295.1593970819249 295.1593970819249 -322.9932220740404 0.04355472509128082 tensor(681.4950)\n",
      "285.6788166955592 285.6788166955592 -320.4484325662593 0.019693216273203036 tensor(633.5503)\n",
      "== Era 9 | Epoch 0 metrics ==\n",
      "\tloss 295.104\n",
      "\tforce 295.104\n",
      "\tdkl -328.694\n",
      "\tlogp 85.6696\n",
      "\tlogq -243.024\n",
      "\tess 0.0266189\n",
      "367.20056982956726 367.20056982956726 -322.23321676162846 0.021854599612063628 tensor(710.0581)\n",
      "293.9479727002934 293.9479727002934 -322.1856627822194 0.01566629820860929 tensor(632.3445)\n",
      "346.5610520489652 346.5610520489652 -320.8660057193913 0.019531947483297785 tensor(656.4414)\n",
      "471.39340447923786 471.39340447923786 -322.2488346974198 0.04783755820012295 tensor(735.8880)\n",
      "444.01405982131257 444.01405982131257 -321.3341796679933 0.01579441781731317 tensor(730.8977)\n",
      "376.0502200016225 376.0502200016225 -321.1859776947354 0.030947466780569404 tensor(664.6793)\n",
      "425.92374220092483 425.92374220092483 -320.80781089598344 0.018653515626761194 tensor(738.2965)\n",
      "291.74653373358467 291.74653373358467 -321.6238519661302 0.01593826451284509 tensor(694.4270)\n",
      "322.6615986400496 322.6615986400496 -321.5588745371613 0.018279790528364547 tensor(720.1046)\n",
      "308.63464964620283 308.63464964620283 -320.0995851993117 0.025784491869155393 tensor(702.7733)\n",
      "376.28446193961474 376.28446193961474 -321.97070250675176 0.054431515623806 tensor(721.3535)\n",
      "329.05665105223034 329.05665105223034 -322.5429105101995 0.025052046069691525 tensor(743.3602)\n",
      "457.0518344037038 457.0518344037038 -320.1803133953482 0.019114258394447758 tensor(714.2470)\n",
      "331.1189359988132 331.1189359988132 -321.5889950037757 0.018827517534957802 tensor(749.7018)\n",
      "330.4006442825984 330.4006442825984 -321.9121435363363 0.053732083409596586 tensor(720.2231)\n",
      "318.91496601975507 318.91496601975507 -321.0247834137421 0.025570698072778567 tensor(646.6454)\n",
      "343.3749535845161 343.3749535845161 -324.18301378278693 0.016112771410034563 tensor(710.7976)\n",
      "408.40496421479185 408.40496421479185 -321.8676535006781 0.015677415245720968 tensor(708.5018)\n",
      "389.0110090228982 389.0110090228982 -321.1156517981766 0.024326507932651485 tensor(723.3343)\n",
      "440.6939793487405 440.6939793487405 -321.15180457487924 0.045179676958480915 tensor(788.9381)\n",
      "361.3915035813581 361.3915035813581 -322.2731224325305 0.02440019574086157 tensor(683.0477)\n",
      "463.52261452029904 463.52261452029904 -323.59985531766256 0.01571195416933893 tensor(742.3076)\n",
      "526.9074117426853 526.9074117426853 -323.8121219509901 0.01679711953397027 tensor(720.1336)\n",
      "439.13764084032584 439.13764084032584 -323.59640049210213 0.03316633982300916 tensor(764.0068)\n",
      "419.85975742924006 419.85975742924006 -323.00032116958056 0.01562556209453184 tensor(752.0314)\n",
      "510.0598794465151 510.0598794465151 -326.7650162384033 0.01576298625030427 tensor(837.1787)\n",
      "526.912762410664 526.912762410664 -324.7401656116088 0.015629949208855295 tensor(759.9400)\n",
      "722.1845949966868 722.1845949966868 -326.6549734946039 0.031012787565757646 tensor(896.3973)\n",
      "623.6755203119061 623.6755203119061 -326.3273032335262 0.017150841015529196 tensor(808.5050)\n",
      "685.3999865621925 685.3999865621925 -326.1833279669472 0.016047645121296812 tensor(895.6274)\n",
      "687.9014944693319 687.9014944693319 -326.61772472051507 0.01565545177658796 tensor(846.2002)\n",
      "787.935220584611 787.935220584611 -328.3440837281806 0.01563837200251169 tensor(1003.0470)\n",
      "798.0333242191743 798.0333242191743 -328.90478630771577 0.01658737893043484 tensor(1202.3249)\n",
      "1057.1985021670632 1057.1985021670632 -327.2066774139183 0.015851018380089205 tensor(1384.0644)\n",
      "805.9136767769439 805.9136767769439 -329.63530835202215 0.016938789717572515 tensor(1311.2743)\n",
      "900.7569507300221 900.7569507300221 -329.4022728973771 0.02383817256864346 tensor(1409.7518)\n",
      "956.4774932255569 956.4774932255569 -327.8947806443774 0.04508825389462014 tensor(1599.0007)\n",
      "1070.6359439846165 1070.6359439846165 -328.73055702035566 0.022967173619008612 tensor(1611.3336)\n",
      "998.709936521952 998.709936521952 -328.48414646900267 0.02476886435739627 tensor(1703.2405)\n",
      "971.3972842680037 971.3972842680037 -329.3030956689979 0.01563828870795407 tensor(1780.1068)\n",
      "1113.375396176487 1113.375396176487 -329.5117696325746 0.04448436154955116 tensor(1838.7805)\n",
      "1049.8078579216967 1049.8078579216967 -330.01701542982727 0.05246940625232735 tensor(1848.8172)\n",
      "1347.2962773221805 1347.2962773221805 -332.20020461409575 0.016239332654345778 tensor(2173.8425)\n",
      "995.4927254221568 995.4927254221568 -330.77787307331283 0.01666044349555362 tensor(2079.0831)\n",
      "1282.3709367699523 1282.3709367699523 -330.25955844995207 0.03126510330785709 tensor(2012.2743)\n",
      "1393.037549268971 1393.037549268971 -329.7615644093408 0.01562864035639898 tensor(2324.0582)\n",
      "1549.3325355067518 1549.3325355067518 -331.7777921428591 0.016115048431129562 tensor(2308.9980)\n",
      "1457.3835611898692 1457.3835611898692 -330.60176746438265 0.020199257077870854 tensor(2105.1450)\n",
      "1666.617788700601 1666.617788700601 -331.50139907098736 0.01745700360637066 tensor(2930.4067)\n",
      "1306.9005430789493 1306.9005430789493 -328.94664874700084 0.06417111125282919 tensor(2437.2606)\n",
      "1744.7147318087893 1744.7147318087893 -332.02147808975775 0.03060101055654968 tensor(2821.8998)\n",
      "1869.9963531000517 1869.9963531000517 -330.80346019562046 0.05613766523570418 tensor(3100.9342)\n",
      "1853.1454622816339 1853.1454622816339 -329.63072122086146 0.02446588223420953 tensor(3390.2606)\n",
      "2327.277688209774 2327.277688209774 -330.4225720445414 0.054022063074660176 tensor(2983.0715)\n",
      "2392.5793150074746 2392.5793150074746 -331.58912984181114 0.037999378784151217 tensor(2811.7413)\n",
      "2135.8020422666414 2135.8020422666414 -333.00556991169935 0.023865715400354103 tensor(3488.6638)\n",
      "3715.761285181119 3715.761285181119 -333.46497766330015 0.05671099377234981 tensor(4073.3840)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998.431829674206 3998.431829674206 -331.7322923991422 0.02403784415869733 tensor(3844.9855)\n",
      "5085.606012190049 5085.606012190049 -333.48727839120147 0.05287876052769839 tensor(4292.3186)\n",
      "4714.050596369251 4714.050596369251 -331.0224902957007 0.015784129707359516 tensor(4401.0227)\n",
      "5759.189270904075 5759.189270904075 -333.36919972814206 0.04969036948341942 tensor(4762.5804)\n",
      "5272.183558920063 5272.183558920063 -334.3072087616177 0.0156250091719157 tensor(5383.0500)\n",
      "4367.983791367229 4367.983791367229 -336.7480240684247 0.03273619429633967 tensor(5870.0304)\n",
      "5137.712593458661 5137.712593458661 -336.36943618622126 0.016920905531488662 tensor(6668.5153)\n",
      "4697.755637820138 4697.755637820138 -339.425695200841 0.0400388511256287 tensor(5686.7754)\n",
      "6518.90617715728 6518.90617715728 -336.939915781685 0.019000968422224096 tensor(8027.8045)\n",
      "4634.630899732005 4634.630899732005 -337.9641708094486 0.022934430341241367 tensor(8259.9521)\n",
      "4310.881377053196 4310.881377053196 -341.34003629509095 0.01568644836776072 tensor(6000.6836)\n",
      "5338.0537358690235 5338.0537358690235 -338.985723453424 0.025898952824878023 tensor(5940.8425)\n",
      "4248.9276520966405 4248.9276520966405 -340.54496989784076 0.020408622396807567 tensor(6610.7330)\n",
      "4453.05689231456 4453.05689231456 -339.70225384755975 0.02483524606807334 tensor(4699.5081)\n",
      "4510.377641965015 4510.377641965015 -339.68749842223485 0.016532182641752834 tensor(6334.8941)\n",
      "7380.105886424157 7380.105886424157 -338.1902296377582 0.017786232692426324 tensor(9408.1705)\n",
      "5491.104026261198 5491.104026261198 -338.1122456856425 0.02583366799777125 tensor(8214.9821)\n",
      "5570.751324288582 5570.751324288582 -337.3911595998806 0.03557537581397594 tensor(9585.5806)\n",
      "5929.459704155659 5929.459704155659 -336.13776164963565 0.01619902364129783 tensor(9449.6935)\n",
      "7105.1562107165355 7105.1562107165355 -337.5796474431842 0.019058635229815157 tensor(9883.2065)\n",
      "5194.748212783 5194.748212783 -336.77344085194403 0.018144581426266824 tensor(10232.1587)\n",
      "4649.787468632001 4649.787468632001 -337.15230867478306 0.023854577046560722 tensor(10768.7861)\n",
      "4574.69875596259 4574.69875596259 -333.36289784681765 0.04665078725522988 tensor(7284.7575)\n",
      "4203.248920355217 4203.248920355217 -337.3215646989398 0.01596687100150047 tensor(8508.7633)\n",
      "4309.102550381353 4309.102550381353 -334.04414432492257 0.01565659583422162 tensor(6159.7278)\n",
      "4280.053410915666 4280.053410915666 -333.01612367692945 0.016787926765931372 tensor(6674.4591)\n",
      "4725.058500466821 4725.058500466821 -335.0589102775019 0.016926750112068262 tensor(4650.4222)\n",
      "3607.263741827164 3607.263741827164 -334.26651131723145 0.016769835380439944 tensor(5763.6118)\n",
      "9116.854352973258 9116.854352973258 -336.46107823892135 0.015630966679454746 tensor(6021.1941)\n",
      "4285.654085607229 4285.654085607229 -335.0879810079864 0.015632968646276783 tensor(5580.3468)\n",
      "3932.530014600875 3932.530014600875 -333.0933153857196 0.043739727760901036 tensor(4072.3014)\n",
      "4112.68835981488 4112.68835981488 -333.81104217710663 0.03789812070170427 tensor(5001.6578)\n",
      "2948.5519308480775 2948.5519308480775 -332.6157008579229 0.015750355664057993 tensor(4328.3951)\n",
      "4132.907779494238 4132.907779494238 -331.34853612612307 0.01572074403084992 tensor(3884.1424)\n",
      "4872.016765735443 4872.016765735443 -330.8370965967323 0.019129690347474283 tensor(6649.0006)\n",
      "2779.720957231093 2779.720957231093 -330.9976042020173 0.03416145131223392 tensor(4282.9349)\n",
      "3315.103414202613 3315.103414202613 -329.7366490401903 0.02739777306082786 tensor(3811.7326)\n",
      "3587.6503267308176 3587.6503267308176 -329.14460971391765 0.017389800579661302 tensor(4278.9615)\n",
      "2977.942884581337 2977.942884581337 -330.28130043409516 0.029501978411978092 tensor(4205.0254)\n",
      "4195.353930401767 4195.353930401767 -329.51233074842 0.01941753022198757 tensor(3604.4149)\n",
      "3260.762241905315 3260.762241905315 -329.44123713077045 0.015646510978391176 tensor(5849.5773)\n",
      "3873.530233191089 3873.530233191089 -329.02605768043503 0.029944362417290264 tensor(4589.8048)\n",
      "Accept rate: 0.0107421875\n",
      "Topological susceptibility = 0.67 +/- 0.16\n",
      "... vs HMC estimate = 1.23 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "flow_model, flow_act = flow_train(param, with_force=True, pre_model=pre_flow_model)\n",
    "flow_eval(flow_model,flow_act)\n",
    "flow = flow_model['layers']\n",
    "# flow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(238.7274)\n",
      "tensor(144.2265)\n"
     ]
    }
   ],
   "source": [
    "def test_force(x = None):\n",
    "    model = flow_model\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "    if x == None:\n",
    "        pre_model = pre_flow_model\n",
    "        pre_layers, pre_prior = pre_model['layers'], pre_model['prior']\n",
    "        pre_xi = pre_prior.sample_n(1)\n",
    "        x = ft_flow(pre_layers, pre_xi)\n",
    "    xi = ft_flow_inv(layers, x)\n",
    "    f = ft_force(param, layers, xi)\n",
    "    f_s = torch.linalg.norm(f)\n",
    "    print(f_s)\n",
    "\n",
    "test_force()\n",
    "test_force(field_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latsize = (8, 8)\n",
      "volume = 64\n",
      "beta = 2.0\n",
      "trajs = 4\n",
      "tau = 0.3\n",
      "steps = 8\n",
      "seed = 1331\n",
      "nth = 2\n",
      "nth_interop = 2\n",
      "Initial configuration:  plaq: 0.6730993066920293  topo: -1.0\n",
      "plaq(x) 0.6730993066920293  force.norm 20.228018493084267\n",
      "Traj:    1  ACCEPT:  dH:  0.010293555  exp(-dH):  0.98975924   plaq:  0.70425209   topo:  0.0\n",
      "plaq(x) 0.7042520923127957  force.norm 18.926189663613435\n",
      "Traj:    2  ACCEPT:  dH:  0.0059908377  exp(-dH):  0.99402707   plaq:  0.75833399   topo:  0.0\n",
      "plaq(x) 0.7583339946270954  force.norm 18.513867027891838\n",
      "Traj:    3  ACCEPT:  dH: -0.0070925583  exp(-dH):  1.0071178    plaq:  0.72418522   topo:  0.0\n",
      "plaq(x) 0.7241852154893258  force.norm 19.360503196991594\n",
      "Traj:    4  ACCEPT:  dH: -0.0021589002  exp(-dH):  1.0021612    plaq:  0.7386098    topo:  0.0\n",
      "plaq(x) 0.7386097994599291  force.norm 19.821337880741375\n",
      "Traj:    5  ACCEPT:  dH: -0.0015942778  exp(-dH):  1.0015955    plaq:  0.71898587   topo:  0.0\n",
      "plaq(x) 0.7189858691427513  force.norm 20.164667252684573\n",
      "Traj:    6  ACCEPT:  dH:  0.0086254103  exp(-dH):  0.99141168   plaq:  0.71574735   topo:  0.0\n",
      "plaq(x) 0.715747353931008  force.norm 18.836941605184265\n",
      "Traj:    7  ACCEPT:  dH: -0.0021598477  exp(-dH):  1.0021622    plaq:  0.68001218   topo:  0.0\n",
      "plaq(x) 0.6800121783766959  force.norm 18.82019544836447\n",
      "Traj:    8  ACCEPT:  dH:  0.0022449581  exp(-dH):  0.99775756   plaq:  0.68720733   topo:  1.0\n",
      "plaq(x) 0.6872073270085157  force.norm 19.29807730710383\n",
      "Traj:    9  ACCEPT:  dH:  0.0021565985  exp(-dH):  0.99784573   plaq:  0.67640932   topo:  0.0\n",
      "plaq(x) 0.6764093214138505  force.norm 18.592368508111065\n",
      "Traj:   10  ACCEPT:  dH:  0.026945453  exp(-dH):  0.97341434   plaq:  0.76191777   topo:  0.0\n",
      "plaq(x) 0.7619177684100281  force.norm 15.580761791119684\n",
      "Traj:   11  ACCEPT:  dH: -0.00118881   exp(-dH):  1.0011895    plaq:  0.77383834   topo:  1.0\n",
      "plaq(x) 0.7738383381607303  force.norm 15.978649326520632\n",
      "Traj:   12  ACCEPT:  dH: -0.0081703008  exp(-dH):  1.0082038    plaq:  0.74818539   topo:  1.0\n",
      "plaq(x) 0.7481853889441678  force.norm 18.072721855257683\n",
      "Traj:   13  ACCEPT:  dH: -0.010723891  exp(-dH):  1.0107816    plaq:  0.72688179   topo:  1.0\n",
      "plaq(x) 0.7268817886184362  force.norm 19.77409339147007\n",
      "Traj:   14  ACCEPT:  dH: -0.010973319  exp(-dH):  1.0110337    plaq:  0.68991797   topo:  1.0\n",
      "plaq(x) 0.6899179693598416  force.norm 20.317768469228884\n",
      "Traj:   15  ACCEPT:  dH:  0.0075785554  exp(-dH):  0.99245009   plaq:  0.70544127   topo:  1.0\n",
      "plaq(x) 0.7054412662630198  force.norm 19.27032603927268\n",
      "Traj:   16  ACCEPT:  dH: -1.6444277e-05  exp(-dH):  1.0000164    plaq:  0.69374672   topo:  2.0\n",
      "Run times:  [0.03962799604050815, 0.034332819981500506, 0.03216097492258996, 0.025240272982046008]\n",
      "Per trajectory:  [0.009906999010127038, 0.008583204995375127, 0.00804024373064749, 0.006310068245511502]\n"
     ]
    }
   ],
   "source": [
    "field_run = run(param, field_run[0])\n",
    "field_run = torch.reshape(field_run,(1,)+field_run.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plaq(field) 0.6937467217995373\n",
      "tensor([-16.4901], grad_fn=<AddBackward0>) tensor([16.4901], grad_fn=<AddBackward0>)\n",
      "original_action tensor(2.2005, grad_fn=<AddBackward0>)\n",
      "eff_action tensor([-49.2896], grad_fn=<AddBackward0>)\n",
      "plaq(x) -0.11987797017477399  logJ tensor([-16.4901], grad_fn=<AddBackward0>)  force.norm 163.17526172583203\n",
      "plaq(y) 0.6937464660899486\n",
      "plaq(x) 0.6937467217995373  force.norm 19.321995366088096\n"
     ]
    }
   ],
   "source": [
    "flows = flow\n",
    "\n",
    "field = torch.clone(field_run)\n",
    "\n",
    "print(f'plaq(field) {action(param, field[0]) / (-param.beta*param.volume)}')\n",
    "# field.requires_grad_(True)\n",
    "x = field\n",
    "logJ = 0.0\n",
    "for layer in reversed(flows):\n",
    "    x, lJ = layer.reverse(x)\n",
    "    logJ += lJ\n",
    "\n",
    "# x is the prior distribution now\n",
    "    \n",
    "x.requires_grad_(True)\n",
    "    \n",
    "y = x\n",
    "logJy = 0.0\n",
    "for layer in flows:\n",
    "    y, lJ = layer.forward(y)\n",
    "    logJy += lJ\n",
    "    \n",
    "s = action(param, y[0]) - logJy\n",
    "\n",
    "print(logJ,logJy)\n",
    "\n",
    "\n",
    "# print(\"eff_action\", s + 136.3786)\n",
    "\n",
    "print(\"original_action\", action(param, y[0]) + 91)\n",
    "\n",
    "print(\"eff_action\", s + 56)\n",
    "\n",
    "s.backward()\n",
    "\n",
    "f = x.grad\n",
    "\n",
    "x.requires_grad_(False)\n",
    "\n",
    "print(f'plaq(x) {action(param, x[0]) / (-param.beta*param.volume)}  logJ {logJ}  force.norm {torch.linalg.norm(f)}')\n",
    "\n",
    "print(f'plaq(y) {action(param, y[0]) / (-param.beta*param.volume)}')\n",
    "\n",
    "print(f'plaq(x) {action(param, field_run[0]) / (-param.beta*param.volume)}  force.norm {torch.linalg.norm(force(param, field_run[0]))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 8, 8])\n",
      "tensor(163.1753)\n",
      "tensor(163.1753)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x = ft_flow_inv(flow, field_run)\n",
    "# x = field_run\n",
    "#for layer in reversed(flows):\n",
    "#    x, lJ = layer.reverse(x)\n",
    "ff = ft_force(param, flow, x)\n",
    "print(torch.linalg.norm(ff))\n",
    "fff = ft_force(param, flow, x)\n",
    "print(torch.linalg.norm(fff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-105.2896], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ft_flow_inv(flow, field_run)\n",
    "ft_action(param, flow, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_leapfrog(param, flow, x, p):\n",
    "    dt = param.dt\n",
    "    x_ = x + 0.5*dt*p\n",
    "    f = ft_force(param, flow, x_)\n",
    "    p_ = p + (-dt)*f\n",
    "    print(f'force.norm {torch.linalg.norm(f)} ft_action {float(ft_action(param, flow, x_).detach())} pp_action {0.5*torch.sum(p_*p_)}')\n",
    "    for i in range(param.nstep-1):\n",
    "        x_ = x_ + dt*p_\n",
    "        f = ft_force(param, flow, x_)\n",
    "        # print(f'force.norm {torch.linalg.norm(f)} ft_action {float(ft_action(param, flow, x_).detach())} pp_action {0.5*torch.sum(p_*p_)}')\n",
    "        p_ = p_ + (-dt)*f\n",
    "    x_ = x_ + 0.5*dt*p_\n",
    "    return (x_, p_)\n",
    "\n",
    "def ft_hmc(param, flow, field):\n",
    "    x = ft_flow_inv(flow, field)\n",
    "    p = torch.randn_like(x)\n",
    "    act0 = ft_action(param, flow, x).detach() + 0.5*torch.sum(p*p)\n",
    "    x_, p_ = ft_leapfrog(param, flow, x, p)\n",
    "    xr = regularize(x_)\n",
    "    act = ft_action(param, flow, xr).detach() + 0.5*torch.sum(p_*p_)\n",
    "    prob = torch.rand([], dtype=torch.float64)\n",
    "    dH = act-act0\n",
    "    exp_mdH = torch.exp(-dH)\n",
    "    acc = prob < exp_mdH\n",
    "    # ADJUST ME\n",
    "    newx = xr if acc else x\n",
    "    # newx = xr\n",
    "    newfield = ft_flow(flow, newx)\n",
    "    return (float(dH), float(exp_mdH), acc, newfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_run(param, flow, field = param.initializer()):\n",
    "    with open(param.uniquestr(), \"w\") as O:\n",
    "        params = param.summary()\n",
    "        O.write(params)\n",
    "        put(params)\n",
    "        plaq, topo = (action(param, field) / (-param.beta*param.volume), topocharge(field))\n",
    "        status = f\"Initial configuration:  plaq: {plaq}  topo: {topo}\\n\"\n",
    "        O.write(status)\n",
    "        put(status)\n",
    "        ts = []\n",
    "        for n in range(param.nrun):\n",
    "            t = -timer()\n",
    "            for i in range(param.ntraj):\n",
    "                field_run = torch.reshape(field,(1,)+field.shape)\n",
    "                dH, exp_mdH, acc, field_run = ft_hmc(param, flow, field_run)\n",
    "                field = field_run[0]\n",
    "                plaq = action(param, field) / (-param.beta*param.volume)\n",
    "                topo = topocharge(field)\n",
    "                ifacc = \"ACCEPT\" if acc else \"REJECT\"\n",
    "                status = f\"Traj: {n*param.ntraj+i+1:4}  {ifacc}:  dH: {dH:< 12.8}  exp(-dH): {exp_mdH:< 12.8}  plaq: {plaq:< 12.8}  topo: {topo:< 3.3}\\n\"\n",
    "                O.write(status)\n",
    "                if (i+1) % (param.ntraj//param.nprint) == 0:\n",
    "                    put(status)\n",
    "            t += timer()\n",
    "            ts.append(t)\n",
    "        print(\"Run times: \", ts)\n",
    "        print(\"Per trajectory: \", [t/param.ntraj for t in ts])\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latsize = (8, 8)\n",
      "volume = 64\n",
      "beta = 2.0\n",
      "trajs = 4\n",
      "tau = 0.3\n",
      "steps = 8\n",
      "seed = 1331\n",
      "nth = 2\n",
      "nth_interop = 2\n",
      "Initial configuration:  plaq: 0.6937467217995373  topo: 2.0\n",
      "force.norm 27.69617606416228 ft_action -52.508123582432155 pp_action 64.60041730663544\n",
      "Traj:    1  ACCEPT:  dH: -0.11410416   exp(-dH):  1.1208689    plaq:  0.68258013   topo: -1.0\n",
      "force.norm 16.447812263770363 ft_action -52.44443526393059 pp_action 59.352502653638425\n",
      "Traj:    2  ACCEPT:  dH: -0.87384304   exp(-dH):  2.3961015    plaq:  0.58139032   topo:  1.0\n",
      "force.norm 20.116609343336297 ft_action -55.03639829945146 pp_action 62.855754350205906\n",
      "Traj:    3  ACCEPT:  dH: -0.23774691   exp(-dH):  1.2683881    plaq:  0.62613819   topo: -1.0\n",
      "force.norm 35.893419051851865 ft_action -53.659288588988986 pp_action 68.88548817263468\n",
      "Traj:    4  ACCEPT:  dH:  0.91658479   exp(-dH):  0.3998824    plaq:  0.58430707   topo: -1.0\n",
      "force.norm 45.50642162021287 ft_action -56.07181051740887 pp_action 70.36270051627473\n",
      "Traj:    5  REJECT:  dH:  1.0584521    exp(-dH):  0.3469925    plaq:  0.58430739   topo: -1.0\n",
      "force.norm 30.5713774138727 ft_action -56.77383653385608 pp_action 63.15877913273814\n",
      "Traj:    6  REJECT:  dH:  0.53150684   exp(-dH):  0.58771871   plaq:  0.58430759   topo: -1.0\n",
      "force.norm 31.10177463453468 ft_action -56.08618707600415 pp_action 67.87049932937327\n",
      "Traj:    7  REJECT:  dH:  38.939591    exp(-dH):  1.2267345e-17  plaq:  0.58430747   topo: -1.0\n",
      "force.norm 36.85226571626188 ft_action -55.75750175458765 pp_action 67.04755380695319\n",
      "Traj:    8  ACCEPT:  dH:  1.1332301    exp(-dH):  0.32199152   plaq:  0.69661413   topo:  2.0\n",
      "force.norm 24.638663327138566 ft_action -55.72296281619634 pp_action 57.24389242941193\n",
      "Traj:    9  REJECT:  dH:  1.1292141    exp(-dH):  0.32328724   plaq:  0.69661423   topo:  2.0\n",
      "force.norm 11.430335523475305 ft_action -56.13835353205272 pp_action 59.662143806287524\n",
      "Traj:   10  REJECT:  dH:  27.859165    exp(-dH):  7.9600993e-13  plaq:  0.69661424   topo:  2.0\n",
      "force.norm 8.377622763099406 ft_action -56.111771548776076 pp_action 67.63514132006003\n",
      "Traj:   11  REJECT:  dH:  4.1980806    exp(-dH):  0.015024386  plaq:  0.69661435   topo:  2.0\n",
      "force.norm 15.878200195177168 ft_action -56.02576010739652 pp_action 49.908902897193585\n",
      "Traj:   12  ACCEPT:  dH:  0.10828619   exp(-dH):  0.89737074   plaq:  0.74223212   topo:  0.0\n",
      "force.norm 7.672593962311596 ft_action -56.4000646358939 pp_action 72.07830651123362\n",
      "Traj:   13  ACCEPT:  dH: -1.1323377    exp(-dH):  3.1029016    plaq:  0.70625828   topo:  2.0\n",
      "force.norm 32.11406397511895 ft_action -54.896425778837276 pp_action 54.09952721801486\n",
      "Traj:   14  ACCEPT:  dH: -0.68830069   exp(-dH):  1.9903305    plaq:  0.74566519   topo:  0.0\n",
      "force.norm 9.814383842955445 ft_action -55.95738100963045 pp_action 66.18414835772609\n",
      "Traj:   15  ACCEPT:  dH: -1.2543832    exp(-dH):  3.5056756    plaq:  0.67855144   topo:  0.0\n",
      "force.norm 39.93845818909092 ft_action -54.11304191631129 pp_action 63.51883877850877\n",
      "Traj:   16  ACCEPT:  dH: -0.39539147   exp(-dH):  1.4849654    plaq:  0.6665683    topo: -1.0\n",
      "Run times:  [5.13177698396612, 5.501595259993337, 4.9344358620001, 5.583415016997606]\n",
      "Per trajectory:  [1.28294424599153, 1.3753988149983343, 1.233608965500025, 1.3958537542494014]\n"
     ]
    }
   ],
   "source": [
    "param = Param(\n",
    "    beta = 2.0,\n",
    "    lat = (8, 8),\n",
    "    tau = 0.3, # 0.3\n",
    "    nstep = 8, # 3\n",
    "    # ADJUST ME\n",
    "    ntraj = 4, # 2**16 # 2**10 # 2**15\n",
    "    #\n",
    "    nprint = 4,\n",
    "    seed = 1331)\n",
    "\n",
    "field_run = ft_run(param, pre_flow, field_run[0])\n",
    "field_run = torch.reshape(field_run,(1,)+field_run.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latsize = (8, 8)\n",
      "volume = 64\n",
      "beta = 2.0\n",
      "trajs = 4\n",
      "tau = 0.3\n",
      "steps = 8\n",
      "seed = 1331\n",
      "nth = 2\n",
      "nth_interop = 2\n",
      "Initial configuration:  plaq: 0.6665683039476181  topo: -1.0\n",
      "force.norm 307.9423040019176 ft_action -94.68608880721163 pp_action 102.85123465185504\n",
      "Traj:    1  REJECT:  dH:  442.48482    exp(-dH):  6.7808737e-193  plaq:  0.6665684    topo: -1.0\n",
      "force.norm 162.31905425742116 ft_action -97.04324594803019 pp_action 80.23882027527453\n",
      "Traj:    2  REJECT:  dH:  424.77143    exp(-dH):  3.3427981e-185  plaq:  0.66656831   topo: -1.0\n",
      "force.norm 101.61936938519396 ft_action -97.67048838705216 pp_action 65.61765389100694\n",
      "Traj:    3  REJECT:  dH:  403.71406    exp(-dH):  4.6688661e-176  plaq:  0.66656887   topo: -1.0\n",
      "force.norm 167.2469477034903 ft_action -92.25949067835325 pp_action 72.7943947867188\n",
      "Traj:    4  REJECT:  dH:  270.36149    exp(-dH):  3.8326354e-118  plaq:  0.66656869   topo: -1.0\n",
      "force.norm 302.6711325323761 ft_action -92.71316521527926 pp_action 113.13539241805272\n",
      "Traj:    5  REJECT:  dH:  505.78399    exp(-dH):  2.1918061e-220  plaq:  0.66656876   topo: -1.0\n",
      "force.norm 219.40515690393664 ft_action -89.37449513239498 pp_action 78.46589675705536\n",
      "Traj:    6  REJECT:  dH:  406.54888    exp(-dH):  2.7419748e-177  plaq:  0.66656889   topo: -1.0\n",
      "force.norm 162.67234850678807 ft_action -93.88018757596494 pp_action 77.76737469759084\n",
      "Traj:    7  REJECT:  dH:  631.98865    exp(-dH):  3.3948313e-275  plaq:  0.66656882   topo: -1.0\n",
      "force.norm 242.70520638992429 ft_action -90.97760673093265 pp_action 95.7665258980676\n",
      "Traj:    8  REJECT:  dH:  226.00132    exp(-dH):  7.0610904e-99  plaq:  0.66656898   topo: -1.0\n",
      "force.norm 1118.8144970692456 ft_action -75.94660034212566 pp_action 862.6659986885243\n",
      "Traj:    9  REJECT:  dH:  1298.5252    exp(-dH):  0.0          plaq:  0.66656912   topo: -1.0\n",
      "force.norm 249.26212593705057 ft_action -93.99350942737969 pp_action 82.28521316485049\n",
      "Traj:   10  REJECT:  dH:  382.77342    exp(-dH):  5.8025153e-167  plaq:  0.66656904   topo: -1.0\n",
      "force.norm 221.39954251072652 ft_action -91.57452902540983 pp_action 90.33380409989633\n",
      "Traj:   11  REJECT:  dH:  274.30308    exp(-dH):  7.4419181e-120  plaq:  0.66656935   topo: -1.0\n",
      "force.norm 244.6263181353045 ft_action -94.70854739707963 pp_action 89.58406415758746\n",
      "Traj:   12  REJECT:  dH:  364.09601    exp(-dH):  7.5008742e-159  plaq:  0.66656926   topo: -1.0\n",
      "force.norm 301.4704491873432 ft_action -92.67341302722929 pp_action 101.13356579278111\n",
      "Traj:   13  REJECT:  dH:  775.17805    exp(-dH):  0.0          plaq:  0.66656938   topo: -1.0\n",
      "force.norm 1296.8380815806913 ft_action -43.62673230102699 pp_action 1101.6793693763375\n",
      "Traj:   14  REJECT:  dH:  1245.8273    exp(-dH):  0.0          plaq:  0.66656952   topo: -1.0\n",
      "force.norm 148.06822537396528 ft_action -94.1243132548561 pp_action 82.80466448188756\n",
      "Traj:   15  REJECT:  dH:  282.67166    exp(-dH):  1.7268592e-123  plaq:  0.66656938   topo: -1.0\n",
      "force.norm 1312.5544554053504 ft_action -55.748561261258715 pp_action 1140.3888307715943\n",
      "Traj:   16  REJECT:  dH:  1947.137     exp(-dH):  0.0          plaq:  0.66656918   topo: -1.0\n",
      "Run times:  [5.480943328002468, 4.625209188903682, 5.296695461962372, 4.427037170971744]\n",
      "Per trajectory:  [1.370235832000617, 1.1563022972259205, 1.324173865490593, 1.106759292742936]\n"
     ]
    }
   ],
   "source": [
    "param = Param(\n",
    "    beta = 2.0,\n",
    "    lat = (8, 8),\n",
    "    tau = 0.3, # 0.3\n",
    "    nstep = 8, # 3\n",
    "    # ADJUST ME\n",
    "    ntraj = 4, # 2**16 # 2**10 # 2**15\n",
    "    #\n",
    "    nprint = 4,\n",
    "    seed = 1331)\n",
    "\n",
    "field_run = ft_run(param, flow, field_run[0])\n",
    "field_run = torch.reshape(field_run,(1,)+field_run.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
